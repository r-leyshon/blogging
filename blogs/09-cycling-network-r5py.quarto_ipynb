{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Bicycle Network Modelling with r<sup>5</sup>py\"\n",
        "author: \"Rich Leyshon\"\n",
        "date: \"February 13 2024\"\n",
        "description: \"Analysing service coverage in London's Santander Bike network.\"\n",
        "categories:\n",
        "    - Tutorial\n",
        "    - Transport Modelling\n",
        "    - REST API\n",
        "    - Web data\n",
        "    - Geospatial\n",
        "    - r5py\n",
        "    - pydeck\n",
        "image: \"/./www/09-cycling-network-r5py/intro-img.jpg\"\n",
        "image-alt: \"A cyclist races against a synthwave cityscape.\"\n",
        "toc: true\n",
        "jupyter: \n",
        "  kernelspec:\n",
        "    name: \"cycling-env\"\n",
        "    language: \"python\"\n",
        "    display_name: \"cycling-env\"\n",
        "---\n",
        "\n",
        "<iframe src=\"../outputs/hex_layer.html\" style=\"display: block; margin-left: auto; margin-right: auto; width: 80%; height: 300px;\" title=\"Interactive map of London cycle station location density\"></iframe>\n",
        "<br/>\n",
        "\n",
        "## Introduction\n",
        "\n",
        "[r<sup>5</sup>py is a relatively new transport modelling package](https://r5py.readthedocs.io/en/stable/)\n",
        "available on PyPI. It provides convenient wrappers to\n",
        "[Conveyal's r<sup>5</sup> Java library](https://github.com/conveyal/r5), a\n",
        "performant routing engine originating from the ubiquitous Open Trip Planner\n",
        "(OTP). Whereas r<sup>5</sup>py may not be as feature-rich as OTP, its unique\n",
        "strength is in the production of origin:destination matrices at scale. This is\n",
        "important if the intention is to produce stable statistics based on routing\n",
        "algorithms, where the idiosyncrasies of local transport service availability\n",
        "means that departure times can have a significant impact upon overall journey\n",
        "duration.\n",
        "\n",
        "r<sup>5</sup>py achieves stable statistics by calculating travel times over\n",
        "multiple journeys within a time window, returning summaries such as the median\n",
        "travel time from point A to B.\n",
        "\n",
        ":::{.callout-caution}\n",
        "\n",
        "### A Note on the Purpose\n",
        "\n",
        "This tutorial aims to familiarise the reader with r<sup>5</sup>py and how it\n",
        "integrates with the python geospatial ecosystem of packages. This article is\n",
        "not to be used to attempt to infer service quality outcomes. Limitations of\n",
        "this analysis and suggested improvements will be discussed throughout.\n",
        ":::\n",
        "\n",
        "### Intended Audience\n",
        "\n",
        "Experienced python practitioners with a robust working knowledge of the typical\n",
        "python GIS stack, eg `geopandas`, `shapely` and `folium` and coordinate\n",
        "reference systems (CRS). Familiarity with r<sup>5</sup>py is not assumed. \n",
        "\n",
        "### Outcomes\n",
        "\n",
        "* Ingest London bike charging station locations.\n",
        "* Visualise charging stations in an interactive hex map.\n",
        "* Generate a naive point plane of destinations.\n",
        "* Check that the point plane is large enough to accommodate station locations.\n",
        "* Adjust point plane locations to ensure routability.\n",
        "* Calculate origin:destination travel time matrix, by cycling modality and \n",
        "with a maximum journey time of 30 minutes.\n",
        "* Engineer features to help analyse the cycling network accessibility.\n",
        "* Visualise the cycling network coverage and the most remote points within that\n",
        "area.\n",
        "\n",
        "### What You'll Need:\n",
        "\n",
        "- [ ] Conda or miniconda\n",
        "- [ ] pip package manager\n",
        "- [ ] Ability to install Java Development Kit\n",
        "- [ ] Ability to request from Transport for London api\n",
        "- [ ] Tutorial compatible with macos. `subprocess` calls may require adaptation\n",
        "for other operating systems.\n",
        "\n",
        "```{.python filename=requirements.txt eval=false}\n",
        "contextily\n",
        "geopandas\n",
        "haversine\n",
        "folium\n",
        "mapclassify\n",
        "matplotlib\n",
        "pydeck\n",
        "pyproj\n",
        "r5py\n",
        "requests\n",
        "scikit-learn\n",
        "\n",
        "```\n",
        "\n",
        "### Configuring Java\n",
        "\n",
        "It is required to configure a Java Virtual Machine for this tutorial. The\n",
        "transport routing depends on this. Please consult the r<sup>5</sup>py\n",
        "installation documentation @r5pyInstallation for guidance. In order to check\n",
        "that you have a compatible Java environment, run\n",
        "`r5py.TransportNetwork(osm_pth)` after [exercise 1](#exercise-1). For\n",
        "reference, I have used OpenJDK to manage my Java instance:\n",
        "\n",
        "```\n",
        "openjdk 11.0.19 2023-04-18 LTS\n",
        "OpenJDK Runtime Environment Corretto-11.0.19.7.1 (build 11.0.19+7-LTS)\n",
        "OpenJDK 64-Bit Server VM Corretto-11.0.19.7.1 (build 11.0.19+7-LTS, mixed mode)\n",
        "```\n",
        "\n",
        "## London Cycle Station Service Coverage\n",
        "\n",
        "Start by loading the required packages."
      ],
      "id": "963c81e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import subprocess\n",
        "import tempfile \n",
        "from typing import Union\n",
        "\n",
        "import contextily as ctx\n",
        "import folium\n",
        "import geopandas as gpd\n",
        "from haversine import haversine, Unit\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pydeck as pdk\n",
        "import pyproj\n",
        "import r5py\n",
        "import requests\n",
        "from sklearn import preprocessing\n",
        "from shapely.geometry import LineString, Point, Polygon"
      ],
      "id": "a929b5cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Street Network Data\n",
        "\n",
        "Firstly, we must acquire information about the transport network. There are\n",
        "a few sources of this, but we shall use the\n",
        "[BBBikes](https://download.bbbike.org/osm/bbbike/) website to ingest\n",
        "London-specific OpenStreetMap extracts. The required data should be in\n",
        "protocol buffer (.pbf) format.\n",
        "\n",
        "#### Exercise 1\n",
        "\n",
        "Find the appropriate url that points to the london.osm.pbf file. Ingest the\n",
        "data and store at an appropriate location.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "Either using python requests or subprocess with the `curl` command, request\n",
        "the url of the pbf file and output the response to a data folder.\n",
        "\n",
        ":::\n",
        "\n",
        "#### Solution"
      ],
      "id": "1dcbb6fa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "# As the osm files are large, I will use a tmp directory, though feel free to\n",
        "# store the data wherever you like.\n",
        "tmp = tempfile.TemporaryDirectory()\n",
        "osm_pth = os.path.join(tmp.name, \"london.osm.pbf\")\n",
        "subprocess.run(\n",
        "    [\n",
        "        \"curl\",\n",
        "        \"https://download.bbbike.org/osm/bbbike/London/London.osm.pbf\",\n",
        "        \"-o\",\n",
        "        osm_pth,\n",
        "    ]\n",
        ")"
      ],
      "id": "68f9d6c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bike Charging Station Locations\n",
        "\n",
        "#### Exercise 2\n",
        "\n",
        "To get data about the bike charging stations in London, we will query\n",
        "[Transport for London's BikePoint API](https://api.tfl.gov.uk/).\n",
        "\n",
        "* Explore the site and find the correct endpoint to query. \n",
        "* The tutorial requires the following fields: station ID, the human-readable\n",
        "name, latitude and longitude for each available station.\n",
        "* Store the data in a `geopandas` geodataframe with the appropriate coordinate\n",
        "reference system.\n",
        "* Inspect the head of the geodataframe.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "1. Using the requests package, send a get request to the endpoint.\n",
        "2. Store the required fields in a list: \"id\", \"commonName\", \"lat\", \"lon\".\n",
        "3. Check that the response returned HTTP status 200. If True, get the content\n",
        "in JSON format.\n",
        "4. Create an empty list to store the station data.\n",
        "5. Iterate through the content dictionaries. If a key is present within the\n",
        "required fields, store the key and value within a temporary dictionary.\n",
        "6. Append the dictionary of required fields and their values to the list of\n",
        "stations.\n",
        "7. Convert the list of dictionaries to a pandas dataframe. Then convert this\n",
        "to a `geopandas` geodataframe, using the coordinate reference system \"EPSG:4326\".\n",
        "As we have lat and lon in separate columns, use `geopandas` `points_from_xy()`,\n",
        "ensuring you pass values in the order of longitude, latitude.\n",
        "8. Print out the head of the stations gdf.\n",
        "\n",
        ":::\n",
        "\n",
        "#### Solution"
      ],
      "id": "c2294c2a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "ENDPOINT = \"https://api.tfl.gov.uk/BikePoint/\"\n",
        "resp = requests.get(ENDPOINT)\n",
        "if resp.ok:\n",
        "    content = resp.json()\n",
        "else:\n",
        "    raise requests.exceptions.HTTPError(\n",
        "        f\"{resp.status_code}: {resp.reason}\"\n",
        "    )\n",
        "\n",
        "needed_keys = [\"id\", \"commonName\", \"lat\", \"lon\"]\n",
        "all_stations = list()\n",
        "for i in content:\n",
        "    node_dict = dict()\n",
        "    for k, v in i.items():\n",
        "        if k in needed_keys:\n",
        "            node_dict[k] = v\n",
        "    all_stations.append(node_dict)\n",
        "\n",
        "stations = pd.DataFrame(all_stations)\n",
        "station_gdf = gpd.GeoDataFrame(\n",
        "    stations,\n",
        "    geometry=gpd.points_from_xy(stations[\"lon\"], stations[\"lat\"]),\n",
        "    crs=4326,\n",
        ")\n",
        "\n",
        "station_gdf.head()"
      ],
      "id": "4934c015",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's all the external data needed for this tutorial. Let's now examine the\n",
        "station locations. \n",
        "\n",
        "### Station Density\n",
        "\n",
        "As the stations are densely located in and around central London, a standard\n",
        "matplotlib point map would suffer from overplotting. A better way is to present\n",
        "some aggregated value on a map, such as density. \n",
        "\n",
        "#### Exercise 3\n",
        "\n",
        "Plot the density of cycle station locations on a map. The solution will use\n",
        "[pydeck](https://deckgl.readthedocs.io/en/latest/index.html), but any\n",
        "visualisation library that can handle geospatial data would be fine.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "1. Create a pydeck hexagon layer based on the `station_gdf`. The hexagon layer\n",
        "should be configured as below:\n",
        "* extruded\n",
        "* position from lon and lat columns\n",
        "* elevation scale is 100\n",
        "* elevation range from 0 through 100\n",
        "* coverage is 1\n",
        "* radius of hexagons is 250 metres\n",
        "\n",
        "2. Create a pydeck view state object to control the initial position of the\n",
        "camera. Configure this as you see fit.\n",
        "3. (Optional) Add a custom tooltip, clarifying that the hexagon elevation is\n",
        "equal to the count of stations within that area. You may wish to consult the\n",
        "[deck.gl](https://deck.gl/docs) documentation to help implement this.\n",
        "4. Create a deck with the hexagon layer, custom view state, tooltip and a map\n",
        "style of your choosing.\n",
        "\n",
        ":::\n",
        "\n",
        "#### Solution"
      ],
      "id": "c109af58"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "# pydeck visuals - concentration of charging stations by r250m hex\n",
        "layer = pdk.Layer(\n",
        "    \"HexagonLayer\",\n",
        "    station_gdf,\n",
        "    pickable=True,\n",
        "    extruded=True,\n",
        "    get_position=[\"lon\", \"lat\"],\n",
        "    auto_highlight=True,\n",
        "    elevation_scale=100,\n",
        "    elevation_range=[0, 100],\n",
        "    coverage=1,\n",
        "    radius=250,  # in metres, default is 1km\n",
        "    colorRange=[\n",
        "        [255, 255, 178, 130],\n",
        "        [254, 217, 118, 130],\n",
        "        [254, 178, 76, 130],\n",
        "        [253, 141, 60, 130],\n",
        "        [240, 59, 32, 130],\n",
        "        [189, 0, 38, 130],\n",
        "    ], # optionally added rgba values to allow transparency\n",
        ")\n",
        "view_state = pdk.ViewState(\n",
        "    # longitude=-0.140,# value for iframe\n",
        "    longitude=-0.070,# value for code chunk\n",
        "    latitude=51.535, \n",
        "    # zoom=10, # value for iframe\n",
        "    zoom=10.5, # value for code chunk\n",
        "    min_zoom=5,\n",
        "    max_zoom=15,\n",
        "    pitch=40.5,\n",
        "    bearing=-27.36,\n",
        ")\n",
        "tooltip = {\"html\": \"<b>n Stations:</b> {elevationValue}\"}\n",
        "r = pdk.Deck(\n",
        "    layers=[layer],\n",
        "    initial_view_state=view_state,\n",
        "    tooltip=tooltip, # prettier than default tooltip\n",
        "    map_style=pdk.map_styles.LIGHT,\n",
        ")\n",
        "r"
      ],
      "id": "bf4cd5fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate Destinations\n",
        "\n",
        "We can use the bike stations as journey origins. To compute travel times, we\n",
        "need to generate destination locations. This tutorial uses a simple approach\n",
        "to generating equally spaced points within a user-defined bounding box. \n",
        "\n",
        ":::{.callout-caution}\n",
        "#### Limitation\n",
        "\n",
        "Generating a point plane is a fast way to get a travel time matrix. However,\n",
        "this is naive to locations that the riders would prefer to start or finish\n",
        "their journeys. A more robust approach would be to use locations of retail or\n",
        "residential features. The European Commission's Global Human Settlement Layer\n",
        "@GHSL data would provide centroids to every populated grid cell down to a\n",
        "10m<sup>2</sup> resolution.\n",
        ":::\n",
        "\n",
        "#### Exercise 4\n",
        "\n",
        "Write a function called `create_point_grid()` that will take the following\n",
        "parameters:\n",
        "\n",
        "* `bbox_list` expecting a [bounding box](https://boundingbox.klokantech.com/)\n",
        "list in [xmin, ymin, xmax, ymax] format with epsg:4326 longitude & latitude\n",
        "values.\n",
        "* `stepsize` expecting a positive integer, specifying the spacing of the grid\n",
        "points in metres.\n",
        "\n",
        "`create_point_grid()` should return a `geopandas` geodataframe of equally\n",
        "spaced point locations - the point grid. The grid point locations should be in\n",
        "epsg:4326 projection. The geodataframe requires a `geometry` column and an `id`\n",
        "column equal to the index of the dataframe (required for r<sup>5</sup>py\n",
        "origin:destination matrix calculation).\n",
        "\n",
        "Once you are happy with the function, use it to produce an example geodataframe\n",
        "and `explore()` a `folium` map of the point grid.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "Note that epsg:4326 is a geodetic projection, unsuitable for measuring distance\n",
        "between points in the point plane. Ensure that the crs is re-projected to an\n",
        "appropriate planar crs for distance calculation.\n",
        "\n",
        "1. Store the South-West and North-East coordinates as `shapely.geometry.Point`\n",
        "objects.\n",
        "2. Use `pyproj.Transformer.from_crs()` to create 2 transformers, one from\n",
        "geodetic to planar, and the other back from planar to geodetic.\n",
        "3. Use the transformers to convert the SW and NE points from geodetic to\n",
        "planar.\n",
        "4. Use nested loops to iterate over the area between the corner points.\n",
        "Store the point location as a `shapely.geometry.Point` object. Append the point\n",
        "to a list of grid points.\n",
        "5. Increment the x and y values by the provided `stepsize` and continue to\n",
        "append points in this fashion until xmin has reached the xmax value and ymin\n",
        "has met the ymax value.\n",
        "6. Ensure the stored coordinates are converted back to epsg:4326.\n",
        "7. Create a pandas dataframe with the geometry column using the appended point\n",
        "locations and an `id` column that uses the `range()` function to generate a\n",
        "unique integer value for each row. \n",
        "8. Use the defined function with a sample bounding box and explore the\n",
        "resulting geodataframe with an interactive `folium` map.\n",
        "\n",
        ":::\n",
        "\n",
        "#### Solution"
      ],
      "id": "d31e8686"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "def create_point_grid(bbox_list: list, stepsize: int) -> gpd.GeoDataFrame:\n",
        "    \"\"\"Create a metric point plane for a given bounding box.\n",
        "\n",
        "    Return a geodataframe of evenly spaced points for a specified bounding box.\n",
        "    Distance between points is controlled by stepsize in metres.  As\n",
        "    an intermediate step requires transformation to epsg:27700, the calculation\n",
        "    of points is suitable for GB only.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bbox_list : list\n",
        "        A list in xmin, ymin, xmax, ymax order. Expected to be in epsg:4326.\n",
        "        Use https://boundingbox.klokantech.com/ or similar to export a bbox.\n",
        "    stepsize : int\n",
        "        Spacing of grid points in metres. Must be larger than zero.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    gpd.GeoDataFrame\n",
        "        GeoDataFrame in epsg:4326 of the point locations.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    TypeError\n",
        "        bbox_list is not type list.\n",
        "        Coordinates in bbox_list are not type float.\n",
        "        step_size is not type int.\n",
        "    ValueError\n",
        "        bbox_list is not length 4.\n",
        "        xmin is greater than or equal to xmax.\n",
        "        ymin is greater than or equal to ymax.\n",
        "        step_size is not a positive integer.\n",
        "\n",
        "    \"\"\"\n",
        "    # defensive checks\n",
        "    if not isinstance(bbox_list, list):\n",
        "        raise TypeError(f\"bbox_list expects a list. Found {type(bbox_list)}\")\n",
        "    if not len(bbox_list) == 4:\n",
        "        raise ValueError(f\"bbox_list expects 4 values. Found {len(bbox_list)}\")\n",
        "    for coord in bbox_list:\n",
        "        if not isinstance(coord, float):\n",
        "            raise TypeError(\n",
        "                f\"Coords must be float. Found {coord}: {type(coord)}\"\n",
        "            )\n",
        "    # check points are ordered correctly\n",
        "    xmin, ymin, xmax, ymax = bbox_list\n",
        "    if xmin >= xmax:\n",
        "        raise ValueError(\n",
        "            \"bbox_list value at pos 0 should be smaller than value at pos 2.\"\n",
        "        )\n",
        "    if ymin >= ymax:\n",
        "        raise ValueError(\n",
        "            \"bbox_list value at pos 1 should be smaller than value at pos 3.\"\n",
        "        )\n",
        "    if not isinstance(stepsize, int):\n",
        "        raise TypeError(f\"stepsize expects int. Found {type(stepsize)}\")\n",
        "    if stepsize <= 0:\n",
        "        raise ValueError(\"stepsize must be a positive integer.\")\n",
        "\n",
        "    # Set up crs transformers. Need a planar crs for work in metres - use BNG\n",
        "    planar_transformer = pyproj.Transformer.from_crs(4326, 27700)\n",
        "    geodetic_transformer = pyproj.Transformer.from_crs(27700, 4326)\n",
        "    # bbox corners\n",
        "    sw = Point((xmin, ymin))\n",
        "    ne = Point((xmax, ymax))\n",
        "    # Project corners to planar\n",
        "    planar_sw = planar_transformer.transform(sw.x, sw.y)\n",
        "    planar_ne = planar_transformer.transform(ne.x, ne.y)\n",
        "    # Iterate over metric plane\n",
        "    points = []\n",
        "    x = planar_sw[0]\n",
        "    while x < planar_ne[0]:\n",
        "        y = planar_sw[1]\n",
        "        while y < planar_ne[1]:\n",
        "            p = Point(geodetic_transformer.transform(x, y))\n",
        "            points.append(p)\n",
        "            y += stepsize\n",
        "        x += stepsize\n",
        "    df = pd.DataFrame({\"geometry\": points, \"id\": range(0, len(points))})\n",
        "    gdf = gpd.GeoDataFrame(df, crs=4326)\n",
        "    return gdf\n",
        "\n",
        "create_point_grid(\n",
        "  bbox_list=[-0.5917,51.2086,0.367,51.7575], stepsize=5000).explore(min_zoom=9)"
      ],
      "id": "c47b94cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Study Area Size\n",
        "\n",
        "Before we go ahead with the transport modelling, it is important to check that\n",
        "the point plane is large enough to contain a 30 minute journey from any of the\n",
        "stations. 30 minutes is the current charging interval for the pay as you ride\n",
        "options @SantanderCycleFees. Note that making the point plane larger or the\n",
        "step size smaller means more travel times to calculate, so there is a\n",
        "compromise to be met. Using too small a grid will introduce edge effects\n",
        "@EdgeEffects and therefore limit the validity of the study.\n",
        "\n",
        "#### Exercise 5\n",
        "\n",
        "Check that the point plane study area is large enough to accommodate an\n",
        "estimation of reachable area from the station locations.\n",
        "\n",
        "#### Part 1\n",
        "\n",
        "1. Create a `point_plane` object with `create_point_grid()` that has a bounding\n",
        "box of your choosing. Use a stepsize of 1000 metres. \n",
        "2. Get the boundary polygon of this point plane. This is the study area.\n",
        "3. Buffer the bike station locations. This buffered area should represent\n",
        "the reachable area from within a 30 minute ride of any station and a presumed\n",
        "average urban cycle speed of 18 kilometres per hour (an opinionated speed\n",
        "based on a sample of one overweight, middle-aged man's Strava data). Store the\n",
        "geometry as a Polygon object.\n",
        "4. Check that the study area completely contains the buffered stations.\n",
        "\n",
        "#### Part 2\n",
        "\n",
        "Create a diagnostic plot displaying the station locations, buffered station\n",
        "polygon and study area polygon together on one map.\n",
        "\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "Part 1\n",
        "\n",
        "For this exercise, you may find the\n",
        "[Klokantech bounding box tool](https://boundingbox.klokantech.com/) useful.\n",
        "Ensure that the output is formatted as csv.\n",
        "\n",
        "1. Create a point plane of your choosing. Use the `total_bounds` attribute to\n",
        "extract values for minx, miny, maxx, maxy.\n",
        "2. Use `shapely.geometry.Polygon` to convert the 4 values above into a\n",
        "rectangular bounding box. \n",
        "3. Re-project the stations geodataframe to a planar crs. Buffer this\n",
        "geodataframe by an appropriate value in metres, convert back to epsg:4326 and\n",
        "store the unary union.\n",
        "4. Check that the study area polygon completely contains the buffered station\n",
        "polygon by using an appropriately named GeoDataFrame method.\n",
        "\n",
        "Part 2\n",
        "\n",
        "1. Plot the stations gdf using marker values \"o\", an alpha of 0.5, markersize\n",
        "of 10 and red colour. Store in a variable called `ax`.\n",
        "2. Plot the study area boundary polygon, ensuring the `ax` value from the\n",
        "previous step is used. Use an alpha of 0.2.\n",
        "3. Add a plot of the buffered stations to the same axes, ensuring a colour\n",
        "\"red\" and an alpha of 0.2.\n",
        "4. Use `contextily` to add a basemap to the axes, selecting an appropriate crs\n",
        "value and tile provider.\n",
        "5. Use `matplotlib.pyplot` to show the plot.\n",
        "\n",
        ":::\n",
        "\n",
        "#### Solution\n",
        "\n",
        "Part 1"
      ],
      "id": "d113d441"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        " \n",
        "point_plane = create_point_grid(\n",
        "    [-0.4, 51.35, 0.15, 51.65], stepsize=1000\n",
        ")\n",
        "# Get a boundary polygon for the study area\n",
        "minx, miny, maxx, maxy = point_plane.total_bounds\n",
        "bbox_polygon = gpd.GeoSeries(\n",
        "    [Polygon([(minx, miny), (minx, maxy), (maxx, maxy), (maxx, miny)])]\n",
        ")\n",
        "# buffer the stations by presumed urban cycle speed of 18 kph\n",
        "station_buffer = gpd.GeoSeries(\n",
        "    Polygon(\n",
        "      station_gdf.to_crs(27700).buffer(9000).to_crs(4326).geometry.unary_union\n",
        "      )\n",
        ")\n",
        "cond = bbox_polygon.contains(station_buffer)[0]\n",
        "print(\n",
        "  f\"Point grid contains buffered stations? {cond}\")"
      ],
      "id": "57d29fdf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 2"
      ],
      "id": "0f797bee"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "ax = station_gdf.plot(marker=\"o\", color=\"red\", alpha=0.5, markersize=10)\n",
        "# plot the bounding box of the point plane boundary in blue\n",
        "bbox_polygon.plot(ax=ax, alpha=0.2, edgecolor=\"black\")\n",
        "# plot the buffered potential travel region around the stations\n",
        "# in light red\n",
        "station_buffer.plot(ax=ax, alpha=0.2, color=\"red\")\n",
        "ctx.add_basemap(\n",
        "    ax, crs=station_gdf.crs.to_string(), source=ctx.providers.CartoDB.Positron\n",
        ")\n",
        "plt.show()"
      ],
      "id": "cfac034b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With a study area adequately encompassing the proposed reachable area, proceed\n",
        "to the transport routing.\n",
        "\n",
        "### Routability\n",
        "\n",
        "As we have created a point plane naive to the transport network, it is\n",
        "important to check that the points are reachable by bike. Any point falling\n",
        "within an inaccessible portion of the transport network will report a null\n",
        "travel time. r<sup>5</sup>py comes with a utility function that helps to 'snap'\n",
        "unreachable locations to the nearest feature of the travel network.\n",
        "\n",
        "#### Exercise 6\n",
        "\n",
        "#### Part 1\n",
        "\n",
        "Using the [r<sup>5</sup>py quickstart documentation](https://r5py.readthedocs.io/en/stable/user-guide/user-manual/quickstart.html), instantiate a `transport_network`\n",
        "object, passing `osm_pth` as its single argument.\n",
        "\n",
        "#### Part 2\n",
        "\n",
        "1. Now using the [r<sup>5</sup>py advanced use section](https://r5py.readthedocs.io/en/stable/user-guide/user-manual/advanced-use.html), create a new column in the\n",
        "`point_plane` gdf called `snapped_geometry`.\n",
        "2. Use the correct method of the `transport_network` to adjust the existing\n",
        "geometry column.\n",
        "3. Use a maximum search radius of 500 metres and specify the bicycle modality.\n",
        "Inspect the resulting geodataframe. \n",
        "\n",
        "#### Part 3\n",
        "\n",
        "Now that we have a point plane with a routable geography, we can check to\n",
        "ensure that the maximum search radius was observed.\n",
        "\n",
        "1. Calculate the haversine distance in metres between the original `geometry`\n",
        "and the `snapped_geometry` coordinates.\n",
        "2. Assign the result to `point_plane[\"snap_dist_m\"]`.\n",
        "3. Inspect the distribution of the `snap_dist_m` column. Confirm that there are\n",
        "no values above the maximum search radius value.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "Part 1\n",
        "\n",
        "1. r<sup>5</sup>py is imported as r5py. You can inspect the available classes\n",
        "by using the `dir()` function.\n",
        "\n",
        "Part 2\n",
        "\n",
        "1. Use `dir()` on the `transport_network` object instantiated in part 1 to find\n",
        "the appropriate method for snapping the coordinates to the nearest network\n",
        "feature.\n",
        "2. Specify the `radius` argument with an appropriate value.\n",
        "3. For the `street_mode` argument, select the appropriate r<sup>5</sup>py\n",
        "transport mode. To find this value, use `dir(r5py.TransportMode)`.\n",
        "\n",
        "Part 3\n",
        "\n",
        "1. The `haversine` function is imported. Unfortunately, it expects coordinates\n",
        "to be in a latitude, longitude order. \n",
        "2. Apply a `lambda` function across every row in the `point_plane`\n",
        "GeoDataFrame. You will need to specify `axis=1` to achieve this.\n",
        "3. Within the lambda function, calculate the haversine distance in metres\n",
        "between the original coordinates and the `snapped_geometry` coordinates. Assign\n",
        "the output to the correctly named column.\n",
        "4. Inspect the distribution of the haversine distances in whichever way you\n",
        "feel. Can you confirm that no coordinate was adjusted beyond the maximum search\n",
        "radius used when you instantiated the `snapped_geometry` column?\n",
        "\n",
        ":::\n",
        "\n",
        "#### Solution\n",
        "\n",
        "#### Part 1"
      ],
      "id": "12fb8559"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "transport_network = r5py.TransportNetwork(osm_pth)"
      ],
      "id": "ecd7dd0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This may seem like a small step, but if this passed, then you have correctly\n",
        "configured your Java Virtual Machine. \n",
        "\n",
        "#### Part 2"
      ],
      "id": "9e5bf204"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "point_plane[\"snapped_geometry\"] = transport_network.snap_to_network(\n",
        "    point_plane[\"geometry\"],\n",
        "    radius=500,\n",
        "    street_mode=r5py.TransportMode.BICYCLE,\n",
        ")\n",
        "point_plane.head()"
      ],
      "id": "3c1e7ce1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Part 3"
      ],
      "id": "f7152f0d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "# reverse the lonlat to latlon\n",
        "point_plane[\"snap_dist_m\"] = point_plane.apply(\n",
        "    lambda row:haversine(\n",
        "        (row[\"geometry\"].y, row[\"geometry\"].x),\n",
        "        (row[\"snapped_geometry\"].y, row[\"snapped_geometry\"].x),\n",
        "        unit=Unit.METERS), axis=1)\n",
        "\n",
        "point_plane[\"snap_dist_m\"].plot.hist(\n",
        "    bins=100,\n",
        "    title=\"Distribution of coordinate snap distance in point plane (m)\"\n",
        "    )"
      ],
      "id": "8fbc8f22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we can confirm that the distribution of the haversine distances is\n",
        "strongly right-skewed. There appear to be no values greater than 450 metres."
      ],
      "id": "7147179d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "point_plane[\"snap_dist_m\"].describe()"
      ],
      "id": "7694413c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In describing the column we can observe the actual maximum haversine distance\n",
        "of 492 metres. Note the differences in the mean and median are attributable to\n",
        "the strong skew in the distance distribution.\n",
        "\n",
        "The spatial adjustment caused by the snapping can be visualised. This is useful\n",
        "for sanity-checking and edge-case investigation. \n",
        "\n",
        "#### Exercise 7\n",
        "\n",
        "#### Part 1\n",
        "\n",
        "1. Create a deep copy of the `point_plane` geodataframe and assign to a new\n",
        "object called `largest_snaps`.\n",
        "2. Retrieve the rows with the largest 100 `snap_dist_m` values. Visualising the\n",
        "points is expensive, so we will only display a subset.\n",
        "3. Apply a lambda function over `largest_snaps`, creating a `LineString`\n",
        "between each `geometry` and `snapped_geometry` value. This will be used to draw\n",
        "a line between each point on a map.\n",
        "4. Assign the output to `largest_snaps[\"lines\"]`.\n",
        "5. Inspect the head of the resultant geodataframe.\n",
        "\n",
        "#### Part 2\n",
        "\n",
        "1. Plot `largest_snaps` on a `folium` map. Add a marker layer with red icons\n",
        "showing the locations of the original point plane geometry.\n",
        "2. Add a second marker layer to the same `folium` map, adding the snapped\n",
        "geometry with a green marker.\n",
        "3. Add the final layer to the map - the lines connecting the geometries to\n",
        "their snapped equivalents.\n",
        "4. Show the map.\n",
        "\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "Part 1\n",
        "\n",
        "1. Sort ascending the `largest_snaps` geodataframe by `snap_dist_m`. Take the\n",
        "top 100 records only.\n",
        "2. `LineString` takes 2 arguments, a start and end point coordinate.\n",
        "3. Apply the `LineString` logic over each row in the geodataframe, ensuring the\n",
        "`axis` argument is set to 1.\n",
        "4. For each row, pass the `geometry` column value to `LineString` as the first\n",
        "argument, and the `snapped_geometry` value as the second.\n",
        "5. Assign the returned value to an appropriately named column.\n",
        "\n",
        "Part 2\n",
        "\n",
        "This exercise will exploit the kwargs available through the\n",
        "`GeoDataFrame.explore()` method. Alternatively, the map can be built from\n",
        "scratch using the `folium` library.\n",
        "\n",
        "1. Call explore on `largest_snaps`, specifying a \"marker\" `marker_type`. Use\n",
        "the `marker_kwds` parameter to pass a dictionary specifying which font-awesome\n",
        "icon to use for the geometry points. Assign the map to `imap`.\n",
        "2. Set the geometry to the `snapped_geometry` column and repeat the above\n",
        "process, this time specifying green markers for the points. Ensure the `m`\n",
        "parameter is set to `imap` in order to add this to the same map object.\n",
        "3. Lastly, set the geometry to the `lines` column and explore, again setting\n",
        "`m=imap` to add the line geometries to the interactive map. Specify an\n",
        "appropriate zoom level.\n",
        "4. Show the map and explore the adjusted geometries.\n",
        "\n",
        ":::\n",
        "\n",
        "#### Solution\n",
        "\n",
        "#### Part 1"
      ],
      "id": "a9ff37fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "largest_snaps = point_plane.copy(deep=True)\n",
        "# retrieve the top 100 rows where coordinates adjusted by the greatest dist.\n",
        "largest_snaps = largest_snaps.sort_values(\n",
        "    by=\"snap_dist_m\", ascending=False).head(100)\n",
        "# create the LineString geometry\n",
        "largest_snaps[\"lines\"] = largest_snaps.apply(\n",
        "    lambda row: LineString([row[\"geometry\"], row[\"snapped_geometry\"]]),\n",
        "    axis=1\n",
        ")\n",
        "largest_snaps.head()"
      ],
      "id": "9cd89a96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Part 2"
      ],
      "id": "af17ca30"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "# layer 1\n",
        "z_start = 9\n",
        "imap = largest_snaps.explore(\n",
        "    marker_type=\"marker\",\n",
        "    marker_kwds={\n",
        "        \"icon\": folium.map.Icon(color=\"red\", icon=\"ban\", prefix=\"fa\"),\n",
        "    },\n",
        "    map_kwds={\n",
        "        \"center\": {\"lat\": 51.550, \"lng\": -0.070}\n",
        "    },\n",
        "    zoom_start=z_start,\n",
        ")\n",
        "# layer 2\n",
        "imap = largest_snaps.set_geometry(\"snapped_geometry\").explore(\n",
        "    m=imap,\n",
        "    marker_type=\"marker\",\n",
        "    marker_kwds={\n",
        "        \"icon\": folium.map.Icon(color=\"green\", icon=\"bicycle\", prefix=\"fa\"),\n",
        "    }\n",
        ")\n",
        "# layer 3\n",
        "imap = largest_snaps.set_geometry(\"lines\").explore(\n",
        "    m=imap,\n",
        "    zoom_start=z_start\n",
        ")\n",
        "imap"
      ],
      "id": "4f0c71ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Travel Times\n",
        "\n",
        "Now that we have everything we need to carry out the transport routing, there\n",
        "is one final adjustment to the point plane - ensure that the snapped geometries\n",
        "are set as the geometry column. The snapped distance and original geometry\n",
        "column can be removed."
      ],
      "id": "dd9e84ad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "point_plane.drop(columns=[\"geometry\", \"snap_dist_m\"], axis=1, inplace=True)\n",
        "point_plane.rename(columns={\"snapped_geometry\": \"geometry\"}, inplace=True)\n",
        "point_plane.set_geometry(\"geometry\", inplace=True)\n",
        "point_plane.head()"
      ],
      "id": "505b4309",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute the Travel Time Matrix\n",
        "\n",
        "Now we use r<sup>5</sup>py to compute the travel times from the station\n",
        "locations to the adjusted point plane.\n",
        "\n",
        "Some notes on the parameters:\n",
        "\n",
        "* `transport_modes` takes a list of modes. For simplicity, only `BICYCLE` is\n",
        "used, though combining with `WALK` would allow routing through portions of the\n",
        "travel network tagged as pedestrian-only.\n",
        "* `departure_time` takes a `datetime` that signifies the first trip start time\n",
        "and date. This should ideally match the date that you ingested the osm file, as\n",
        "the osm files will best represent the real-world state of the transport\n",
        "network.\n",
        "* `departure_time_window` creates a time window to carry out routing\n",
        "operations. The first journey occurs at 8am, as specified by `departure`. Then\n",
        "r<sup>5</sup>py processes a journey at every minute until the\n",
        "`departure_time_window` is met. By default, r<sup>5</sup>py returns the median\n",
        "travel time across these journeys. This feature provides stable statistics,\n",
        "particularly when working with bus or train timetable data.\n",
        "* The points can be snapped during the computation job, by specifying\n",
        "`snap_to_network=True`. As we have already specified how to do this, we can set\n",
        "this to False.\n",
        "* `max_time` takes a timedelta object. Here we specify that the journeys should\n",
        "take no longer than 30 minutes, as this is the current hire charge period for\n",
        "the bikes. \n",
        "* The `compute_travel_times` method returns a pandas DataFrame of median\n",
        "travel times for every origin, destination combination.\n",
        "\n",
        "This step can be expensive, depending on the size of your point plane. Don't be\n",
        "alarmed by NaN in the `travel_time` column. These are points in the point plane\n",
        "that were not reachable from any bike station. "
      ],
      "id": "0cb08e02"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dept_time = datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)\n",
        "\n",
        "travel_time_matrix = r5py.TravelTimeMatrixComputer(\n",
        "    transport_network,\n",
        "    origins=station_gdf,\n",
        "    destinations=point_plane,\n",
        "    transport_modes=[r5py.TransportMode.BICYCLE],\n",
        "    departure=dept_time,\n",
        "    departure_time_window=timedelta(minutes=10),\n",
        "    snap_to_network=False,\n",
        "    max_time=timedelta(minutes=30),\n",
        ").compute_travel_times()\n",
        "\n",
        "travel_time_matrix.dropna().head()"
      ],
      "id": "9f630054",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering\n",
        "\n",
        "In order to produce some informative visuals, the travel time matrix will need\n",
        "some summarisation and feature engineering.\n",
        "\n",
        "#### Exercise 8\n",
        "\n",
        "Produce a table called `med_tts` with the following spec:\n",
        "\n",
        "```\n",
        "id                       int64\n",
        "geometry              geometry\n",
        "median_tt              float64\n",
        "n_stations_serving       int16\n",
        "n_stations_norm        float64\n",
        "inverted_med_tt        float64\n",
        "listed_geom             object\n",
        "```\n",
        "\n",
        "#### Part 1\n",
        "\n",
        "1. Calculate the median travel time for every point in the point plane across\n",
        "the stations, call the column `median_tt`.\n",
        "2. Calculate the number of bike stations that can reach each point in the point\n",
        "plane. Ensure that this column is formatted as \"int16\" and is called\n",
        "`n_stations_serving`.\n",
        "3. Join the medians and number of stations to `point_plane` on `to_id`.\n",
        "\n",
        "#### Part 2\n",
        "\n",
        "1. Use a minmax scaler to scale the number of stations serving each point in\n",
        "the point plane. Assign this to `med_tts[\"n_stations_norm\"]`.\n",
        "2. Calculate inverteded values for the median travel time. Use the same scaling\n",
        "as the previous step and assign to `med_tts[\"inverted_med_tt\"]`.\n",
        "3. Create a column with a list of the coordinate for each row, in `[long, lat]`\n",
        "order. This is the geometry format expected by pydeck. Assign this to \n",
        "`med_tts[\"listed_geom\"]`.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "Part 1\n",
        "\n",
        "1. To create the median travel times across bike stations, group by the `to_id`\n",
        "column and calculate the `median`.\n",
        "2. To get the number of stations reaching each point, group by the `to_id`\n",
        "column and count the number of `from_id` values.\n",
        "3. Join the above grouped dataframes to the point plane dataframe, using the\n",
        "`to_id` column as the search key. Ensure the columns are named as specified in\n",
        "the exercise.\n",
        "4. Cast `n_stations_serving` to int16. First, ensure that NaNs get encoded\n",
        "as 0. To do this, create a boolean mask where that column is na and assign the\n",
        "column values that meet that boolean index to 0. Then casting to int will be\n",
        "possible.\n",
        "\n",
        "Part 2\n",
        "\n",
        "1. Instantiate a `min_max_scaler` using an appropriate class from `sklearn`.\n",
        "2. Reshape the values of `n_stations_serving` into a 2D numpy array, containing\n",
        "enough rows for each value.\n",
        "3. Using the `min_max_scaler`, transform the numpy array.\n",
        "4. Flatten the output of `min_max_scaler` and assign to a column called\n",
        "`n_stations_norm`.\n",
        "5. Create a new column `inverted_med_tt`, which subtracts all `median_tt`\n",
        "values from the maximum value in that column.\n",
        "6. Scale `inverted_med_tt` by repeating steps 2 through 4 for this column.\n",
        "7. Use a list comprehension to extract each of the `geometry` coordinate\n",
        "values as a long,lat list. Assign to `listed_geom`.\n",
        ":::\n",
        "\n",
        "#### Solution"
      ],
      "id": "b64f8536"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "def get_median_tts_for_all_stations(\n",
        "    tt: pd.DataFrame, pp: gpd.GeoDataFrame\n",
        ") -> gpd.GeoDataFrame:\n",
        "    \"\"\"Join travel times point geometries & calculate medians.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tt : pd.DataFrame\n",
        "        Matrix of travel times where `from_id` are stations and `to_id` are\n",
        "        points in the point plane.\n",
        "    pp : gpd.GeoDataFrame\n",
        "        Locations in the point plane.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    gpd.GeoDataFrame\n",
        "        Point plane locations with median travel times from stations and number\n",
        "        of stations serving each point.\n",
        "\n",
        "    \"\"\"\n",
        "    #----- Part 1 -----\n",
        "    # get median travel time from all stations:\n",
        "    med_tts = tt.groupby(\"to_id\")[\"travel_time\"].median()\n",
        "    # get number of stations serving each point in the grid\n",
        "    tt_dropna = tt.dropna()\n",
        "    n_stations = tt_dropna.groupby(\"to_id\")[\"from_id\"].count()\n",
        "    df = pp.join(med_tts).join(n_stations)\n",
        "    df = df.rename(\n",
        "        columns={\"travel_time\": \"median_tt\", \"from_id\": \"n_stations_serving\"}\n",
        "    )\n",
        "    # need integer for n_stations_serving but there are NaNs\n",
        "    bool_ind = df[\"n_stations_serving\"].isna()\n",
        "    df.loc[bool_ind, \"n_stations_serving\"] = 0.0\n",
        "    df[\"n_stations_serving\"] = df[\"n_stations_serving\"].astype(\"int16\")\n",
        "    #----- Part 2 -----\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    x = df[\"n_stations_serving\"].values.reshape(-1, 1)\n",
        "    x_scaled = min_max_scaler.fit_transform(x)\n",
        "    df[\"n_stations_norm\"] = pd.Series(x_scaled.flatten())\n",
        "    max_tt = max(df[\"median_tt\"].dropna())\n",
        "    df[\"inverted_med_tt\"] = (max_tt - df[\"median_tt\"])\n",
        "    x = df[\"inverted_med_tt\"].values.reshape(-1, 1)\n",
        "    x_scaled = min_max_scaler.fit_transform(x)\n",
        "    df[\"inverted_med_tt\"] = pd.Series(x_scaled.flatten())\n",
        "    out_gdf = gpd.GeoDataFrame(df, crs=4326)\n",
        "    out_gdf[\"listed_geom\"] = [[c.x, c.y] for c in out_gdf[\"geometry\"]]\n",
        "\n",
        "    return out_gdf\n",
        "\n",
        "\n",
        "med_tts = get_median_tts_for_all_stations(travel_time_matrix, point_plane)\n",
        "med_tts.dropna().head()"
      ],
      "id": "fc491e1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As this final GeoDataFrame is all that is required for the remaining tutorial,\n",
        "go ahead and tidy up the environment. "
      ],
      "id": "a368b5b0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tidy up\n",
        "tmp.cleanup() # only needed if tmp directory used\n",
        "del [station_gdf, travel_time_matrix, point_plane, transport_network, imap,\n",
        "largest_snaps, z_start]"
      ],
      "id": "b2cce7b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualise Travel Time\n",
        "\n",
        "#### Exercise 9\n",
        "\n",
        "Using the [pydeck scatterplot layer docs](https://deckgl.readthedocs.io/en/latest/gallery/scatterplot_layer.html),\n",
        "write a function that will take the `med_tts` GeoDataFrame and plot an\n",
        "interactive map. Use the features available in `med_tts` to customise the point\n",
        "radius and colour. Use the function to render an interactive map."
      ],
      "id": "37b62468"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "\n",
        "def make_scatter_deck(\n",
        "    gdf: gpd.GeoDataFrame,\n",
        "    radius=\"(n_stations_norm * 20) + 20\",\n",
        "    start_lon: float=-0.005,\n",
        "    start_lat: float=51.518,\n",
        "    start_zoom: Union[int, float]=10,\n",
        ") -> pdk.Deck:\n",
        "    \"\"\"Render a scatterPlotLayer of travel time & number of stations serving.\n",
        "\n",
        "    Intended for use with output of ./src/tt-london-bikes.py ->\n",
        "    ./data/interim/median_travel_times.pkl.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    gdf : gpd.GeoDataFrame\n",
        "        Table of grid locations and travel time from station locations.\n",
        "    radius : str, optional\n",
        "        A valid pydeck get_radius expression, by default\n",
        "        \"(n_stations_norm * 25) + 20\"\n",
        "    start_lon: float, optional\n",
        "        The starting view longitude, by default -0.110.\n",
        "    start_lat: float, optional\n",
        "        The starting view latitude, by default 51.518.\n",
        "    start_zoom: Union[int, float], optional\n",
        "        The starting view zoom, by default 10.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pdk.Deck\n",
        "        A rendered interactive map.\n",
        "\n",
        "    \"\"\"\n",
        "    # some basic defensive checks\n",
        "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
        "        raise TypeError(f\"gdf expected gpd.GeoDataFrame, found {type(gdf)}\")\n",
        "    expected_cols = [\n",
        "        \"n_stations_serving\",\n",
        "        \"listed_geom\",\n",
        "        \"inverted_med_tt\",\n",
        "        \"median_tt\",\n",
        "    ]\n",
        "    coldiff = sorted(list(set(expected_cols).difference(gdf.columns)))\n",
        "    if coldiff:\n",
        "        raise AttributeError(f\"Required column names are absent: {coldiff}\")\n",
        "    gdf = gdf.rename(columns={\"n_stations_serving\": \"n_stats\"})\n",
        "    # create deck layers\n",
        "    layer = pdk.Layer(\n",
        "        \"ScatterplotLayer\",\n",
        "        gdf,\n",
        "        pickable=True,\n",
        "        opacity=0.2,\n",
        "        stroked=True,\n",
        "        filled=True,\n",
        "        radius_scale=6,\n",
        "        radius_min_pixels=1,\n",
        "        radius_max_pixels=100,\n",
        "        line_width_min_pixels=1,\n",
        "        get_position=\"listed_geom\",\n",
        "        get_radius=radius,\n",
        "        get_fill_color=\"[255,(median_tt * 255), (inverted_med_tt * 255)]\",\n",
        "        get_line_color=\"[255,(median_tt * 255), (inverted_med_tt * 255)]\",\n",
        "    )\n",
        "    # Set the viewport location\n",
        "    view_state = pdk.ViewState(\n",
        "        longitude=start_lon,\n",
        "        latitude=start_lat,\n",
        "        zoom=start_zoom,\n",
        "        min_zoom=5,\n",
        "        max_zoom=15,\n",
        "        pitch=40.5,\n",
        "        bearing=-27.36,\n",
        "    )\n",
        "    tooltip = {\n",
        "        \"text\": \"Stations serving: {n_stats}\\nMdn travel time: {median_tt}\"\n",
        "    }\n",
        "    # Render\n",
        "    r = pdk.Deck(\n",
        "        layers=[layer], initial_view_state=view_state, tooltip=tooltip\n",
        "    )\n",
        "    return r\n",
        "\n",
        "\n",
        "r = make_scatter_deck(med_tts)\n",
        "r"
      ],
      "id": "91a439b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take some time to study the map. Pan in and out by scrolling. The angle of the\n",
        "map can be adjusted by shift + clicking and dragging the mouse left to right.\n",
        "Find the point with the greatest number of stations serving. Look for any\n",
        "curious patterns in the median travel time. Take a look at the Greenwich\n",
        "peninsula, where the River Thames appears to limit accessibility from the\n",
        "North.\n",
        "\n",
        "#### Exercise 10\n",
        "\n",
        "Lastly, we can identify those points within the thirty minute reachable area\n",
        "from the bike station network that are the most remote. Let's visualise the 20\n",
        "most remote locations. These would represent candidate locations for increasing\n",
        "the coverage of the bike network within the thirty minute reachable zone. Once\n",
        "more, please note that the point grid is naive to locations where people live\n",
        "or would like to travel to and from.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\"}\n",
        "#### Click to expand hint\n",
        "\n",
        "1. Sort descending the `med_tt` dataframe on `median_tt` and\n",
        "`n_stations_serving`.\n",
        "2. Take the top 20 records.\n",
        "3. Pass this dataframe to the function you wrote in [exercise 9](#exercise-9).\n",
        ":::"
      ],
      "id": "a09b401c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the code\"\n",
        "\n",
        "n_isolated = (\n",
        "    med_tts.dropna()\n",
        "    .sort_values([\"median_tt\", \"n_stations_serving\"], ascending=[False, False])\n",
        "    .head(20)\n",
        ")\n",
        "r = make_scatter_deck(n_isolated, radius=50, start_zoom=9.5)\n",
        "r"
      ],
      "id": "19701f3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips\n",
        "\n",
        "* Most of the packages used in this tutorial expect the sequence of coordinates\n",
        "to be long, lat. If you select an alternative method for mapping visuals,\n",
        "remember to check that this is consistent. If you are getting empty interactive\n",
        "map visuals, pan out and check if an incorrect coordinate specification has\n",
        "resulted in your points being rendered off the East coast of Africa.\n",
        "* The exception to the above rule is `haversine`, which expects lat, long.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "If you made it this far, well done! This tutorial has got you up and running\n",
        "with the r<sup>5</sup>py package. You have used several libraries in the\n",
        "python GIS stack to execute an analysis of bike station locations in London:\n",
        "\n",
        "* Station locations were ingested with TfL's api.\n",
        "* OpenStreetMap data was ingested from the BBBikes download service.\n",
        "* A point plane of your size was generated.\n",
        "* The coverage of the point plane was inspected.\n",
        "* The point plane features were adjusted to the underlying transport network.\n",
        "* Median travel times from bike stations to the point plane were calculated.\n",
        "* Travel times were summarised and features engineered for presentation in \n",
        "informative `pydeck` maps.\n",
        "\n",
        "Next steps for this work would be to explore how potential station locations\n",
        "could be informed by places where people would wish to commute, such as retail,\n",
        "businesses, tourist attractions and residential areas. OpenStreetMap files are\n",
        "a rich source of location data, which can be extracted with libraries such as\n",
        "[pyosmium](https://osmcode.org/pyosmium/). \n",
        "\n",
        "Service optimisation is an interesting area of operational research. This\n",
        "analysis does not consider local demand on the stations and their capacity to\n",
        "meet that demand. This sort of problem is known as the capacitated facility\n",
        "location problem and can provide operational efficiencies while improving\n",
        "service quality for the customer.\n",
        "\n",
        "<p id=fin><i>fin!</i></p>"
      ],
      "id": "2b03ceb1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "cycling-env",
      "language": "python",
      "display_name": "cycling-env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}