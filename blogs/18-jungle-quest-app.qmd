---
title: "Choose Your Own Adventure with ChatGPT"
author: "Rich Leyshon"
date: "September 21 2024"
description: "Iteratively Building an LLM-Powered Shiny Application."
categories:
    - Tutorial
    - Python Shiny
    - LLMs
    - Large Language Models
    - GenAI
    - Generative AI
    - Front End Dev
    - OpenAI
image: https://i.imgur.com/z9Xm9Lf.jpeg
image-alt: "Adventurer reading a large book within a mysterious jungle temple."
toc: true
css: /./www/17-quarto-comments/styles.css
code-annotations: select
---

<figure class=center>
 <img class=shaded_box src=https://i.imgur.com/z9Xm9Lf.jpeg alt="Adventurer reading within a jungle temple." width=120%>
</figure>

> "ChatGPT amplifies human potential, turning thoughts into creation. It
reminds us that imagination, when paired with technology, can shape the
future." ChatGPT on the creative potential of ChatGPT.

## Introduction

This article will guide you through the process of building a Choose Your
Own Adventure game using ChatGPT and Python Shiny. We'll walk through the
entire journey, from concept to deployment, with a focus on the iterative
development process and the use of ChatGPT for generating storylines.

Choose Your Own Adventure is a classic storytelling format where the reader
is presented with a series of choices that guide the story in different
directions. The game is interactive, allowing the reader to make decisions
that affect the outcome of the story. They were popular in the 1980s and
early 1990s, widely available as graphic novels and comics with a fantasy
or adventure theme.

The aim of this project is to produce an interactive application that will
put the OpenAI GPT-3.5-turbo model to work. The model will generate the
branching outcomes depending on the choices made by the user. We will
provide the user with an introduction to the theme and we will provide the
model with the rules for the game. Each game will play out differently
depending on the creative interplay between the user and the model.

::: {.callout-note collapse=true}

### Inspiration for This Blog (Click to expand)

The application concept was heavily influenced by the YouTube video by 
Tech with Tim called
<a href="https://www.youtube.com/watch?v=nhYcTh6vw9A" target="_blank">Python AI Choose Your Own Adventure Game - Tutorial</a>.
This tutorial uses a more complicated stack behind the scenes and resulted
in a game that solved itself - essentially the model would also generate
'imagined' user responses through to completion. The tutorial was published
only 11 months ago at the time of writing, though the code would not run
without significant wiggling, due to a raft of breaking changes within
langchain.

I was inspired by the playful use of generative AI but could see that a few
things could be done to improve the reproducibility of the code. Also, by 
simplifying the stack required to generate the game responses, it is hoped
that the risk of deprecation and breaking changes will be reduced,
increasing the longevity of the code. Finally, an application would be
needed in order to allow the human player and model to take turns in
playing the game. I have opted to use 
<a href="https://shiny.posit.co/py/" target="_blank">Shiny for Python</a>
in order to achieve this, though the same functionality could be achieved
with many other dashboarding solutions.

:::

### Intended Audience

Python programmers who are curious about building LLM-enabled applications.
Some familiarity with Shiny may be assumed. For an overview and intro to
building Shiny apps with Python, chack out my other blogs:

- [The State of Python Shiny](/blogs/01-state-of-pyshiny.qmd)
- [Let's Build a Basic Python Shiny App](/blogs/02-getting-started-pyshiny.qmd)

### What You'll Need

- [ ] Command line access
- [ ] Python know-how
  - [ ] Configure a virtual environment
  - [ ] Dependency management
- [ ] Basic knowledge of Python Shiny
- [ ] An OpenAI API key

```{.abc filename=requirements.txt}
openai==1.30.4
shiny==1.1.0
shinyswatch==0.7.0

```

:::{.callout collapse="true"}

### A Note on the Purpose (Click to expand)

This article intends to discuss clearly. It doesn't aim to be clever or
impressive. Its aim is to extend understanding without overwhelming the
reader. The code may not always be optimal, favouring a simplistic approach
wherever possible. The application may not be to your liking. The purpose
is to introduce a simple AI-driven applications rather than a masterpiece.
If you have ideas for improvements to the app or blog, please feel free to
leave a comment at then end of the article.

:::

The final application is presented below, hosted with
<a href="https://www.shinyapps.io/" target="_blank">shinyapps.io</a>.
Please note, this is not configured for high traffic. Let me know if the
app fails to launch for you by leaving a comment at the end of the blog.
You will need an OpenAI API key in order to prompt the model. The app has a
link to the sign up page if you would like to give it a try. If you would
prefer to read the source code for the application before proceeding with
the article, then please click on the GitHub icon at the top-right of the
application. If you would rather interact with the application in a
full-sized window, then visit the
<a href="https://richleysh84.shinyapps.io/choose-adventure/" target="_blank">Jungle Quest app on shinyapps.io</a>.
This app is set up to query the gpt-3.5-turbo model, but as you proceed
through the tutorial, feel free to experiment with other available models
(they can behave quite differently).

<iframe class=iframey src="https://richleysh84.shinyapps.io/choose-adventure/" style="overflow:hidden;margin:0;padding:0;width:100%;height:50rem"></iframe>

## Setting up the Development Environment

I'd recommend using VSCode with the
<a href="https://marketplace.visualstudio.com/items?itemName=Posit.shiny" target="_blank">Shiny extension</a>
to help run and debug the app. It has a super handy utility for launching
your app within the VSCode interface or expanding it to full screen in your
default browser. This is priceless when testing your User Interface's (UI)
appearance on different browsers.

You'll need to create and activate a virtual environment of your choice, I
have used python 3.12 in the examples without any issues. install the
dependencies listed in the `requirements.txt` file, and finally ensure that
VSCode is configured to
<a href="https://code.visualstudio.com/docs/python/environments" target="_blank">use the virtual environment</a>.

## Iterative Development

::: {.callout-caution}

Take care with your OpenAI APi credentials. I demonstrate hard-coding these
credentials within python scripts for simplicity. I'd advise storing them
in a git-ignored secrets file or using the
<a href=https://pypi.org/project/python-dotenv/ target="_blank">`python-dotenv`</a>
package to keep them safe. Take care not to accidentally commit these
credentials and expose them on GitHub. Leakage of OpenAI credentials is the
fastest-growing type of secret leak, according to
<a href=https://www.gitguardian.com/state-of-secrets-sprawl-report-2024 target="_blank">Git Guardian's State of Secret Sprawl 2024</a>.

Finally, please note that usage of the openai service associated with your
is associated to your account via your API key and should conform to the
service's usage policy.

:::

::: {.callout-tip}

### Code Annotations

By clicking on the numbered points within the code blocks, you should see
tooltips with additional explanations.

:::

::: {.panel-tabset #iterations}

Let's gradually build on the logic until we have a fully functional app.

### Iteration 1

In this early prototype, we will focus on using the openai python client
to send a basic prompt to the gpt-3.5-turbo model. 

```{.python filename=app.py}
"""Iteration 1: How to query the OpenAI API."""
import openai

API_KEY = "<INSERT_YOUR_KEY_HERE>"                                    # <1>


def query_openai(prompt: str, api_key: str) -> str:
    """Query the chat completions endpoint.

    Parameters
    ----------
    prompt: str
        The prompt to query the chat completions endpoint with.
    api_key: str
        The API key to use to query the chat completions endpoint.

    Returns
    -------
    str
        The response from the chat completions endpoint.
    """

    client = openai.OpenAI(api_key=api_key)                           # <2>
    # need to handle cases where queries go wrong.
    try:                                                              # <3>
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[                                                # <4>
                {"role": "user", "content": prompt}                   # <4>
            ]                                                         # <4>
        )
        return response.choices[0].message.content
    # in cases where the API key is invalid.
    except openai.AuthenticationError as e:
        raise ValueError(f"Is your API key valid?:\n {e}")



model_response = query_openai(
  prompt="What is the capital of the moon?", api_key=API_KEY
  )

```
1. Insert your API key into the API_KEY variable. Note - it's not advisable
to include your secret credentials in your python scripts like this, but
for simplicity's sake, I'm showing that here. I'd advise storing them in a
git-ignored secrets file or using the `python-dotenv` package to handle
keeping them safe. Take care not to accidentally commit these
credentials and expose them on GitHub.
2. Create a new OpenAI client with the api_key.
3. This will only pass if the key provided is valid.
4. Note the format of the messages - a list of dictionaries. The value for
role can be "user", "system" or "assistant".

The model responds with:

> The moon does not have a capital as it is not a sovereign nation or
political entity.

Let's summarise the process with a diagram:

![Process diagram for iteration 1](https://i.imgur.com/t15T2J3.png)

So far we have a basic `query_openai()` function that we can feed in a
prompt and our api key. We then receive a response back from the openai
model with the expected content.

Although this is an extremely simple process, it's great to start off with
the fundamentals. Understanding the structure of what's being sent and
received is useful when we begin embedding this logic into our Shiny app.

### Iteration 2

In this iteration, we are going to introduce a system message to help
guide the behaviour of the model - we will want it to act as the guide on
an adventure. We'll also need it to follow a few rules such as how to
indicate the game is over.

```{.python filename=app.py}
"""Iteration 2: Add system & welcome prompts."""
import openai

API_KEY = "<INSERT_YOUR_KEY_HERE>"
_SYSTEM_MSG = """
You are the guide of a 'choose your own adventure'- style game: a mystical
journey through the Amazon Rainforest. Your job is to create compelling
outcomes that correspond with the player's choices. You must navigate the
player through challenges, providing choices, and consequences, dynamically
adapting the tale based on the player's inputs. Your goal is to create a
branching narrative experience where each of the player's choices leads to
a new path, ultimately determining their fate. The player's goal is to find
the lost crown of Quetzalcoatl.

Here are some rules to follow:
1. Always wait for the player to respond with their input before providing  # <1>
any choices. Never provide the player's input yourself. This is most        # <1>
important.                                                                  # <1>
2. Ask the player to provide a name, gender and race.
3. Ask the player to choose from a selection of weapons that will be used
later in the game.
4. Have a few paths that lead to success. 
5. Have some paths that lead to death.
6. Whether or not the game results in success or death, the response must   # <2>
include the text "The End...", I will search for this text to end the game. # <2>
"""

WELCOME_MSG = """
Welcome to the Amazon Rainforest, adventurer! Your mission is to find the   # <3>
lost Crown of Quetzalcoatl.                                                 # <3>
However, many challenges stand in your way. Are you brave enough, strong    # <3>
enough and clever enough to overcome the perils of the jungle and secure    # <3>
the crown?                                                                  # <3>
                                                                            # <3>
Before we begin our journey, choose your name, gender and race. Choose a    # <3>
weapon to bring with you. Choose wisely, as the way ahead is filled with    # <3>
many dangers.                                                               # <3>
"""                                                                         # <3>


def query_openai(
        prompt: str,
        api_key: str,
        sys_prompt:str = _SYSTEM_MSG,
        start_prompt:str = WELCOME_MSG,
        ) -> str:
    """Query the chat completions endpoint.

    Parameters
    ----------
    prompt: str
        The prompt to query the chat completions endpoint with.
    api_key: str
        The API key to use to query the chat completions endpoint.
    sys_prompt: str
        The system prompt to help guide the model behaviour. By default,
        the system prompt is set to _SYSTEM_MSG.
    start_prompt: str
        The start prompt which will be presented to the user as the app
        begins. By default, the start prompt is set to WELCOME_MSG.

    Returns
    -------
    str
        The response from the chat completions endpoint.
    """

    client = openai.OpenAI(api_key=api_key)
    # need to handle cases where queries go wrong.
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[                                                      # <4>
                {"role": "system", "content": sys_prompt},                  # <4>
                {"role": "assistant", "content": start_prompt},             # <4>
                {"role": "user", "content": prompt},                        # <4>
            ]                                                               # <4>
        )
        return response.choices[0].message.content
    # in cases where the API key is invalid.
    except openai.AuthenticationError as e:
        raise ValueError(f"Is your API key valid?:\n {e}")


model_response = query_openai(
    prompt="What is the capital of the moon?",
    api_key=API_KEY
    )

```
1. Certain models can get a bit over-zealous and start providing imagined
user input, ultimately playing the game thorugh to completion on their own.
As games go, that's not that fun, so let's try to safeguard against that
behaviour with these explicit instructions.
2. The gpt-3.5-turbo model seems to be pretty reliable at ending the game
with the required pattern "The end...". We'll later search for this pattern
to exit the app and return a message indicating game over. Interestingly, 
I found gpt-4 models to be fairly unreliable in following this instruction.
All of the models can be configured to stream their responses too, in which
case they rarely gave the specified game over pattern. I'd be interested in
others' opinions as to why this may be the case. Please feel free to leave
a comment at the end of the article if you have an opinion.
3. This welcome message will be used to introduce the game context for our
users when the app launches. We will append this into the message stream
and simulate our LLM greeting our user. We will also include this message
when querying the model, where it will serve as what's known as a one-shot
prompt to help guide the model's behaviour. A one-shot prompt is an example
of how you'd like the model to behave.
4. We now update the messages stream with our hard-coded prompt. This helps
to guide both the model and the user, setting context and modelling the
desired behaviour.

Thanks to the guidance in the hard-coded prompts, our model now behaves a
bit differently:

> I'm afraid the Moon doesn't have a capital city like countries on Earth
do! Let's focus on our adventure in the Amazon Rainforest. To begin, please
choose your name, gender, and race. Additionally, select a weapon to arm
yourself with on this mystical journey. The fate of finding the lost Crown
of Quetzalcoatl awaits your choices!

Notice that the model still answers the question, but guides the user back
to the purpose of the app. In a later iteration, we will see how to
introduce moderations as a safeguard against the user passing inappropriate
content.

Finally, updating our process diagram to include the additional prompts, I
have emphasised the changes implemented within this iteration. As we
proceed, the diagram's complexity will increase and therefore I'll try to
emphasise the changes implemented over the previous iteration only:

![Process diagram for iteration 2](https://i.imgur.com/6vuOSp5.png)

### Iteration 3

In this iteration, we'll put together the basic UI for the app. The UI
needs a text field to pass the user's API key and the chat component. Let's
update the app script to include the shiny UI.

```{.python filename="app.py"}
"""Iteration 3: A basic user interface with no server logic."""
import openai
from shiny import App, ui

_SYSTEM_MSG = """
You are the guide of a 'choose your own adventure'- style game: a mystical
journey through the Amazon Rainforest. Your job is to create compelling
outcomes that correspond with the player's choices. You must navigate the
player through challenges, providing choices, and consequences, dynamically
adapting the tale based on the player's inputs. Your goal is to create a
branching narrative experience where each of the player's choices leads to
a new path, ultimately determining their fate. The player's goal is to find
the lost crown of Quetzalcoatl.

Here are some rules to follow:
1. Always wait for the player to respond with their input before providing
any choices. Never provide the player's input yourself. This is most
important.
2. Ask the player to provide a name, gender and race.
3. Ask the player to choose from a selection of weapons that will be used
later in the game.
4. Have a few paths that lead to success. 
5. Have some paths that lead to death.
6. Whether or not the game results in success or death, the response must
include the text "The End...", I will search for this text to end the game.
"""

WELCOME_MSG = """
Welcome to the Amazon Rainforest, adventurer! Your mission is to find the
lost Crown of Quetzalcoatl.
However, many challenges stand in your way. Are you brave enough, strong
enough and clever enough to overcome the perils of the jungle and secure
the crown?

Before we begin our journey, choose your name, gender and race. Choose a
weapon to bring with you. Choose wisely, as the way ahead is filled with
many dangers.
"""


def query_openai(
        prompt: str,
        api_key: str,
        sys_prompt:str = _SYSTEM_MSG,
        start_prompt:str = WELCOME_MSG,
        ) -> str:
    """Query the chat completions endpoint.

    Parameters
    ----------
    prompt: str
        The prompt to query the chat completions endpoint with.
    api_key: str
        The API key to use to query the chat completions endpoint.
    sys_prompt: str
        The system prompt to help guide the model behaviour. By default,
        the system prompt is set to _SYSTEM_MSG.
    start_prompt: str
        The start prompt which will be presented to the user as the app
        begins. By default, the start prompt is set to WELCOME_MSG.

    Returns
    -------
    str
        The response from the chat completions endpoint.
    """

    client = openai.OpenAI(api_key=api_key)
    # need to handle cases where queries go wrong.
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": sys_prompt},
                {"role": "assistant", "content": start_prompt},
                {"role": "user", "content": prompt},
            ]
        )
        return response.choices[0].message.content
    # in cases where the API key is invalid.
    except openai.AuthenticationError as e:
        raise ValueError(f"Is your API key valid?:\n {e}")


# Shiny User Interface ----------------------------------------------------

app_ui = ui.page_fillable(                                                  # <1>
    ui.panel_title("Choose Your Own Adventure: Jungle Quest!"),
    ui.accordion(                                                           # <2>
    ui.accordion_panel("Step 1: Your OpenAI API Key",
        ui.input_text(id="key_input", label="Enter your openai api key"),   # <3>
    ), id="acc", multiple=False),
    ui.chat_ui(id="chat"),                                                  
    fillable_mobile=True,
)

app = App(app_ui, server=None)                                              # <4>
```
1. `ui.page_fillable()` Works well with a chat component, increasing the
height of your app to accommodate a growing chat log.
2. The `ui.accordion()` component will present a collapsible panel. This
will be useful for the key input panel - we can minimise this portion of
our app and focus on the chat.
3. In `shiny` UI elements, the first argument is usually the `id`. If you
know CSS and HTML, then it's the same `id` you'd target for styling an
element. It's really important in `shiny` as the server logic we'll write
later will communicate data to the UI via these `id` values. Make sure the
`id` values are unique and do not include hyphens - use underscores
instead. Shiny will raise the following error if you attempt to use
`id="row-1"` for example:
`ValueError: The string 'row-1' is not a valid id; only letters, numbers, and underscore are permitted` 
4. In this final step, we need to combine our UI with server logic to make
things work. As we haven't written any server logic yet, we can just pass
`None`. This means our UI won't do anything in its current state.

Feel free to play around with the code and re-run the app using the play
icon in the top-right corner of `app.py`. This interface uses the
<a href="https://shinylive.io/py/examples/" target="_blank">shinylive service</a>
which is useful for sharing simple shiny apps without any need for python
installations.

<iframe src=https://shinylive.io/py/editor/#code=NobwRAdghgtgpmAXGKAHVA6VBPMAaMAYwHsIAXOcpMAMwCdiYACAZwAsBLCbJjmVYnTJMAgujxMArhwA6EOWlQB9aUwC8UjligBzOEpocANkagAjI3AAUcpnc3aIcI0rIcylm2ADCbYsRY4JgBNYkk6JgB5AHcIUQATADdKMnC4RCYAKUkIHUsmAEVJOBYyAEIZMABKPFt7aQwoQhI6eI5SGzj6rSaWttIlVCgnIy8AZQpUJgBGDNDwqNRKEQBJUQAFNYBpOGxK2q77bowuVEkyVzgADzIrDni1SoBrXaVT8-2mUzNnR7AAUXIcAi2DCEWIS2gHCYaGhLz21QORxqvAelV6nxgkiMblQljUADEoEZAjU6nYGoQ2FALtI7miiNSyJUyYcmIYTOZLEoYMQzMY4GoACp0YoHKpyBTodSidBWRQqDgSQJ0ZJ0NQAOVIcAlEDAAF8ALpAA class=iframey style="overflow:hidden;margin:0;padding:0;width:100%;height:30rem"></iframe>

The process diagram for our app so far looks like this:

![Process diagram for iteration 3](https://i.imgur.com/ToBp4iQ.png)

Our logic for talking to the OpenAI model has not yet been coupled with our
UI. We'll fold that logic into our shiny server in the next iteration.

### Iteration 4

In this part, we'll take the logic from our `query_openai()` function
defined in iteration 1 and use it to build our shiny server. The shiny
server is typically referenced as the "backend" to our app.

```{.python filename="app.py"}
"""Iteration 4: Server logic allows us to create a chat log."""
import openai
from shiny import App, ui

_SYSTEM_MSG = """
You are the guide of a 'choose your own adventure'- style game: a mystical
journey through the Amazon Rainforest. Your job is to create compelling
outcomes that correspond with the player's choices. You must navigate the
player through challenges, providing choices, and consequences, dynamically
adapting the tale based on the player's inputs. Your goal is to create a
branching narrative experience where each of the player's choices leads to
a new path, ultimately determining their fate. The player's goal is to find
the lost crown of Quetzalcoatl.

Here are some rules to follow:
1. Always wait for the player to respond with their input before providing
any choices. Never provide the player's input yourself. This is most
important.
2. Ask the player to provide a name, gender and race.
3. Ask the player to choose from a selection of weapons that will be used
later in the game.
4. Have a few paths that lead to success. 
5. Have some paths that lead to death.
6. Whether or not the game results in success or death, the response must
include the text "The End...", I will search for this text to end the game.
"""

WELCOME_MSG = """
Welcome to the Amazon Rainforest, adventurer! Your mission is to find the
lost Crown of Quetzalcoatl.
However, many challenges stand in your way. Are you brave enough, strong
enough and clever enough to overcome the perils of the jungle and secure
the crown?

Before we begin our journey, choose your name, gender and race. Choose a
weapon to bring with you. Choose wisely, as the way ahead is filled with
many dangers.
"""

# compose a message stream
_SYS = {"role": "system", "content": _SYSTEM_MSG}
_WELCOME = {"role": "assistant", "content": WELCOME_MSG}
stream = [_SYS, _WELCOME]                                                   # <1>

# Shiny User Interface ----------------------------------------------------

app_ui = ui.page_fillable(
    ui.panel_title("Choose Your Own Adventure: Jungle Quest!"),
    ui.accordion(
    ui.accordion_panel("Step 1: Your OpenAI API Key",
        ui.input_text(id="key_input", label="Enter your openai api key"),
    ), id="acc", multiple=False),
    ui.chat_ui(id="chat"),
    fillable_mobile=True,
)

# Shiny server logic ------------------------------------------------------


def server(input, output, session):
    chat = ui.Chat(                                                         # <2>
        id="chat", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None      # <2>  
        )                                                                   # <2>
    

    # Define a callback to run when the user submits a message
    @chat.on_user_submit
    async def respond():                                                    # <3>
        """Respond to the user's message."""
        # Get the user's input
        user = chat.user_input()
        #  update the stream list
        stream.append({"role": "user", "content": user})                    # <1>
        # Append a response to the chat
        client = openai.AsyncOpenAI(api_key=input.key_input())              # <4>
        response = await client.chat.completions.create(                    # <5>
            model="gpt-3.5-turbo",
            messages=stream,
            temperature=0.7, # increase to make the model more creative
            )
        model_response = response.choices[0].message.content
        await chat.append_message(model_response)                           # <5>
        #  if the model indicates game over, end the game with a message.
        if "the end..." in model_response.lower():                          # <6>
            await chat.append_message(                                      # <6>
                {                                                           # <6>
                    "role": "assistant",                                    # <6>
                    "content": "Game Over! Refresh the page to play again." # <6>
                    })                                                      # <6>
            exit()                                                          # <6>
        else:
            stream.append({"role": "assistant", "content": model_response}) # <1>


app = App(ui=app_ui, server=server)

```
1. To keep a running log of what's been said, we assign chat messages to
a `stream` list. When the user and model respond, we'll dump that content
as a dictionary at the end of this list.
2. Here we create the backend to our `shiny` chat interface. It's vital
that it has the same `id` value as the `ui.chat_ui()` element defined in
our UI in iteration 3. This connection will allow the backend and frontend
to communicate when we run the app.
3. We use async here because:\n
        1. It allows the function to perform I/O operations
        (like API calls) without blocking the entire application.
        2. It improves responsiveness, especially when dealing with
        potentially slow network requests to the OpenAI API.
        3. It works well with Shiny's event-driven architecture, allowing
        other parts of the app to remain interactive while waiting for the
        API response.
4. We've now switched over the the OpenAI Async client. This is better
for working with event driven apps like this one. We no longer hard-code an
API key. Instead, we'll take the value from the `ui.input_text()` field.
Notice that we reference the `id` value that we set when we defined the UI
like a method: `input.key_input()`. This is how `shiny` apps wire the 
frontend and backend together.
5. We need to use `await` for these parts of our server logic. This is
because the model response typically takes some time to arrive and parts of
the server would error until they receive it. Typically, anything that
would raise an exception rather than returning `None` you'll need to
`await`.
6. This part of our server is where we end the game. Notice that this is
dependent on our model following rule 6 in `_SYSTEM_MSG`. Not all models
are great at following that instruction. At the time of writing this blog,
I've tested `gpt-3.5-turbo`, `gpt-4o` and `chatgpt-4o-latest`. In my
testing I found `gpt-3.5-turbo` to be the most reliable at following this
rule. But when I tested streaming the model responses, no models would end
the game as requested. This is definitely the most flaky element of this
app and is part of the fun of working with these models.

Now adding in the server logic for our process diagram, note that I have
added a key that illustrates wherever we instantiate an openai client in
the app. As we continue to build, handling the client becomes a bit
involved so let's start paying attention to wherever we're using it:

![Process diagram for iteration 4](https://i.imgur.com/46mqCrY.png)

You can see that the `respond()` function has become the busiest unit in
the app. It takes the api key value from our UI, combines the users's
messages sent from the chat UI, combines these with the chat stream and
communicates with the OpenAI model. Now these components are all wired up
we get a running application. If you've made it this far - well done!

You can see me interacting with the resultant app in the video below. Note
that I cannot use shinylive to host a working version of this iteration as
unfortunately the `openai` package is not available on that service. 

:::{.callout-important}

I use a real OpenAI API key in these clips to demonstrate the application
working. Note that I have since revoked this key and it will no longer
work. You should not share your secret keys with anyone.

:::

<iframe title="Iteration 4 recording" src="https://player.vimeo.com/video/1010110793?h=133c2b081d" class=iframey allowfullscreen style="overflow:hidden;margin:0;padding:0;width:100%;height:24rem;"></iframe>

Notice that I attempt to use a nonsense key value and we get a
nasty-looking error. Luckily, it's not a fatal one - the app doesn't crash.
But we should think about handling cases where the key is bad and giving a
more accessible notification to the user. 

### Iteration 5

In this version, we build on our working app to improve the user
experience. We'll add a 'submit' button, which the user can use when
they're ready to use their key. We also provide some notifications to the
user when they submit their key, but we won't be checking whether the key
is valid until the next iteration.

```{.python filename="app.py"}
"""Iteration 5: Submit button & notifications for the user."""
import openai
from shiny import App, reactive, ui

_SYSTEM_MSG = """
You are the guide of a 'choose your own adventure'- style game: a mystical
journey through the Amazon Rainforest. Your job is to create compelling
outcomes that correspond with the player's choices. You must navigate the
player through challenges, providing choices, and consequences, dynamically
adapting the tale based on the player's inputs. Your goal is to create a
branching narrative experience where each of the player's choices leads to
a new path, ultimately determining their fate. The player's goal is to find
the lost crown of Quetzalcoatl.

Here are some rules to follow:
1. Always wait for the player to respond with their input before providing
any choices. Never provide the player's input yourself. This is most
important.
2. Ask the player to provide a name, gender and race.
3. Ask the player to choose from a selection of weapons that will be used
later in the game.
4. Have a few paths that lead to success. 
5. Have some paths that lead to death.
6. Whether or not the game results in success or death, the response must
include the text "The End...", I will search for this text to end the game.
"""

WELCOME_MSG = """
Welcome to the Amazon Rainforest, adventurer! Your mission is to find the
lost Crown of Quetzalcoatl.
However, many challenges stand in your way. Are you brave enough, strong
enough and clever enough to overcome the perils of the jungle and secure
the crown?

Before we begin our journey, choose your name, gender and race. Choose a
weapon to bring with you. Choose wisely, as the way ahead is filled with
many dangers.
"""

# compose a message stream
_SYS = {"role": "system", "content": _SYSTEM_MSG}
_WELCOME = {"role": "assistant", "content": WELCOME_MSG}
stream = [_SYS, _WELCOME]

# Shiny User Interface ----------------------------------------------------


def input_text_with_button(id, label, button_label, placeholder=""):        # <1>
    """
    An interface component combining an input text widget with an action
    button. IDs for the text field and button can be accessed as <id>_text
    and <id>_btn respectively.
    """
    return ui.div(
        ui.input_text(
            id=f"{id}_text", label=label, placeholder=placeholder),         # <2>
        ui.input_action_button(                                             # <2>
            id=f"{id}_btn",                                                 # <2>
            label=button_label,
            style="margin-top:28px;margin-bottom:16px;color:#04bb8c;border-color:#04bb8c;" # <3>
            ),
        class_="d-flex gap-2"
    )


app_ui = ui.page_fillable(
    ui.panel_title("Choose Your Own Adventure: Jungle Quest!"),
    ui.accordion(
    ui.accordion_panel("Step 1: Your OpenAI API Key",
        input_text_with_button(                                             # <4>
            id="key_input",                                                 # <4>
            label="Enter your OpenAI API key",                              # <4>
            button_label="Submit",                                          # <4>
            placeholder="Enter key here"                                    # <4>
            )), id="acc", multiple=False),
ui.h6("Step 2: Choose your adventure"),
    ui.chat_ui(id="chat"),
    fillable_mobile=True,
)

# Shiny server logic ------------------------------------------------------


def server(input, output, session):
    chat = ui.Chat(
        id="chat", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None
        )


    @reactive.Effect                                                        # <5>
    @reactive.event(input.key_input_btn)                                    # <5>
    def handle_api_key_submit():                                            # <5>
        """Update the UI with a notification when user submits key."""      # <5>
        api_key = input.key_input_text()                                    # <5>
        if api_key:                                                         # <5>
            ui.notification_show(f"API key submitted: {api_key[:5]}...")    # <5>
        else:                                                               # <5>
            ui.notification_show("Please enter an API key", type="warning") # <5>


    # Define a callback to run when the user submits a message
    @chat.on_user_submit
    async def respond():
        """Respond to the user's message."""
        # Get the user's input
        user = chat.user_input()
        #  update the stream list
        stream.append({"role": "user", "content": user})
        # Append a response to the chat
        client = openai.AsyncOpenAI(api_key=input.key_input_text())
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=stream,
            temperature=0.7, # increase to make the model more creative
            )
        model_response = response.choices[0].message.content
        await chat.append_message(model_response)
        #  if the model indicates game over, end the game with a message.
        if "the end..." in model_response.lower():
            await chat.append_message(
                {
                    "role": "assistant",
                    "content": "Game Over! Refresh the page to play again."
                    })
            exit()
        else:
            stream.append({"role": "assistant", "content": model_response})


app = App(ui=app_ui, server=server)

```
1. Here we define a new function that's used to conveniently return a text
field and an action button together. This is what we'll use for the key
input going forward.
2. Notice that the `id` value that we'll pass into
`input_text_with_button()` will return seperate unique `id values` for the
text field and action button.
3. Feel free to experiment with styling any elements with CSS. If you'd
rather not have inline CSS, you can move the styling into a dedicated CSS
file and apply it with classes or IDs to the elements in your UI.
4. We replace the text field of previous iterations with our new
`input_text_with_button()` text field action button combo.
5. In the server, we define a new function that will run whenever the
action button with `id=input.key_input_btn` is clicked by the user. If
there's a value that's been submitted we're going to place a confirmation
notification on the UI. If not, we'll raise a warning to the user to remind
them to submit their key.

I've added a marker in the process diagram to remind us that
`handle_api_key_submit()` will run as a reactive event when the key is
submitted. This is going to update the UI with feedback notifications.

![Process diagram for iteration 5](https://i.imgur.com/lU743ra.png)

:::{.callout-tip}

Using `ui_notification_show()` is a really useful method for debugging
reactive values when your app breaks. Use it to check on intermediate
values that the frontend receives from the backend.

:::

:::{.callout-important}

I use a real OpenAI API key in these clips to demonstrate the application
working. Note that I have since revoked this key and it will no longer
work. You should not share your secret keys with anyone.

:::

In the recording below you can see the new action button and the UI
notifications being returned by the server. However, note that I still get
that nasty red error when I pass an invalid key. In the next iteration,
we'll determine whether the user has used a valid key.

<iframe title="Iteration 5 recording" src="https://player.vimeo.com/video/1010111488?h=f74e808099" class=iframey allowfullscreen style="overflow:hidden;margin:0;padding:0;width:100%;height:24rem;"></iframe>

### Iteration 6

In this version of the app we will introduce more backend logic that will
check whether the key the user has submitted is a valid one. 

```{.python filename="app.py"}
"""Iteration 6: Check the key is valid."""
import openai
from shiny import App, reactive, ui

_SYSTEM_MSG = """
You are the guide of a 'choose your own adventure'- style game: a mystical
journey through the Amazon Rainforest. Your job is to create compelling
outcomes that correspond with the player's choices. You must navigate the
player through challenges, providing choices, and consequences, dynamically
adapting the tale based on the player's inputs. Your goal is to create a
branching narrative experience where each of the player's choices leads to
a new path, ultimately determining their fate. The player's goal is to find
the lost crown of Quetzalcoatl.

Here are some rules to follow:
1. Always wait for the player to respond with their input before providing
any choices. Never provide the player's input yourself. This is most
important.
2. Ask the player to provide a name, gender and race.
3. Ask the player to choose from a selection of weapons that will be used
later in the game.
4. Have a few paths that lead to success. 
5. Have some paths that lead to death.
6. Whether or not the game results in success or death, the response must
include the text "The End...", I will search for this text to end the game.
"""

WELCOME_MSG = """
Welcome to the Amazon Rainforest, adventurer! Your mission is to find the
lost Crown of Quetzalcoatl.
However, many challenges stand in your way. Are you brave enough, strong
enough and clever enough to overcome the perils of the jungle and secure
the crown?

Before we begin our journey, choose your name, gender and race. Choose a
weapon to bring with you. Choose wisely, as the way ahead is filled with
many dangers.
"""

# compose a message stream
_SYS = {"role": "system", "content": _SYSTEM_MSG}
_WELCOME = {"role": "assistant", "content": WELCOME_MSG}
stream = [_SYS, _WELCOME]

# Shiny User Interface ----------------------------------------------------


def input_text_with_button(id, label, button_label, placeholder=""):
    """
    An interface component combining an input text widget with an action
    button. IDs for the text field and button can be accessed as <id>_text
    and <id>_btn respectively.
    """
    return ui.div(
        ui.input_text(
            id=f"{id}_text", label=label, placeholder=placeholder),
        ui.input_action_button(
            id=f"{id}_btn",
            label=button_label,
            style="margin-top:28px;margin-bottom:16px;color:#04bb8c;border-color:#04bb8c;"
            ),
        class_="d-flex gap-2"
    )


app_ui = ui.page_fillable(
    ui.panel_title("Choose Your Own Adventure: Jungle Quest!"),
    ui.accordion(
    ui.accordion_panel("Step 1: Your OpenAI API Key",
        input_text_with_button(
            id="key_input",
            label="Enter your OpenAI API key",
            button_label="Submit",
            placeholder="Enter key here"
            )), id="acc", multiple=False),
ui.h6("Step 2: Choose your adventure"),
    ui.chat_ui(id="chat"),
    fillable_mobile=True,
)

# Shiny server logic ------------------------------------------------------


def server(input, output, session):
    chat = ui.Chat(
        id="chat", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None
        )

    @reactive.Effect
    @reactive.event(input.key_input_btn)
    async def handle_api_key_submit():
        """Update the UI with a notification when user submits key.
        
        Checks the validity of the API key by querying the models list
        endpoint."""
        api_key = input.key_input_text()
        client = openai.AsyncOpenAI(api_key=api_key)                        # <1>
        try:
            resp = await client.models.list()                               # <2>
            if resp:
                ui.notification_show(
                    f"API key validated: {api_key[:5]}...")
        except openai.AuthenticationError as e:                             # <3>
            ui.notification_show(
                "Bad key provided. Please try again.", type="warning")


    # Define a callback to run when the user submits a message
    @chat.on_user_submit
    async def respond():
        """Respond to the user's message."""
        # Get the user's input
        user = chat.user_input()
        #  update the stream list
        stream.append({"role": "user", "content": user})
        # Append a response to the chat
        client = openai.AsyncOpenAI(api_key=input.key_input_text())
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=stream,
            temperature=0.7, # increase to make the model more creative
            )
        model_response = response.choices[0].message.content
        await chat.append_message(model_response)
        #  if the model indicates game over, end the game with a message.
        if "the end..." in model_response.lower():
            await chat.append_message(
                {
                    "role": "assistant",
                    "content": "Game Over! Refresh the page to play again."
                    })
            exit()
        else:
            stream.append({"role": "assistant", "content": model_response})


app = App(ui=app_ui, server=server)

```
1. Notice that we are now creating another openai client. This is so that
we can test the key to see whether it successfully queries the openai
service, before using it to play the game. Initiating multiple clients is
not needed and is inefficient design. In a later iteration we'll come back
to this.
2. This time we'll query the `models.list()` endpoint to get a list of
models available. There is currently no OpenAI endpoint for explicitly
checking whether a service is valid. OpenAI API support team responded to
my support ticket to suggest this as the best method for ensuring the
submitted key is valid.
3. In cases where a bad key is provided, we can avoid the
`openai.AuthenticationError` and print a warning to the UI instead.

In our increasingly complex process diagram, I've emphasised that
`handle_api_key_submit()` now instantiates another client object and uses
it to query the `models.list` endpoint of the OpenAI service.

![Process diagram for iteration 6](https://i.imgur.com/Tb7jjeK.png)

:::{.callout-important}

I use a real OpenAI API key in these clips to demonstrate the application
working. Note that I have since revoked this key and it will no longer
work. You should not share your secret keys with anyone.

:::

In the recording below I demonstrate how this version of the app will
return a warning to the user if the submitted key was not valid.

<iframe title="Iteration 6 recording" src="https://player.vimeo.com/video/1010111977?h=b625a6f9ef" class=iframey allowfullscreen style="overflow:hidden;margin:0;padding:0;width:100%;height:24rem;"></iframe>

### Iteration 7

Now we introduce a moderations feature that will check that the prompts
being passed from the user to the OpenAI service comply with the service's
usage policies. Forewarned - this is far from perfect!

In general, it's pretty good but if you're intentionally trying to test it
like I did when implementing this feature, you can find some funny quirks.
British expletives tend to sail through unchallenged and at times my test
prompts were raised as violations for stating things like "Let's fight!"
(category: harassment) when that was one of the options provided to me by
the model! It's likely that passing greater context to the moderations
endpoint (such as more of the message stream) may be able to overcome this,
though that has not been implemented for this tutorial.

:::{.callout-caution}

Use of your API credentials are subject to the OpenAI usage policy, please
remember this while using the app. In the video, I use the most benign
example of a statement that reliably violates OpenAI's moderations service:
"kill, kill, kill".

:::

### Iteration 8

### Iteration 9

:::

[Click to return to the start of iteration tabsets](#iterations)

## 8. Final Touches and Deployment
- **Polishing the app**
  - Any last steps before deploying: Testing, UI tweaks, refining the game logic.
- **Deploying the App**
  - Link to deployment file and backlink t deploying to shinyapps.io blog.

## Conclusion
- Recap the journey of building the app, from idea to deployment.
- Mention potential future improvements (e.g., adding more complex storylines, user authentication, etc.).
- Invite readers to try out the app or explore the code on GitHub.

## Call to Action
- **GitHub Link**: Provide a link to the source code repository.
- **Demo Link**: If applicable, include a link to a live version of the app.
- **Invitation for Feedback**: Encourage readers to share their thoughts or improvements in the comments.

If you spot an error with this article, or have a suggested improvement then
feel free to leave a comment (GitHub login required) or
[raise an issue on GitHub](https://github.com/r-leyshon/blogging/issues).  

<p id=fin><i>fin!</i></p>
