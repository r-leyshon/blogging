---
title: "The Fiddly Bits of Pytest"
author: "Rich Leyshon"
date: "March 24 2024"
description: "Plain English discussion of the more intrictate aspects of testing with pytest."
categories:
    - Explanation
    - pytest
    - Unit tests
image: "https://images.pixexid.com/sculptural-simplicity-monochrome-background-highlighting-the-beauty-of-minimali-jmhkipzb.jpeg?h=699&amp;q=70"
image-alt: "Sculptural simplicity, monochrome background highlighting the beauty of minimalist sculptures by [Ralph](https://pixexid.com/profile/cjxrsxsl7000008s6h21jecoe)"
toc: true
---

<figure class=center>
  <img class="shaded_box" width=400px src="https://images.pixexid.com/sculptural-simplicity-monochrome-background-highlighting-the-beauty-of-minimali-jmhkipzb.jpeg"></img>
  <figcaption style="text-align:center;">Creative commons license by [Ralph](https://pixexid.com/profile/cjxrsxsl7000008s6h21jecoe)</figcaption>
</figure>

## Introduction

`pytest` is a testing package for the python framework. It is broadly used to
quality assure code logic. This article discusses some of the more intricate
features of `pytest`, favouring accessible language and simple examples to
describe the scenarios.


- <a href="https://docs.pytest.org/en/8.0.x/" target="_blank">Pytest documentation</a>

:::{.callout collapse="true"}

### A Note on the Purpose (Click to expand)

This article intends to discuss clearly. It doesn't aim to be clever or
impressive. Its aim is to extend the audience's understanding of the more
intricate features of `pytest` by describing their utility with simple code
examples.  

:::

### Intended Audience

Programmers with a working knowledge of python and some familiarity with
`pytest` and packaging. The type of programmer who has wondered about how to
mock an api call or how to optimise their test code.

### What You'll Need:

- [ ] Preferred python environment manager (eg `conda`)
- [ ] `pip install pytest==8.1.1`
- [ ] Git
- [ ] GitHub account
- [ ] Command line access

### Preparation

This blog is accompanied by code in
[this repository](https://github.com/r-leyshon/pytest-fiddly-examples). The
main branch provides a template with the minimum structure and requirements
expected to run a `pytest` suite. The repo branches contain the code used in
the examples of the following sections.

Feel free to fork or clone the repo and checkout to the example branches as
needed.

## Fixtures

The example code that accompanies this section is available in the fixtures
branch of the 
[example code repo](https://github.com/r-leyshon/pytest-fiddly-examples/tree/fixtures).

### What are fixtures?

Data. Well, data provided specifically for testing purposes. This is the
essential definition for a fixture. One could argue the case that fixtures are
more than this. Fixtures could be environment variables, class instances,
connection to a server or whatever dependencies your code needs to run.

I would agree that fixtures are not just data. But that all fixtures return
data of some sort, regardless of the system under test.

### When would you use fixtures?

It's a bad idea to commit data to a git version-controlled repository, right?
Agreed. Though fixtures are rarely 'real' data. The data used for testing
purposes should be minimal and are usually synthetic. 

**Minimal fixtures** conform to the schema of the actual data under test.
These fixtures will be as small as possible while capturing all known important
cases. Keeping the data small maintains a performant test suite and avoids
problems associated with large files and git version control.

If you have ever encountered a problem in a system that was caused by a
problematic record in the data, the aspect of that record that broke your
system should absolutely make it into the next version of your minimal test
fixture. Writing a test that checks that the codebase can handle such problem
records is known as 'regression testing' - safeguarding against old bugs
resurfacing when code is refactored or new features are implemented. This
scenario commonly occurs when a developer unwittingly violates Chesterton's
Principle.


<iframe src="https://www.youtube.com/embed/qPGbl2gxGqI" class="shaded-box" title="Chesterton's Fence by Sprouts" style="display: block; width: 600px; height: 338px" frameborder="0">
</iframe>

Many thanks to my colleague Mat for pointing me towards this useful analogy. A
considerate developer would probably include a comment in their code about a
specific problem that they've handled (like erecting a sign next to
Chesterton's fence). An experienced developer would do the same, and also write
a regression test to ensure the problem doesn't re-emerge in the future
(monitoring the fence with CCTV...). Discovering these problem cases and
employing defensive strategies avoids future pain for yourself and colleagues.

As you can imagine, covering all the important cases and keeping the fixture
minimal are a compromise. At the outset of the work, it may not be obvious what
problematic cases may arise. Packages such as
[`hypothesis`](https://hypothesis.readthedocs.io/en/latest/) allow you to
generate awkward cases. Non-utf-8 strings anyone? Hypothesis can generate
these test cases for you - *ƒÉ—£ùî†’Æ·ªÅ≈øƒ£»ü·é•ùíã«©ƒæ·∏øÍûë»Øùò±ùëûùóãùò¥»∂ùûÑùúàœàùíôùòÜùö£*.

**Non-disclosive fixtures** are those that do not expose personally
identifiable or commercially-sensitive information. If you are working with
this sort of data, it is necessary to produce toy test fixtures that mimic the
schema of the real data. Names and addresses can be de-identified to random
alphanumeric strings. Location data can be adjusted with noise. The use of
dummy variables or categories can mitigate the risk of disclosure by
differencing.

By adequately anonymising data and testing problem cases, the programmer
exhibit their duty to upholding organisational duty to the General Data
Protection Regulation, specifically to the duties to accurately store, process,
retain and erase personally-identifiable information.

In cases where system integrates with data available in the public domain, it
is may be permissable to include a small sample of the data as a test fixture.
Ensure the license that the data is distributed under is compatible with your
code's license. If the license is compatible, I recommend including a reference
to the fixture, its source and license within a LICENSE.note file. This
practice is enforced by Comprehensive R Archive Network. You can read more about
this in the
[R Packages documentation](https://r-pkgs.org/license.html#sec-how-to-include).

### Scoping Fixtures

Pytest fixtures have different scopes, meaning that they will be prepared
differently dependent on the scope you specify. The avalable scopes are as
follows. 

| Scope Name  | Teardown after each |
| ----------- | ------------------- |
| function    | test function       |
| class       | test class          |
| module      | test module         |
| session     | pytest session      |

Note that the default scope for any fixtures that you define will be
'function'. A function-scoped fixture will be set up for every test function
that requires it. Once the function has executed, the fixture will then be
torn down and all changes to this fixture will be lost. This default behaviour
encourages isolation in your test suite. Meaning that the tests have no
dependencies upon each other. The test functions could be run in any order
without affecting the results of the test. Function-scoped fixtures are the
shortest-lived fixtures. Moving down the table, the persistence of the fixtures
increases, so that changes to a session-scoped fixture persist for the entire
test execution direction, only being torn down once pytest has executed all
tests.

#### Scoping for Performance

It is generally advisable to keep your tests free of external dependencies. By
definition, a unit test is completely isolated. However, there may be a few
cases where this would be less desirable. Slow test suites may introduce
excessive friction to the software development process. Persistent fixtures can
be used to improve the performance of a test suite. 

For example, here we define some expensive class:

```{.python filename=expensive.py}
"""A module containing an expensive class definition."""
import time
from typing import Union


class ExpensiveDoodah:
    """A toy class that represents some costly operation.

    This class will sleep for the specified number of seconds on instantiation.

    Parameters
    ----------
    sleep_time : Union[int, float]
        Number of seconds to wait on init.

    """
    def __init__(self, sleep_time: Union[int, float] = 2):
        print(f"Sleeping for {sleep_time} seconds")
        time.sleep(sleep_time)
        return None

```

This class will be used to demonstrate the effect of scoping with some costly
operation. This example could represent reading in a bulky xlsx file, for
instance.

To test `ExpensiveDoodah`, I will define a function-scoped fixture. To do this,
we use pytest's fixture decorator to return the class instance with a specified
sleep time of 2 seconds.

```{.python filename=test_expensive.py}
import pytest

from example_pkg.expensive import ExpensiveDoodah


@pytest.fixture(scope="function")
def module_doodah():
    """Function-scoped ExpensiveDoodah."""
    return ExpensiveDoodah(2)

```
Now we extend our test module to include a test class with 3 separate test
functions, all making assertions about the `ExpensiveDoodah`. The assertions
will all be the same for this simple example, that `ExpensiveDoodah` executes
without raising any error conditions. Notice we must pass the name of the
fixture in each test function's signature.

```{.python filename=test_expensive.py}
"""Tests for expensive.py using function-scoped fixture."""
from contextlib import nullcontext as does_not_raise
import pytest

from example_pkg.expensive import ExpensiveDoodah


@pytest.fixture(scope="function")
def doodah_fixture():
    """Function-scoped ExpensiveDoodah."""
    return ExpensiveDoodah(2)


class TestA:
    """A test class."""

    def test_1(self, doodah_fixture):
        """Test 1."""
        with does_not_raise():
            doodah_fixture

    def test_2(self, doodah_fixture):
        """Test 2."""
        with does_not_raise():
            doodah_fixture

    def test_3(self, doodah_fixture):
        """Test 3."""
        with does_not_raise():
            doodah_fixture

```

The result of running this test module can be seen below:

```
collected 3 items

./tests/test_expensive_function_scoped.py ...    [100%]

============================ 3 passed in 6.04s ================================

```

Notice that the test module took just over 6 seconds to execute because the
function-scoped fixture was set up once for each test function.

If instead we had defined `doodah_fixture` with a different scope, it would
reduce the time for the test suite to complete.

```{.python filename=test_expensive.py}
@pytest.fixture(scope="module")
def doodah_fixture():
    """Module-scoped ExpensiveDoodah."""
    return ExpensiveDoodah(2)

```

```
collected 3 items

./tests/test_expensive_function_scoped.py ...    [100%]

============================ 3 passed in 2.02s ================================

```

The scoping feature of pytest fixtures can be used to optimise a test-suite and
avoid lengthy delays while waiting for your test suites to execute. However,
any changes to the fixture contents will persist until the fixture is next torn
down. Keeping track of the states of differently-scoped fixtures in a complex
test suite can be tricky and reduces segmentation overall. Bear that in mind
when considering which scope best suits your needs.

### Troubleshooting Fixture Scopes

## Temporary Files & Directories

## Parametrized Tests

## Marks

## Mocking


<p id=fin><i>fin!</i></p>
