[
  {
    "objectID": "blogs/15-pytest-mocking.html",
    "href": "blogs/15-pytest-mocking.html",
    "title": "Mocking With Pytest in Plain English",
    "section": "",
    "text": "The Joker sings the Green Green Grass of Home."
  },
  {
    "objectID": "blogs/15-pytest-mocking.html#introduction",
    "href": "blogs/15-pytest-mocking.html#introduction",
    "title": "Mocking With Pytest in Plain English",
    "section": "Introduction",
    "text": "Introduction\npytest is a testing package for the python framework. It is broadly used to quality assure code logic. This article discusses the dark art of mocking, why you should do it and the nuts and bolts of implementing mocked tests. This blog is the fourth in a series of blogs called pytest in plain English, favouring accessible language and simple examples to explain the more intricate features of the pytest package.\nFor a wealth of documentation, guides and how-tos, please consult the pytest documentation.\n\nWhat does Mocking Mean?\nCode often has external dependencies:\n\nWeb APIs (as in this article)\nWebsites (if scraping / crawling)\nExternal code (importing packages)\nData feeds and databases\nEnvironment variables\n\nAs developers cannot control the behaviour of those dependencies, they would not write tests dependent upon them. In order to test their source code that depends on these services, developers need to replace the properties of these services when the test suite runs. Injecting replacement values into the code at runtime is generally referred to as mocking. Mocking these values means that developers can feed dependable results to their code and make reliable assertions about the code’s behaviour, without changes in the ‘outside world’ affecting outcomes in the system under test.\nDevelopers who write unit tests may also mock their own code. The “unit” in the term “unit test” implies complete isolation from external dependencies. Mocking is an indispensible tool in achieving that isolation within a test suite. It ensures that code can be efficiently verified in any order, without dependencies on other elements in your codebase. However, mocking also adds to code complexity, increasing cognitive load and generally making things harder to debug.\n\n\n\n\n\n\nA Note on the Purpose (Click to expand)\n\n\n\n\n\nThis article intends to discuss clearly. It doesn’t aim to be clever or impressive. Its aim is to extend understanding without overwhelming the reader. The code may not always be optimal, favouring a simplistic approach wherever possible.\n\n\n\n\n\nIntended Audience\nProgrammers with a working knowledge of python, HTTP requests and some familiarity with pytest and packaging. The type of programmer who has wondered about how to follow best practice in testing python code.\n\n\nWhat You’ll Need:\n\nPreferred python environment manager (eg conda)\npip install pytest==8.1.1 requests mockito\nGit\nGitHub account\nCommand line access\n\n\n\nPreparation\nThis blog is accompanied by code in this repository. The main branch provides a template with the minimum structure and requirements expected to run a pytest suite. The repo branches contain the code used in the examples of the following sections.\nFeel free to fork or clone the repo and checkout to the example branches as needed.\nThe example code that accompanies this article is available in the mocking branch of the repo."
  },
  {
    "objectID": "blogs/15-pytest-mocking.html#overview",
    "href": "blogs/15-pytest-mocking.html#overview",
    "title": "Mocking With Pytest in Plain English",
    "section": "Overview",
    "text": "Overview\nMocking is one of the trickier elements of testing. It’s a bit niche and is often perceived to be too hacky to be worth the effort. The options for mocking in python are numerous and this adds to the complexity of many example implementations you will find online.\nThere is also a compromise in simplicity versus flexibility. Some of the options available are quite involved and can be adapted to the nichest of cases, but may not be the best option for those new to mocking. With this in mind, I present 3 alternative methods for mocking python source code. So if you’ll forgive me, this is the first of the pytest in plain English series where I introduce alternative testing practices from beyond the pytest package.\n\nmonkeypatch: The pytest fixture designed for mocking. The origin of the fixture’s name is debated but potentially arose from the term ‘guerrilla patch’ which may have been misinterpreted as ‘gorilla patch’. This is the concept of modifying source code at runtime, which probably sounds a bit like ‘monkeying with the code’.\nMagicMock: This is the mocking object provided by python3’s builtin unittest package.\nmockito: This package is based upon the popular Java framework of the same name. Despite having a user-friendly syntax, mockito is robust and secure.\n\n\n\n\n\n\n\nA note on the language\n\n\n\n\n\nMocking has a bunch of synonyms & related language which can be a bit off-putting. All of the below terms are associated with mocking. Some may be preferred to the communities of specific programming frameworks over others.\n\n\n\n\n\n\n\n\nTerm\nBrief Meaning\nFrameworks/Libraries\n\n\n\n\nMocking\nCreating objects that simulate the behaviour of real objects for testing\nMockito (Java), unittest.mock (Python), Jest (JavaScript), Moq (.NET)\n\n\nSpying\nObserving and recording method calls on real objects\nMockito (Java), Sinon (JavaScript), unittest.mock (Python), RSpec (Ruby)\n\n\nStubbing\nReplacing methods with predefined behaviours or return values\nSinon (JavaScript), RSpec (Ruby), PHPUnit (PHP), unittest.mock (Python)\n\n\nPatching\nTemporarily modifying or replacing parts of code for testing\nunittest.mock (Python), pytest-mock (Python), PowerMock (Java)\n\n\nFaking\nCreating simplified implementations of complex dependencies\nFaker (multiple languages), Factory Boy (Python), FactoryGirl (Ruby)\n\n\nDummy Objects\nPlaceholder objects passed around but never actually used\nCan be created in any testing framework"
  },
  {
    "objectID": "blogs/15-pytest-mocking.html#mocking-in-python",
    "href": "blogs/15-pytest-mocking.html#mocking-in-python",
    "title": "Mocking With Pytest in Plain English",
    "section": "Mocking in Python",
    "text": "Mocking in Python\nThis section will walk through some code that uses HTTP requests to an external service and how we can go about testing the code’s behaviour without relying on that service being available. Feel free to clone the repository and check out to the example code branch to run the examples.\nThe purpose of the code is to retrieve jokes from https://icanhazdadjoke.com/ like so:\n\nfor _ in range(3):\n    print(get_joke(f=\"application/json\"))\n\nWhat did Yoda say when he saw himself in 4K? \"HDMI\"\nThe other day I was listening to a song about superglue, it’s been stuck in my head ever since.\nWhat do you call a careful wolf? Aware wolf.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe jokes are provided by https://icanhazdadjoke.com/ and are not curated by me. In my testing of the service I have found the jokes to be harmless fun, but I cannot guarantee that. If an offensive joke is returned, this is unintentional but let me know about it and I will generate new jokes.\n\n\n\nDefine the Source Code\nThe function get_joke() uses 2 internals:\n\n_query_endpoint() Used to construct the HTTP request with required headers and user agent.\n_handle_response() Used to catch HTTP errors, or to pull the text out of the various response formats.\n\n\n\"\"\"Retrieve dad jokes available.\"\"\"\nimport requests\n\n\ndef _query_endpoint(\n    endp:str, usr_agent:str, f:str,\n    ) -&gt; requests.models.Response:\n    \"\"\"Utility for formatting query string & requesting endpoint.\"\"\"\n    HEADERS = {\n        \"User-Agent\": usr_agent,\n        \"Accept\": f,\n        }\n    resp = requests.get(endp, headers=HEADERS)\n    return resp\n\nKeeping separate, the part of the codebase that you wish to target for mocking is often the simplest way to go about things. The target for our mocking will be the command that integrates with the external service, so requests.get() here.\nThe use of requests.get() in the code above depends on a few things:\n\nAn endpoint string.\nA dictionary with string values for the keys “User-Agent” and “Accept”.\n\nWe’ll need to consider those dependencies when mocking. Once we return a response from the external service, we need a utility to handle the various statuses of that response:\n\n\"\"\"Retrieve dad jokes available.\"\"\"\nimport requests\n\n\ndef _query_endpoint(\n    endp:str, usr_agent:str, f:str,\n    ) -&gt; requests.models.Response:\n    ...\n\n\ndef _handle_response(r: requests.models.Response) -&gt; str:\n    \"\"\"Utility for handling reponse object & returning text content.\n\n    Parameters\n    ----------\n    r : requests.models.Response\n        Response returned from webAPI endpoint.\n\n    Raises\n    ------\n    NotImplementedError\n        Requested format `f` was not either 'text/plain' or 'application/json'. \n    requests.HTTPError\n        HTTP error was encountered.\n    \"\"\"\n    if r.ok:\n        c_type = r.headers[\"Content-Type\"]\n        if c_type == \"application/json\":\n            content = r.json()\n            content = content[\"joke\"]\n        elif c_type == \"text/plain\":\n            content = r.text\n        else:\n            raise NotImplementedError(\n                \"This client accepts 'application/json' or 'text/plain' format\"\n                )\n    else:\n        raise requests.HTTPError(\n            f\"{r.status_code}: {r.reason}\"\n        )\n    return content\n\nOnce _query_endpoint() gets us a response, we can feed it into _handle_response(), where different logic is executed depending on the response’s properties. Specifically, any response we want to mock would need the following:\n\nheaders, containing a dictionary eg: {\"content_type\": \"plain/text\"}\nA json() method.\ntext, status_code and reason attributes.\n\nFinally, the above functions get wrapped in the get_joke() function below:\n\n\"\"\"Retrieve dad jokes available.\"\"\"\nimport requests\n\n\ndef _query_endpoint(\n    endp:str, usr_agent:str, f:str,\n    ) -&gt; requests.models.Response:\n    ...\n\n\ndef _handle_response(r: requests.models.Response) -&gt; str:\n    ...\n\n\ndef get_joke(\n    endp:str = \"https://icanhazdadjoke.com/\",\n    usr_agent:str = \"datasavvycorner.com (https://github.com/r-leyshon/pytest-fiddly-examples)\", \n    f:str = \"text/plain\",\n) -&gt; str:\n    \"\"\"Request a joke from icanhazdadjoke.com.\n\n    Ask for a joke in either plain text or JSON format. Return the joke text.\n\n    Parameters\n    ----------\n    endp : str, optional\n        Endpoint to query, by default \"https://icanhazdadjoke.com/\"\n    usr_agent : str, optional\n        User agent value, by default\n        \"datasavvycorner.com (https://github.com/r-leyshon/pytest-fiddly-examples)\"\n    f : str, optional\n        Format to request eg \"application.json\", by default \"text/plain\"\n\n    Returns\n    -------\n    str\n        Joke text.\n    \"\"\"\n    r = _query_endpoint(endp=endp, usr_agent=usr_agent, f=f)\n    return _handle_response(r)\n\n\n\nLet’s Get Testing\nThe behaviour in get_joke() is summarised in the flowchart below:\n\nThere are 4 outcomes to check, coloured red and green in the process chart above.\n\nget_joke() successfully returns joke text when the user asked for json format.\nget_joke() successfully returns joke text when the user asked for plain text.\nget_joke() raises NotImplementedError if any other valid format is asked for. Note that the API also accepts HTML and image formats, though parsing the joke text out of those is more involved and beyond the scope of this blog.\nget_joke() raises a HTTPError if the response from the API was not ok.\n\nNote that the event that we wish to target for mocking is highlighted in blue - we don’t want our tests to execute any real requests.\nThe strategy for testing this function without making requests to the web API is composed of 4 similar steps, regardless of the package used to implement the mocking.\n\n\nMock: Define the object or property that you wish to use as a replacement. This could be a static value or something a bit more involved, like a mock class that can return dynamic values depending upon the values it receives.\nPatch: Replace part of the source code with our mock value.\nUse: Use the source code to return a value.\nAssert: Check the returned value is what you expect.\n\nIn the examples that follow, I will label the equivalent steps for the various mocking implementations.\n\n\nThe “Ultimate Joke”\nWhat hard-coded text shall I use for my expected joke? I’ll create a fixture that will serve up this joke text to all of the test modules used below. I’m only going to define it once and then refer to it throughout several examples below. So it needs to be a pretty memorable, awesome joke.\n\nimport pytest\n\n\n@pytest.fixture(scope=\"session\")\ndef ULTI_JOKE():\n    return (\"Doc, I can't stop singing 'The Green, Green Grass of Home.' That \"\n    \"sounds like Tom Jones Syndrome. Is it common? Well, It's Not Unusual.\")\n\nBeing a Welshman, I may be a bit biased. But that’s a pretty memorable dad joke in my opinion. This joke will be available to every test within my test suite when I execute pytest from the command line. The assertions that we will use when using get_joke() will expect this string to be returned. If some other joke is returned, then we have not mocked correctly and an HTTP request was sent to the API.\n\n\nMocking Everything\nI’ll start with an example of how to mock get_joke() completely. This is an intentionally bad idea. In doing this, the test won’t actually be executing any of the code, just returning a hard-coded value for the joke text. All this does is prove that the mocking works as expected and has nothing to do with the logic in our source code.\nSo why am I doing it? Hopefully I can illustrate the most basic implementation of mocking in this way. I’m not having to think about how I can mock a response object with all the required properties. I just need to provide some hard coded text.\n\nmonkeypatchMagicMockmockito\n\n\n\nimport example_pkg.only_joking\n\n\ndef test_get_joke_monkeypatched_entirely(monkeypatch, ULTI_JOKE):\n    \"\"\"Completely replace the entire get_joke return value.\n\n    Not a good idea for testing as none of our source code will be tested. But\n    this demonstrates how to entirely scrub a function and replace with any\n    placeholder value at pytest runtime.\"\"\"\n    # step 1\n    def _mock_joke():\n        \"\"\"Return the joke text.\n\n        monkeypatch.setattr expects the value argument to be callable. In plain\n        English, a function or class.\"\"\"\n        return ULTI_JOKE\n    # step 2\n    monkeypatch.setattr(\n        target=example_pkg.only_joking,\n        name=\"get_joke\",\n        value=_mock_joke\n        )\n    # step 3 & 4\n    # Use the module's namespace to correspond with the monkeypatch\n    assert example_pkg.only_joking.get_joke() == ULTI_JOKE \n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nStep 2 requires the hard coded text to be returned from a callable, like a function or class. So we define _mock_joke to serve the text in the required format.\n\nStep 2\n\nmonkeypatch.setattr() is able to take the module namespace that we imported as the target. This must be the namespace where the function (or variable etc) is defined.\n\nStep 3\n\nWhen invoking the function, be sure to reference the function in the same way as it was monkeypatched.\nAliases can also be used if preferable (eg import example_pkg.only_joking as jk). Be sure to update your reference to get_joke() in step 2 and 3 to match your import statement.\n\n\n\n\n\n\n\nfrom unittest.mock import MagicMock, patch\n\nimport example_pkg.only_joking\n\n\ndef test_get_joke_magicmocked_entirely(ULTI_JOKE):\n    \"\"\"Completely replace the entire get_joke return value.\n\n    Not a good idea for testing as none of our source code will be tested. But\n    this demonstrates how to entirely scrub a function and replace with any\n    placeholder value at pytest runtime.\"\"\"\n    # step 1\n    _mock_joke = MagicMock(return_value=ULTI_JOKE)\n    # step 2\n    with patch(\"example_pkg.only_joking.get_joke\", _mock_joke):\n        # step 3\n        joke = example_pkg.only_joking.get_joke()\n        # step 4\n        assert joke == ULTI_JOKE\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nMagicMock() allows us to return static values as mock objects.\n\nStep 3\n\nWhen you use get_joke(), be sure to call reference the namespace in the same way as to your patch in step 2.\n\n\n\n\n\n\n\nfrom mockito import when, unstub\n\nimport example_pkg.only_joking\n\n\ndef test_get_joke_mockitoed_entirely(ULTI_JOKE):\n    \"\"\"Completely replace the entire get_joke return value.\n\n    Not a good idea for testing as none of our source code will be tested. But\n    this demonstrates how to entirely scrub a function and replace with any\n    placeholder value at pytest runtime.\"\"\"\n    # step 1 & 2\n    when(example_pkg.only_joking).get_joke().thenReturn(ULTI_JOKE)\n    # step 3\n    joke = example_pkg.only_joking.get_joke()\n    # step 4\n    assert joke == ULTI_JOKE\n    unstub()\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1 & 2\n\nmockito’s intuitive when(...).thenReturn(...) pattern allows you to reference any object within the imported namespace. Like with MagicMock, the static string ULTI_JOKE can be referenced.\n\nStep 3\n\nWhen you use get_joke(), be sure to call reference the namespace in the same way as to your patch in step 2.\n\nunstub\n\nThis step explicitly ‘unpatches’ get_joke(). If you did not unstub(), the patch to get_joke() would persist through the rest of your tests.\nmockito allows you to implicitly unstub() by using the context manager with.\n\n\n\n\n\n\n\n\n\nmonkeypatch() without OOP\nSomething I’ve noticed about the pytest documentation for monkeypatch, is that it gets straight into mocking with Object Oriented Programming (OOP). While this may be a bit more convenient, it is certainly not a requirement of using monkeypatch and definitely adds to the cognitive load for new users. This first example will mock the value of requests.get without using classes.\n\nimport requests\n\nfrom example_pkg.only_joking import get_joke\n\n\ndef test_get_joke_monkeypatched_no_OOP(monkeypatch, ULTI_JOKE):\n    # step 1: Mock the response object\n    def _mock_response(*args, **kwargs):\n        resp = requests.models.Response()\n        resp.status_code = 200\n        resp._content = ULTI_JOKE.encode(\"UTF8\")\n        resp.headers = {\"Content-Type\": \"text/plain\"}\n        return resp\n    \n    # step 2: Patch requests.get\n    monkeypatch.setattr(requests, \"get\", _mock_response)\n    # step 3: Use requests.get\n    joke = get_joke()\n    # step 4: Assert\n    assert joke == ULTI_JOKE, f\"Expected:\\n'{ULTI_JOKE}\\nFound:\\n{joke}'\"\n    # will also work for json format\n    joke = get_joke(f=\"application/json\")\n    assert joke == ULTI_JOKE, f\"Expected:\\n'{ULTI_JOKE}\\nFound:\\n{joke}'\"\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nThe return value of requests.get() will be a response object. We need to mock this object with the methods and attributes required by the _handle_response() function.\nWe need to encode the static joke text as bytes to format the data. Response objects encode data as bytes for interoperatability and optimisation purposes.\n\nstep4\n\nAs we have set an appropriate value for the mocked response’s _content attribute, the mocked joke will be returned for both JSON and plain text formats - very convenient!\n\n\n\n\n\n\nCondition 1: Test JSON\nIn this example, we demonstrate the same functionality as above, but with an object-oriented design pattern. This approach more closely follows that of the pytest documentation. As before, MagicMock and mockito examples will be included.\nThe purpose of this test is to test the outcome of get_joke() when the user specifies a json format.\n\nmonkeypatchMagicMockmockito\n\n\n\nimport pytest\nimport requests\n\nfrom example_pkg.only_joking import get_joke\n\n\n@pytest.fixture\ndef _mock_response(ULTI_JOKE):\n    \"\"\"Return a class instance that will mock all the properties of a response\n    object that get_joke needs to work.\n    \"\"\"\n    HEADERS_MAP = {\n        \"text/plain\": {\"Content-Type\": \"text/plain\"},\n        \"application/json\": {\"Content-Type\": \"application/json\"},\n        \"text/html\": {\"Content-Type\": \"text/html\"},\n    }\n\n    class MockResponse:\n        def __init__(self, f, *args, **kwargs):\n            self.ok = True\n            self.f = f\n            self.headers = HEADERS_MAP[f] # header corresponds to format that\n            # the user requested\n            self.text = ULTI_JOKE \n\n        def json(self):\n            if self.f == \"application/json\":\n                return {\"joke\": ULTI_JOKE}\n            return None\n\n    return MockResponse\n\n\ndef test_get_joke_json_monkeypatched(monkeypatch, _mock_response, ULTI_JOKE):\n    \"\"\"Test behaviour when user asked for JSON joke.\n\n    Test get_joke using the mock class fixture. This approach is the\n    implementation suggested in the pytest docs.\n    \"\"\"\n    # step 1: Mock\n    def _mock_get_good_resp(*args, **kwargs):\n        \"\"\"Return fixtures with the correct header.\n\n        If the test uses \"text/plain\" format, we need to return a MockResponse\n        class instance with headers attribute equal to\n        {\"Content-Type\": \"text/plain\"}, likewise for JSON.\n        \"\"\"\n        f = kwargs[\"headers\"][\"Accept\"]\n        return _mock_response(f)\n    # Step 2: Patch\n    monkeypatch.setattr(requests, \"get\", _mock_get_good_resp)\n    # Step 3: Use\n    j_json = get_joke(f=\"application/json\")\n    # Step 4: Assert\n    assert j_json == ULTI_JOKE, f\"Expected:\\n'{ULTI_JOKE}\\nFound:\\n{j_json}'\"\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nWe define a mocked class instance with the necessary properties expected by _handle_response().\nThe mocked response is served to our test as a pytest fixture.\nWithin the test, we need another function, which will be able to take the arguments passed to requests.get(). This will allow our class instance to retrieve the appropriate header from the HEADERS_MAP dictionary.\n\n\nAs you may appreciate, this does not appear to be the most straight forward implementation, but it will allow us to test when the user asks for JSON, plain text or HTML formats. In the above test, we assert against JSON format only.\n\n\n\n\n\nfrom unittest.mock import MagicMock, patch\nimport requests\n\nfrom example_pkg.only_joking import get_joke\n\n\ndef test_get_joke_json_magicmocked(ULTI_JOKE):\n    \"\"\"Test behaviour when user asked for JSON joke.\"\"\"\n    # step 1: Mock\n    mock_response = MagicMock(spec=requests.models.Response)\n    mock_response.ok = True\n    mock_response.headers = {\"Content-Type\": \"application/json\"}\n    mock_response.json.return_value = {\"joke\": ULTI_JOKE}\n    # step 2: Patch\n    with patch(\"requests.get\", return_value=mock_response):\n        # step 3: Use\n        joke = get_joke(f=\"application/json\")\n        # step 4: Assert\n        assert joke == ULTI_JOKE\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nMagicMock() can return a mock object with a specification designed to mock response objects. Super useful.\nOur static joke content can be served directly to MagicMock without the need for an intermediate class.\nIn comparison to the monkeypatch approach, this appears to be more straight forward and maintainable.\n\n\n\n\n\n\n\nfrom mockito import when, unstub\nimport requests\n\nimport example_pkg.only_joking\n\n\ndef test_get_joke_json_mockitoed(ULTI_JOKE):\n    \"\"\"Test behaviour when user asked for JSON joke.\"\"\"\n    # step 1: Mock\n    _mock_response = requests.models.Response()\n    _mock_response.status_code = 200\n    _mock_response._content = b'{\"joke\": \"' + ULTI_JOKE.encode(\"utf-8\") + b'\"}'\n    _mock_response.headers = {\"Content-Type\": \"application/json\"}\n    # step 2: Patch\n    when(requests).get(...).thenReturn(_mock_response)\n    # step 3: Use\n    joke = example_pkg.only_joking.get_joke(f=\"application/json\")\n    # step 4: Assert\n    assert joke == ULTI_JOKE\n    unstub()\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nIn order to encode the expected joke for JSON format, we need a dictionary encoded within a bytestring. This bit is a little tricky.\nAlternatively, define the expected dictionary and use the json package. json.dumps(dict).encode(\"UTF8\") will format the content dictionary in the required way.\n\nStep 2\n\nmockito’s when() approach will allow you to access the methods of the object that is being patched, in this case requests.\nmockito allows you to pass the ... argument to a patched method, to indicate that whatever arguments were passed to get(), return the specified mock value.\nBeing able to specify values passed in place of ... will allow you to set different return values depending on argument values received by get().\n\n\n\n\n\n\n\n\n\nCondition 2: Test Plain Text\nThe purpose of this test is to check the outcome when the user specifies a plain/text format while using get_joke().\n\nmonkeypatchMagicMockmockito\n\n\n\nimport pytest\nimport requests\n\nfrom example_pkg.only_joking import get_joke\n\n\n@pytest.fixture\ndef _mock_response(ULTI_JOKE):\n    \"\"\"The same fixture as was used for testing JSON format\"\"\"\n    ...\n\n\ndef test_get_joke_text_monkeypatched(monkeypatch, _mock_response, ULTI_JOKE):\n    \"\"\"Test behaviour when user asked for plain text joke.\"\"\"\n    # step 1: Mock\n    def _mock_get_good_resp(*args, **kwargs):\n        f = kwargs[\"headers\"][\"Accept\"]\n        return _mock_response(f)\n    # step 2: Patch\n    monkeypatch.setattr(requests, \"get\", _mock_get_good_resp)\n    # step 3: Use\n    j_txt = get_joke(f=\"text/plain\")\n    # step 4: Assert\n    assert j_txt == ULTI_JOKE, f\"Expected:\\n'{ULTI_JOKE}\\nFound:\\n{j_txt}'\"\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nWe can use the same mock class as for testing Condition 1, due to the content of the HEADERS_MAP dictionary.\n\n\n\n\n\n\n\nfrom unittest.mock import MagicMock, patch\nimport requests\n\nfrom example_pkg.only_joking import get_joke\n\n\ndef test_get_joke_text_magicmocked(ULTI_JOKE):\n    \"\"\"Test behaviour when user asked for plain text joke.\"\"\"\n    # step 1: Mock\n    mock_response = MagicMock(spec=requests.models.Response)\n    mock_response.ok = True\n    mock_response.headers = {\"Content-Type\": \"text/plain\"}\n    mock_response.text = ULTI_JOKE\n    # step 2: Patch\n    with patch(\"requests.get\", return_value=mock_response):\n        # step 3: Use\n        joke = get_joke(f=\"text/plain\")\n        # step 4: Assert\n        assert joke == ULTI_JOKE\n\n\n\n\nfrom mockito import when, unstub\nimport requests\n\nimport example_pkg.only_joking\n\ndef test_get_joke_text_mockitoed(ULTI_JOKE):\n    \"\"\"Test behaviour when user asked for plain text joke.\"\"\"\n    # step 1: Mock\n    mock_response = requests.models.Response()\n    mock_response.status_code = 200\n    mock_response._content = ULTI_JOKE.encode(\"utf-8\")\n    mock_response.headers = {\"Content-Type\": \"text/plain\"}\n    # step 2: Patch\n    when(requests).get(...).thenReturn(mock_response)\n    # step 3: Use\n    joke = example_pkg.only_joking.get_joke(f=\"text/plain\")\n    # step 4: Assert\n    assert joke == ULTI_JOKE\n    unstub()\n\n\n\n\n\n\nCondition 3: Test Not Implemented\nThis test will check the outcome of what happens when the user asks for a format other than text or JSON format. As the webAPI also offers image or HTML formats, a response 200 (ok) would be returned from the service. But I was too busy (lazy) to extract the text from those formats.\n\nmonkeypatchMagicMockmockito\n\n\n\nimport pytest\nimport requests\n\nfrom example_pkg.only_joking import get_joke\n\n\n@pytest.fixture\ndef _mock_response(ULTI_JOKE):\n    \"\"\"The same fixture as was used for testing JSON format\"\"\"\n    ...\n\n\ndef test_get_joke_not_implemented_monkeypatched(\n    monkeypatch, _mock_response):\n    \"\"\"Test behaviour when user asked for HTML response.\"\"\"\n    #  step 1: Mock\n    def _mock_get_good_resp(*args, **kwargs):\n        f = kwargs[\"headers\"][\"Accept\"]\n        return _mock_response(f)\n    # step 2: Patch\n    monkeypatch.setattr(requests, \"get\", _mock_get_good_resp)\n    # step 3 & 4 Use (try to but exception is raised) & Assert\n    with pytest.raises(\n        NotImplementedError,\n        match=\"This client accepts 'application/json' or 'text/plain' format\"):\n        get_joke(f=\"text/html\")\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nWe can use the same mock class as for testing Condition 1, due to the content of the HEADERS_MAP dictionary.\n\nStep 4\n\nWe use a context manager (with pytest.raises) which catches the raised exception and stops it from terminating our pytest session.\nThe asserted match argument can take a regular expression, so that wildcard patterns can be used. This allows matching of part of the exception message.\n\n\n\n\n\n\n\nimport pytest\nimport requests\nfrom unittest.mock import MagicMock, patch\n\nfrom example_pkg.only_joking import get_joke\ndef test__handle_response_not_implemented_magicmocked():\n    \"\"\"Test behaviour when user asked for HTML response.\"\"\"\n    # step 1: Mock\n    mock_response = MagicMock(spec=requests.models.Response)\n    mock_response.ok = True\n    mock_response.headers = {\"Content-Type\": \"text/html\"}\n    #  step 2: Patch\n    with patch(\"requests.get\", return_value=mock_response):\n        # step 3 & 4 Use (try to but exception is raised) & Assert\n        with pytest.raises(\n            NotImplementedError,\n            match=\"client accepts 'application/json' or 'text/plain' format\"):\n            get_joke(f=\"text/html\")\n\n\n\n\nfrom mockito import when, unstub\nimport requests\n\nimport example_pkg.only_joking\n\ndef test_get_joke_not_implemented_mockitoed():\n    \"\"\"Test behaviour when user asked for HTML response.\"\"\"\n    # step 1: Mock\n    mock_response = requests.models.Response()\n    mock_response.status_code = 200\n    mock_response.headers = {\"Content-Type\": \"text/html\"}\n    # step 2: Patch\n    when(\n        example_pkg.only_joking\n        )._query_endpoint(...).thenReturn(mock_response)\n    # step 3 & 4 Use (try to but exception is raised) & Assert\n    with pytest.raises(\n        NotImplementedError,\n        match=\"This client accepts 'application/json' or 'text/plain' format\"):\n        example_pkg.only_joking.get_joke(f=\"text/html\")\n    unstub()\n\n\n\n\n\n\nCondition 4: Test Bad Response\nIn this test, we simulate a bad response from the webAPI, which could arise for a number of reasons:\n\nThe api is unavailable.\nThe request asked for a resource that is not available.\nToo many requests were made in a short period.\n\nThese conditions are those that we have the least control over and therefore have the greatest need for mocking.\n\nmonkeypatchMagicMockmockito\n\n\n\nimport pytest\nimport requests\n\nfrom example_pkg.only_joking import get_joke, _handle_response\n\n\n@pytest.fixture\ndef _mock_bad_response():\n    class MockBadResponse:\n        def __init__(self, *args, **kwargs):\n            self.ok = False\n            self.status_code = 404\n            self.reason = \"Not Found\"\n    return MockBadResponse\n\n\ndef test_get_joke_http_error_monkeypatched(\n    monkeypatch, _mock_bad_response):\n    \"\"\"Test bad HTTP response.\"\"\"\n    #  step 1: Mock\n    def _mock_get_bad_response(*args, **kwargs):\n        f = kwargs[\"headers\"][\"Accept\"]\n        return _mock_bad_response(f)\n    #  step 2: Patch\n    monkeypatch.setattr(requests, \"get\", _mock_get_bad_response)\n    # step 3 & 4 Use (try to but exception is raised) & Assert\n    with pytest.raises(requests.HTTPError, match=\"404: Not Found\"):\n        get_joke()\n\n\n\n\n\n\n\nNotes\n\n\n\n\nStep 1\n\nThis time we need to define a new fixture that returns a bad response.\nAlternatively, we could have implemented a single fixture for all of our tests that dynamically served a good or bad response dependent upon arguments passed to get_joke(), for example different string values passed as the endpoint.\nIn a more thorough implementation of get_joke(), you may wish to retry the request for certain HTTP error status codes. The ability to provide mocked objects that reliably serve those statuses allow you to deterministically validate your code’s behaviour.\n\n\n\n\n\n\n\nimport pytest\nfrom unittest.mock import MagicMock, patch\nimport requests\n\nfrom example_pkg.only_joking import get_joke\n\n\ndef test_get_joke_http_error_magicmocked():\n    \"\"\"Test bad HTTP response.\"\"\"\n    # step 1: Mock\n    _mock_response = MagicMock(spec=requests.models.Response)\n    _mock_response.ok = False\n    _mock_response.status_code = 404\n    _mock_response.reason = \"Not Found\"\n    # step 2: Patch\n    with patch(\"requests.get\", return_value=_mock_response):\n        # step 3 & 4 Use (try to but exception is raised) & Assert\n        with pytest.raises(requests.HTTPError, match=\"404: Not Found\"):\n            get_joke()\n\n\n\n\nfrom mockito import when, unstub\nimport requests\n\nimport example_pkg.only_joking\n\n\ndef test_get_joke_http_error_mockitoed():\n    \"\"\"Test bad HTTP response.\"\"\"\n    # step 1: Mock\n    _mock_response = requests.models.Response()\n    _mock_response.status_code = 404\n    _mock_response.reason = \"Not Found\"\n    # step 2: Patch\n    when(example_pkg.only_joking)._query_endpoint(...).thenReturn(\n        _mock_response)\n    # step 3 & 4 Use (try to but exception is raised) & Assert\n    with pytest.raises(requests.HTTPError, match=\"404: Not Found\"):\n        example_pkg.only_joking.get_joke()\n    unstub()"
  },
  {
    "objectID": "blogs/15-pytest-mocking.html#summary",
    "href": "blogs/15-pytest-mocking.html#summary",
    "title": "Mocking With Pytest in Plain English",
    "section": "Summary",
    "text": "Summary\nWe have thoroughly tested our code using approaches that mock the behaviour of an external webAPI. We have also seen how to implement those tests with 3 different packages.\nI hope that this has provided you with enough introductory material to begin mocking tests if you have not done so before. If you find that your specific use case for mocking is quite nuanced and fiddly (it’s likely to be that way), then the alternative implementations presented here can help you to understand how to solve your specific mocking dilemma.\nOne final quote for those developers having their patience tested by errors attempting to implement mocking:\n\n“He who laughs last, laughs loudest.”\n\n…or she for that matter: Don’t give up!\nIf you spot an error with this article, or have a suggested improvement then feel free to raise an issue on GitHub.\nHappy testing!"
  },
  {
    "objectID": "blogs/15-pytest-mocking.html#acknowledgements",
    "href": "blogs/15-pytest-mocking.html#acknowledgements",
    "title": "Mocking With Pytest in Plain English",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo past and present colleagues who have helped to discuss pros and cons, establishing practice and firming-up some opinions. Special thanks to Edward for bringing mockito to my attention.\nThe diagrams used in this article were produced with the excellent Excalidraw.\n\nfin!"
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "",
    "text": "Wikimedia commons UK Map."
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html#introduction",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html#introduction",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "Introduction",
    "text": "Introduction\nThis tutorial is for programmers familiar with Python and how to create virtual environments, but perhaps less familiar with the Python requests package or ArcGIS REST API [1].\nIf you’re in a rush and just need a snippet that will ingest every UK 2021 LSOA boundary available, here is a GitHub gist just for you."
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html#the-scenario",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html#the-scenario",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "The Scenario",
    "text": "The Scenario\nYou would like to use python to programmatically ingest data from the Office for National Statistics (ONS) Open Geography Portal. This tutorial aims to help you do this, working with the 2021 LSOA boundaries, the essential features and quirks of the ArcGIS REST API will be explored."
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html#what-youll-need",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html#what-youll-need",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "What you’ll need:",
    "text": "What you’ll need:\n\nA permissive firewall (whitelist the domain “https://geoportal.statistics.gov.uk/” if necessary)\nPython package manager (eg pip)\nPython environment manager (eg venv, poetry etc)\nPython requirements:\n\n\n\nrequirements.txt\n\nfolium\ngeopandas\nmapclassify\nmatplotlib\npandas\nrequests"
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html#tutorial",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html#tutorial",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "Tutorial",
    "text": "Tutorial\n\nSetting Things Up\n\nCreate a new directory with a requirements file as shown above.\nCreate a new virtual environment.\npip install -r requirements.txt\nCreate a file called get_data.py or whatever you would like to call it. The rest of the tutorial will work with this file.\nAdd the following lines to the top of get_data.py and run them, this ensures that you have the dependencies needed to run the rest of the code:\n\n\nimport requests\nimport geopandas as gpd\nimport pandas as pd\n\n\n\nFinding The Data Asset\nOne of the tricky parts of working with the GeoPortal is finding the resource that you need.\n\nAccess the ONS Open Geography Portal homepage [2].\nUsing the ribbon menu at the top of the page, navigate to:\nBoundaries  Census Boundaries  Lower Super Output Areas  2021 Boundaries.\nOnce you have clicked on this option, a page will open with items related to your selection. Click on the item called “Lower Layer Super Output Areas (2021) Boundaries EW BFC”\nThis will bring you to the data asset that you need. It should look like the webpage below.\n\n\n\n\n\n\nFinding the Endpoint\nNow that we have the correct data asset, let’s find the endpoint. This is the url that we will need to send our requests to, in order to receive the data that we need.\n\nClick on the “View Full Details” button.\nScroll down, under the menu “I want to…”, and expand the “View API Resources” menu.\nYou will see two urls labelled “GeoService” and “GeoJSON”. Click the copy button to the right of the url.\nPaste the url into your Python script.\nEdit the url string to remove everything to the right of the word ‘query’, including the question mark. Then assign it to a variable called ENDPOINT as below:\n\n\nENDPOINT = \"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Lower_layer_Super_Output_Areas_2021_EW_BFC_V8/FeatureServer/0/query\"\n\nThis ENDPOINT is a url that we can use to flexibly ask for only the data or metadata, that we require.\n\n\nRequesting a Single Entry\nNow that we’re set up to make requests, we can use an example that brings back only a small slice of the database. To do this, we will need to specify some query parameters. These parameters will get added to our endpoint url and will be interpreted by ArcGIS to serve us only the data we ask for. In this example, I will ask for a single LSOA boundary only by specifying the LSOA code with an SQL clause. For more detail on the flexibility of ArcGIS API, please consult the documentation [1].\n\nDefine the below Python dictionary, noting that the syntax and data formats can be brittle - don’t forget to wrap the LSOA21CD in speech marks:\n\n\n# requesting a specific LSOA21CD\nparams = {\n    \"where\": \"LSOA21CD = 'W01002029'\", # SQL clauses can go here\n    \"outSR\": 4326, # CRS that you want\n    \"f\": \"geoJSON\", # response format\n    \"resultOffset\": 0, # parameter used for pagination later\n    \"outFields\": \"*\", # This will ensure all available fields are returned\n}\n\n\nNow I will define a function that will make the request and handle the response for us. Go ahead and define this function:\n\n\ndef request_to_gdf(url:str, query_params:dict) -&gt; gpd.GeoDataFrame:\n    \"\"\"Send a get request to ArcGIS API & Convert to GeoDataFrame.\n\n    Only works when asking for features and GeoJSON format.\n\n    Parameters\n    ----------\n    url : str\n        The url endpoint.\n    query_params : dict\n        A dictionary of query parameter : value pairs.\n\n    Returns\n    -------\n    requests.response\n        The response from ArcGIS API server. Useful for paginated requests\n        later.\n    gpd.GeoDataFrame\n        A GeoDataFrame of the requested geometries in the crs specified by the\n        response metadata.\n\n    Raises\n    ------\n    requests.exceptions.RequestException\n        The response was not ok.\n    \"\"\"\n    # this approach will only work with geoJSON\n    query_params[\"f\"] = \"geoJSON\"\n    # get the response\n    response = requests.get(url, params=query_params)\n    if response.ok:\n        # good response (hopefully, but be careful for JSONDecodeError)\n        content = response.json()\n        return (\n            response, # we'll need the response again later for pagination\n            gpd.GeoDataFrame.from_features(\n                content[\"features\"],\n                crs=content[\"crs\"][\"properties\"][\"name\"]\n                # safest to get crs from response\n                ))\n    else:\n        # cases where a traditional bad response may be returned\n        raise requests.RequestException(\n            f\"HTTP Code: {response.status_code}, Status: {response.reason}\"\n        )\n\nBriefly, this function is going to ensure the geoJSON format is asked for, as this is the neatest way to bash the response into a GeoDataFrame. It then queries ArcGIS API with the endpoint and parameter you specify. It checks if a status code 200 was returned (good response), if not an exception is raised with the HTTP code and status. Finally, if no error triggered an exception, the ArcGIS response and a GeoDataFrame format of the spatial feature is returned.\n\n\n\n\n\n\nCaution\n\n\n\n\n\nBe careful when handling the response of ArcGIS API. Depending on the query you send, it is possible to return status code 200 responses that seem fine. But if the server was unable to make sense of your SQL query, it may result in a JSONDecodeError or even content with details of your error. It is important to handle the various error conditions if you plan to build something more robust than this tutorial and to be exacting with your query strings. For this reason, I would suggest using the params dictionary approach to introducing query parameters rather than attempting to manually format the url string.\n\n\n\n\nWith that function defined, we can go straight to a tabular data format, like below:\n\n\n_, gdf = request_to_gdf(ENDPOINT, params)\ngdf.head()\n\n\n\n\n\n\n\n\ngeometry\nFID\nLSOA21CD\nLSOA21NM\nBNG_E\nBNG_N\nLONG\nLAT\nShape__Area\nShape__Length\nGlobalID\n\n\n\n\n0\nPOLYGON ((-3.06378 51.58946, -3.06200 51.58922...\n35661\nW01002029\nNewport 009G\n326721\n187882\n-3.05905\n51.58501\n315524.689297\n3127.139319\n716fb767-06e5-40c8-a0be-9c88b31f6cdf\n\n\n\n\n\n\n\n\nWe can use the GeoDataFrame .explore() method to quickly inspect the fruit of our efforts.\n\n\ngdf.explore()\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nReturn All LSOAs in a Local Authority\n\nWe probably need to work with more than just a single LSOA, but would prefer not to ingest all of them. Have a look at the available columns in the GeoDataFrame.\n\n\n\n\n\n\n\n\n\n\ngeometry\nFID\nLSOA21CD\nLSOA21NM\nBNG_E\nBNG_N\nLONG\nLAT\nShape__Area\nShape__Length\nGlobalID\n\n\n\n\n0\nPOLYGON ((-3.06378 51.58946, -3.06200 51.58922...\n35661\nW01002029\nNewport 009G\n326721\n187882\n-3.05905\n51.58501\n315524.689297\n3127.139319\n716fb767-06e5-40c8-a0be-9c88b31f6cdf\n\n\n\n\n\n\n\nThere is a pattern that we can exploit to request every LSOA in a local authority. Have a go at updating params[\"where\"] with an SQL query that can achieve this.\n\n\nShow the solution\nparams[\"where\"] = \"LSOA21NM like 'Newport%'\"\n\n\n\nPass the updated params dictionary to the request_to_gdf function and use the .explore() method to visualise the map. Confirm that the LSOAs returned match what you expected.\n\n\n\nShow the solution\n_, gdf = request_to_gdf(ENDPOINT, params)\ngdf.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nHow Many Records Are There?\n\nUpdate the params dictionary by changing the value of where to '1=1'.\n\n\n\nShow the Solution\n# parameter to get max allowed data, this will get encoded to \"where=1%3D1\"\n# https://www.w3schools.com/tags/ref_urlencode.ASP\nparams[\"where\"] = \"1=1\"\n\n\nFor more on why to do this, consult the ArcGIS docs [1]. This is the way to state ‘where=true’, meaning get every record possible while respecting the maxRecordCount. maxRecordCount limits the number of records available for download to 2,000 records in most cases. This is ArcGIS’ method of limiting service demand while not requiring authentication. It also means we need to handle paginated responses.\n\nIt’s a good idea to confirm the number of records available within the database. Have a go at reading through the ArcGIS docs [1] to find the parameter responsible for returning counts only. Query the database for the number of records and store it as an integer called n_records.\n\n\n\nShow the Solution\n# how many LSOA boundaries should we expect in the full data?\nparams[\"returnCountOnly\"] = True\nresponse = requests.get(ENDPOINT, params=params)\nn_records = response.json()[\"properties\"][\"count\"]\nprint(f\"There are {n_records} LSOAs in total\")\n\n\nThere are 35672 LSOAs in total\n\n\n\n\nPaginated Requests\n\nNow we have the number of records, it’s important to go back to collecting geometries. Please update the params dictionary to allow that to happen.\n\n\n\nShow the Solution\n# lets now return to collecting geometries\ndel params[\"returnCountOnly\"] #alternatively set to False\n\n\n\nHave a go at requesting the first batch of LSOA boundaries. Count how many you get without attempting to paginate.\n\n\n\nShow the Solution\nresponse, gdf = request_to_gdf(ENDPOINT, params)\nprint(f\"There are only {len(gdf)} LSOAs on this page.\")\n\n\nThere are only 2000 LSOAs on this page.\n\n\n\nVisualise the first 100 rows of the GeoDataFrame you created in the previous step.\n\n\n\nShow the Solution\ngdf.head(100).explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nWe need a condition to check if there are more pages left in the database. See if you can find the target parameter by examining the response properties.\n\n\n\nShow the Solution\ncontent = response.json()\n# we need a conditional on whether more pages are available:\nmore_pages = content[\"properties\"][\"exceededTransferLimit\"]\nprint(f\"It is {more_pages}, that there are more pages of data to ingest...\")\n\n\nIt is True, that there are more pages of data to ingest...\n\n\n\nWe are nearly ready to ask for every available LSOA boundary. This will be an expensive request. Therefore to make things go a bit faster, let’s ask for only the default fields by removing params[\"outFields\"].\n\n\n\nShow the solution\ndel params[\"outFields\"]\n\n\n\nNow we need to add a new parameter to our params dictionary, with the key resultOffset. We need to send multiple queries to the server, incrementing the value of resultOffset by the number of records on each page in every consecutive request. This may take quite a while, depending on your connection. Add the code below to your python script and run it, then make yourself a cup of your chosen beverage.\n\n\noffset = len(gdf) # number of records to offset by\nall_lsoas = gdf # we can append our growing gdf of LSOA boundaries to this\nwhile more_pages:\n    params[\"resultOffset\"] += offset # increment the records to ingest\n    response, gdf = request_to_gdf(ENDPOINT, params)\n    content = response.json()\n    all_lsoas = pd.concat([all_lsoas, gdf])\n    try:\n        more_pages = content[\"properties\"][\"exceededTransferLimit\"]\n    except KeyError:\n        # rather than exceededTransferLimit = False, it disappears...\n        more_pages = False\n\nall_lsoas = all_lsoas.reset_index(drop=True)\n\nBe careful with the exceededTransferLimit parameter. Instead of being set to False on the last page (as the docs suggest it should) - it actually disappears instead, hence why I use the try:...except clause above. You can attempt to set this parameter explicitly, but I find this makes no difference.\n\nparams[\"returnExceededLimitFeatures\"] = \"true\"\n# or\nparams[\"returnExceededLimitFeatures\"] = True\n# both patterns result in the same behaviour as not setting it - the \n# [\"properties\"][\"exceededTransferLimit\"] key disappears from the final page's\n# response\n\n\nCheck whether the number of records ingested matches the number expected.\n\n\n\nShow the Solution\nall_done = len(all_lsoas) == n_records\nprint(f\"Does the row count match the expected number of records? {all_done}\")\n\n\nDoes the row count match the expected number of records? True\n\n\n\nFinally, visualise the last 100 records available within the GeoDataFrame.\n\n\n\nShow the Solution\nall_lsoas.tail(100).explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html#troubleshooting",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html#troubleshooting",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nOne tip I have for troubleshooting queries is to open up the web interface for the ENDPOINT, by pasting it into your web browser. You should get an interface like below:\n\n\n\nBy using the fields to test out your query parameters and clicking the “Query (GET)” button at the bottom of the page, you can get an indication of whether your query is valid. This is a good place to test out more complex SQL statements for the where parameter:"
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html#conclusion",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html#conclusion",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "Conclusion",
    "text": "Conclusion\nIn this tutorial, we have:\n\nDemonstrated how to find resources on ONS Open Geography Portal.\nFound the ArcGIS endpoint url of that resource.\nHad a brief read through the ArcGIS documentation.\nQueried the API for a single LSOA code.\nDiscussed a few of the quirks of this API.\nRetrieved the total number of records available.\nUsed paginated requests to retrieve every record in the database.\n\nA good next step towards a more robust ingestion method would be to consider adding a retry strategy to the requests [3]. For a great overview of the essentials of geographic data and tools, check out my colleague’s fantastic blog on geospatial need-to-knows [4].\nEvery web API has its own quirks, which is part of the joy of working with web data. I hope this was helpful and all the best with your geospatial data project!"
  },
  {
    "objectID": "blogs/06-working-with-ONS-open-geo-portal.html#special-thanks",
    "href": "blogs/06-working-with-ONS-open-geo-portal.html#special-thanks",
    "title": "Getting Data from ONS Open Geography Portal",
    "section": "Special Thanks…",
    "text": "Special Thanks…\n…to my colleague Edward, for working through this blog and providing me with really useful feedback.\n\nfin!"
  },
  {
    "objectID": "blogs/16-pytest-marks.html",
    "href": "blogs/16-pytest-marks.html",
    "title": "Custom Marks With Pytest in Plain English",
    "section": "",
    "text": "Planet composed of croissants."
  },
  {
    "objectID": "blogs/16-pytest-marks.html#introduction",
    "href": "blogs/16-pytest-marks.html#introduction",
    "title": "Custom Marks With Pytest in Plain English",
    "section": "Introduction",
    "text": "Introduction\npytest is a testing package for the python framework. It is broadly used to quality assure code logic. This article discusses custom marks, use cases and patterns for selecting and deselecting marked tests. This blog is the fifth and final in a series of blogs called pytest in plain English, favouring accessible language and simple examples to explain the more intricate features of the pytest package.\nFor a wealth of documentation, guides and how-tos, please consult the pytest documentation.\n\nWhat are pytest Custom Marks?\nMarks are a way to conditionally run specific tests. There are a few marks that come with the pytest package. To view these, run pytest --markers from the command line. This will print a list of the pre-registered marks available within the pytest package. However, it is extremely easy to register your own markers, allowing greater control over which tests get executed.\nThis article will cover:\n\nReasons for marking tests\nRegistering marks with pytest\nMarking tests\nIncluding or excluding markers from the command line\n\n\n\n\n\n\n\nA Note on the Purpose (Click to expand)\n\n\n\n\n\nThis article intends to discuss clearly. It doesn’t aim to be clever or impressive. Its aim is to extend understanding without overwhelming the reader. The code may not always be optimal, favouring a simplistic approach wherever possible.\n\n\n\n\n\nIntended Audience\nProgrammers with a working knowledge of python and some familiarity with pytest and packaging. The type of programmer who has wondered about how to follow best practice in testing python code.\n\n\nWhat You’ll Need:\n\nPreferred python environment manager (eg conda)\npip install pytest==8.1.1\nGit\nGitHub account\nCommand line access\n\n\n\nPreparation\nThis blog is accompanied by code in this repository. The main branch provides a template with the minimum structure and requirements expected to run a pytest suite. The repo branches contain the code used in the examples of the following sections.\nFeel free to fork or clone the repo and checkout to the example branches as needed.\nThe example code that accompanies this article is available in the marks branch of the repo."
  },
  {
    "objectID": "blogs/16-pytest-marks.html#overview",
    "href": "blogs/16-pytest-marks.html#overview",
    "title": "Custom Marks With Pytest in Plain English",
    "section": "Overview",
    "text": "Overview\nOccasionally, we write tests that are a bit distinct to the rest of our test suite. They could be integration tests, calling on elements of our code from multiple modules. They could be end to end tests, executing a pipeline from start to finish. Or they could be a flaky or brittle sort of test, a test that is prone to failure on specific operating systems, architectures or when external dependencies do not provide reliable inputs.\nThere are multiple ways to handle these kinds of tests, including mocking, as discussed in my previous blog. Mocking can often take a bit of time, and developers don’t always have that precious commodity. So instead, they may mark the test, ensuring that it doesn’t get run on continuous integration (CI) checks. This may involve flagging any flaky test as “technical debt” to be investigated and fixed later.\nIn fact, there are a number of reasons that we may want to selectively run elements of a test suite. Here is a selection of scenarios that could benefit from marking.\n\n\n\n\n\n\nFlaky Tests: Common Causes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCategory\nCause\nExplanation\n\n\n\n\nExternal Dependencies\nNetwork\nNetwork latency, outages, or Domain Name System (DNS) issues.\n\n\n\nWeb APIs\nBreaking changes, rate limits, or outages.\n\n\n\nDatabases\nConcurrency issues, data changes, or connection problems.\n\n\n\nTimeouts\nHardcoded or too-short timeouts cause failures.\n\n\nEnvironment Dependencies\nEnvironment Variables\nIncorrectly set environment variables.\n\n\n\nFile System\nFile locks, permissions, or missing files.\n\n\n\nResource Limits\nInsufficient CPU, memory, or disk space.\n\n\nState Dependencies\nShared State\nInterference between tests sharing state.\n\n\n\nOrder Dependency\nTests relying on execution order.\n\n\nTest Data\nRandom Data\nDifferent results on each run due to random data and seed not set.\n\n\nConcurrency Issues\nParallel Execution\nTests not designed for parallel execution.\n\n\n\nLocks\nDeadlocks or timeouts involving locks or semaphores.\n\n\n\nRace Conditions\nTests depend on the order of execution of threads or processes.\n\n\n\nAsync Operations\nImproperly awaited asynchronous code.\n\n\nHardware and System Issues\nDifferences in Hardware\nVariations in performance across hardware or operating systems.\n\n\n\nSystem Load\nFailures under high system load due to resource contention.\n\n\nNon-deterministic Inputs\nTime\nVariations in current time affecting test results.\n\n\n\nUser Input\nNon-deterministic user input causing flaky behaviour.\n\n\n\nFilepaths\nCI runner filepaths may be hard to predict.\n\n\nTest Implementation Issues\nAssertions\nIncorrect or overly strict assertions.\n\n\n\nSetup and Teardown\nInconsistent state due to improper setup or teardown.\n\n\n\n\n\n\n\nIn the case of integration tests, one approach may be to group them all together and have them execute within a dedicated CI workflow. This is common practice as developers may want to stay alert to problems with external resources that their code depends upon, while not failing ‘core’ CI checks about changes to the source code. If your code relies on a web API; for instance; you’re probably less concerned about temporary outages in that service. However, a breaking change to that service would require our source code to be adapted. Once more, life is a compromise.\n\n“Le mieux est l’ennemi du bien.” (The best is the enemy of the good), Voltaire"
  },
  {
    "objectID": "blogs/16-pytest-marks.html#custom-marks-in-pytest",
    "href": "blogs/16-pytest-marks.html#custom-marks-in-pytest",
    "title": "Custom Marks With Pytest in Plain English",
    "section": "Custom Marks in pytest",
    "text": "Custom Marks in pytest\nMarking allows us to have greater control over which of our tests are executed when we invoke pytest. Marking is conveniently implemented in the following way (presuming you have already written your source and test code):\n\nRegister a custom marker\nAssign the new marker name to the target test\nInvoke pytest with the -m (MARKEXPR) flag.\n\nThis section uses code available in the marks branch of the GitHub repository.\n\nDefine the Source Code\nI have a motley crew of functions to consider. A sort of homage to Sergio Leone’s ‘The Good, The Bad & the Ugly’, although I’ll let you figure out which is which.\n\n\n\nThe Flaky, The Slow & The Needy\n\n\n\nThe Flaky Function\nHere we define a function that will fail half the time. What a terrible test to have. The root of this unpredictable behaviour should be diagnosed as a priority as a matter of sanity.\n\nimport random\n\n\ndef croissant():\n    \"\"\"A very flaky function.\"\"\"\n    if round(random.uniform(0, 1)) == 1:\n        return True\n    else:\n        raise Exception(\"Flaky test detected!\")\n\n\n\nThe Slow Function\nThis function is going to be pretty slow. Slow test suites throttle our productivity. Once it finishes waiting for a specified number of seconds, it will return a string.\n\nimport time\nfrom typing import Union\n\n\ndef take_a_nap(how_many_seconds:Union[int, float]) -&gt; str:\n    \"\"\"Mimic a costly function by just doing nothing for a specified time.\"\"\"\n    time.sleep(float(how_many_seconds))\n    return \"Rise and shine!\"\n\n\n\nThe Needy Function\nFinally, the needy function will have an external dependency on a website. This test will simply check whether we get a HTTP status code of 200 (ok) when we request any URL.\n\nimport requests\n\n\ndef check_site_available(url:str, timeout:int=5) -&gt; bool:\n    \"\"\"Checks if a site is available.\"\"\"\n    try:\n        response = requests.get(url, timeout=timeout)\n        return True if response.status_code == 200 else False\n    except requests.RequestException:\n        return False\n\n\n\nThe Wrapper\nFinally, I’ll introduce a wrapper that will act as an opportunity for an integration test. This is a bit awkward, as none of the above functions are particularly related to each other.\nThis function will execute the check_site_available() and take_a_nap() together. A pretty goofy example, I admit. Based on the status of the url request, a string will be returned.\n\nimport time\nfrom typing import Union\n\nimport requests\n\ndef goofy_wrapper(url:str, timeout:int=5) -&gt; str:\n    \"\"\"Check a site is available, pause for no good reason before summarising\n    outcome with a string.\"\"\"\n    msg = f\"Napping for {timeout} seconds.\\n\"\n    msg = msg + take_a_nap(timeout)\n    if check_site_available(url):\n        msg = msg + \"\\nYour site is up!\"\n    else:\n        msg = msg + \"\\nYour site is down!\"\n\n    return msg\n\n\n\n\nLet’s Get Testing\nInitially, I will define a test that does nothing other than pass. This will be a placeholder, unmarked test.\n\ndef test_nothing():\n    pass\n\nNext, I import croissant() and assert that it returns True. As you may recall from above, croissant() will do so ~50 % of the time.\n\nfrom example_pkg.do_something import (\n    croissant,\n    )\n\n\ndef test_nothing():\n    pass\n\n\ndef test_croissant():\n    assert croissant()\n\nNow running pytest -v will print the test results, reporting test outcomes for each test separately (-v means verbose).\n...% pytest -v\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 2 items                                                             \ntests/test_do_something.py::test_nothing PASSED                          [ 50%]\ntests/test_do_something.py::test_croissant PASSED                        [100%]\n============================== 2 passed in 0.05s ==============================\nBut note that half the time, I will also get the following output:\n...% pytest -v\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 2 items                         \n\ntests/test_do_something.py::test_nothing PASSED                          [ 50%]\ntests/test_do_something.py::test_croissant FAILED                        [100%]\n\n================================== FAILURES ==================================\n_______________________________ test_croissant ________________________________\n    @pytest.mark.flaky\n    def test_croissant():\n&gt;       assert croissant()\ntests/test_do_something.py:17: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n    def croissant():\n        \"\"\"A very flaky function.\"\"\"\n        if round(random.uniform(0, 1)) == 1:\n            return True\n        else:\n&gt;           raise Exception(\"Flaky test detected!\")\nE           Exception: Flaky test detected!\n\nsrc/example_pkg/do_something.py:13: Exception\n============================short test summary info ===========================\nFAILED ...::test_croissant - Exception: Flaky test detected!\n========================= 1 failed, 1 passed in 0.07s =========================\nTo prevent this flaky test from failing the test suite, we can choose to mark it as flaky, and optionally skip it when invoking pytest. To go about that, we first need to register a new marker. To do that, let’s update out project’s pyproject.toml to include additional options for a flaky mark:\n# `pytest` configurations\n[tool.pytest.ini_options]\nmarkers = [\n    \"flaky: tests that can randomly fail through no change to the code\",\n]\nNote that when registering a marker in this way, text after the colon is an optional mark description. Saving the document and running pytest --markers should show that a new custom marker is available to our project:\n... % pytest --markers\n@pytest.mark.flaky: tests that can randomly fail through no change to the code\n...\nNow that we have confirmed our marker is available for use, we can use it to mark test_croissant() as flaky:\n\nimport pytest\n\nfrom example_pkg.do_something import (\n    croissant,\n    )\n\n\ndef test_nothing():\n    pass\n\n\n@pytest.mark.flaky\ndef test_croissant():\n    assert croissant()\n\nNote that we need to import pytest to our test module in order to use the pytest.mark.&lt;MARK_NAME&gt; decorator.\n\nSelecting a Single Mark\nNow that we have registered and marked a test as flaky, we can adapt our pytest call to execute tests with that mark only. The pattern we will use is:\n\npytest -k -m \"&lt;INSERT_MARK_NAME&gt;\"\n\n... % pytest -v -m \"flaky\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 2 items / 1 deselected / 1 selected                                 \n\ntests/test_do_something.py::test_croissant PASSED                        [100%]\n\n======================= 1 passed, 1 deselected in 0.05s =======================\nNow we see that test_croissant() was executed, while the unmarked test_nothing() was not.\n\n\nDeselecting a Single Mark\nMore useful than selectively running a flaky test is to deselect it. In this way, it cannot fail our test suite. This is achieved with the following pattern:\n\npytest -v -m \"not &lt;INSERT_MARK_NAME&gt;\"\n\n... % pytest -v -m \"not flaky\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 2 items / 1 deselected / 1 selected                                  \n\ntests/test_do_something.py::test_nothing PASSED                          [100%]\n\n======================= 1 passed, 1 deselected in 0.05s =======================\nNote that this time, test_flaky() was not executed.\n\n\nSelecting Multiple Marks\nIn this section, we will introduce another, differently marked test to illustrate the syntax for running multiple marks. For this example, we’ll test take_a_nap():\n\nimport pytest\n\nfrom example_pkg.do_something import (\n    croissant,\n    take_a_nap,\n    )\n\n\ndef test_nothing():\n    pass\n\n\n@pytest.mark.flaky\ndef test_croissant():\n    assert croissant()\n\n\n@pytest.mark.slow\ndef test_take_a_nap():\n    out = take_a_nap(how_many_seconds=3)\n    assert isinstance(out, str), f\"a string was not returned: {type(out)}\"\n    assert out == \"Rise and shine!\", f\"unexpected string pattern: {out}\"\n\nOur new test just makes some simple assertions about the string take_a_nap() returns after snoozing. But notice what happens when running pytest -v now:\n... % pytest -v\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 3 items                                                             \n\ntests/test_do_something.py::test_nothing PASSED                          [ 33%]\ntests/test_do_something.py::test_croissant PASSED                        [ 66%]\ntests/test_do_something.py::test_take_a_nap PASSED                       [100%]\n\n============================== 3 passed in 3.07s ==============================\nThe test suite now takes in excess of 3 seconds to execute, as the test specified for take_a_nap() to sleep for that period. Let’s update our pyproject.toml and register a new mark:\n# `pytest` configurations\n[tool.pytest.ini_options]\nmarkers = [\n    \"flaky: tests that can randomly fail through no change to the code\",\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n]\nNote that the nested speech marks within the description of the slow mark were escaped. pytest would have complained that the toml file was not valid unless we ensured it was valid toml syntax.\nIn order to run tests marked with either flaky or slow, we can use or:\n\npytest -v -m \"&lt;INSERT_MARK_1&gt; or &lt;INSERT_MARK_2&gt;\"\n\n... % pytest -v -m \"flaky or slow\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 3 items / 1 deselected / 2 selected                                 \n\ntests/test_do_something.py::test_croissant PASSED                        [ 50%]\ntests/test_do_something.py::test_take_a_nap PASSED                       [100%]\n\n======================= 2 passed, 1 deselected in 3.06s =======================\nNote that anything not marked with flaky or slow (eg test_nothing()) was not run. Also, test_croissant() failed 3 times in a row while I tried to get a passing run. I didn’t want the flaky exception to carry on presenting itself. While I may be sprinkling glitter, I do not want to misrepresent how frustrating flaky tests can be!\n\nGlitter GIFfrom Glitter GIFs\n\n\n\n\nComplex Selection Rules\nBy adding an additional mark, we can illustrate more complex selection and deselection rules for invoking pytest. Let’s write an integration test that checks whether the domain for this blog site can be reached.\n\nimport pytest\n\nfrom example_pkg.do_something import (\n    croissant,\n    take_a_nap,\n    check_site_available,\n    )\n\n\ndef test_nothing():\n    pass\n\n\n@pytest.mark.flaky\ndef test_croissant():\n    assert croissant()\n\n\n@pytest.mark.slow\ndef test_take_a_nap():\n    out = take_a_nap(how_many_seconds=3)\n    assert isinstance(out, str), f\"a string was not returned: {type(out)}\"\n    assert out == \"Rise and shine!\", f\"unexpected string pattern: {out}\"\n\n\n@pytest.mark.integration\ndef test_check_site_available():\n    url = \"https://thedatasavvycorner.com/\"\n    assert check_site_available(url), f\"site {url} is down...\"\n\nNow updating our pyproject.toml like so:\n# `pytest` configurations\n[tool.pytest.ini_options]\nmarkers = [\n    \"flaky: tests that can randomly fail through no change to the code\",\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n    \"integration: tests that require external resources\",\n]\nNow we can combine and and not statements when calling pytest to execute just the tests we need to. In the below, I choose to run the slow and integration tests while excluding that pesky flaky test.\n... % pytest -v -m \"slow or integration and not flaky\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 4 items / 2 deselected / 2 selected                                 \n\ntests/test_do_something.py::test_take_a_nap PASSED                       [ 50%]\ntests/test_do_something.py::test_check_site_available PASSED             [100%]\n\n======================= 2 passed, 2 deselected in 3.29s =======================\nNote that both test_nothing() (unmarked) and test_croissant() (deselected) were not run.\n\n\nMarks and Test Classes\nNote that so far, we have applied marks to test functions only. But we can also apply marks to an entire test class, or even target specific test modules. For this section, I will introduce the wrapper function introduced earlier and use a test class to group its tests together. I will mark those tests with 2 new marks, classy and subclassy.\n# `pytest` configurations\n[tool.pytest.ini_options]\nmarkers = [\n    \"flaky: tests that can randomly fail through no change to the code\",\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n    \"integration: tests that require external resources\",\n    \"classy: tests arranged in a class\",\n    \"subclassy: test methods\",\n]\nUpdating our test module to include test_goofy_wrapper():\n\nimport pytest\n\nfrom example_pkg.do_something import (\n    croissant,\n    take_a_nap,\n    check_site_available,\n    goofy_wrapper\n    )\n\n\ndef test_nothing():\n    pass\n\n\n@pytest.mark.flaky\ndef test_croissant():\n    assert croissant()\n\n\n@pytest.mark.slow\ndef test_take_a_nap():\n    out = take_a_nap(how_many_seconds=3)\n    assert isinstance(out, str), f\"a string was not returned: {type(out)}\"\n    assert out == \"Rise and shine!\", f\"unexpected string pattern: {out}\"\n\n\n@pytest.mark.integration\ndef test_check_site_available():\n    url = \"https://thedatasavvycorner.com/\"\n    assert check_site_available(url), f\"site {url} is down...\"\n\n\n@pytest.mark.classy\nclass TestGoofyWrapper:\n    @pytest.mark.subclassy\n    def test_goofy_wrapper_url_exists(self):\n        assert goofy_wrapper(\n            \"https://thedatasavvycorner.com/\", 1\n            ).endswith(\"Your site is up!\"), \"The site wasn't up.\"\n    @pytest.mark.subclassy\n    def test_goofy_wrapper_url_does_not_exist(self):\n        assert goofy_wrapper(\n            \"https://thegoofycorner.com/\", 1\n            ).endswith(\"Your site is down!\"), \"The site wasn't down.\"\n\nNote that targeting either the classy or subclassy mark results in the same output - all tests within this test class are executed:\n... % pytest -v -m \"classy\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 6 items / 4 deselected / 2 selected                                 \n\nTestGoofyWrapper::test_goofy_wrapper_url_exists PASSED                   [ 50%]\nTestGoofyWrapper::test_goofy_wrapper_url_does_not_exist PASSED           [100%]\n\n======================= 2 passed, 4 deselected in 2.30s =======================\nNobody created the domain https://thegoofycorner.com/ yet, such a shame.\n\n\nTests with Multiple Marks\nNote that we can use multiple marks with any test or test class. Let’s update TestGoofyWrapper to be marked as integration & slow:\n\n@pytest.mark.slow\n@pytest.mark.integration\n@pytest.mark.classy\nclass TestGoofyWrapper:\n    @pytest.mark.subclassy\n    def test_goofy_wrapper_url_exists(self):\n        assert goofy_wrapper(\n            \"https://thedatasavvycorner.com/\", 1\n            ).endswith(\"Your site is up!\"),\"The site wasn't up.\"\n    @pytest.mark.subclassy\n    def test_goofy_wrapper_url_does_not_exist(self):\n        assert goofy_wrapper(\n            \"https://thegoofycorner.com/\", 1\n            ).endswith(\"Your site is down!\"), \"The site wasn't down.\"\n\nThis test class can now be exclusively targeted by specifying multiple marks with and:\n\npytest -v -m \"&lt;INSERT_MARK_1&gt; and &lt;INSERT_MARK2&gt;... and &lt;INSERT_MARK_N&gt;\"\n\n\n... % pytest -v -m \"integration and slow\"   \n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- /...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 6 items / 4 deselected / 2 selected                                 \n\nTestGoofyWrapper::test_goofy_wrapper_url_exists PASSED                   [ 50%]\nTestGoofyWrapper::test_goofy_wrapper_url_does_not_exist PASSED           [100%]\n\n======================= 2 passed, 4 deselected in 2.30s =======================\nNote that even though there are other tests marked with integration and slow separately, they are excluded on the basis that and expects them to be marked with both.\n\n\nDeselecting All Marks\nNow that we have introduced multiple custom markers to our test suite, what if we want to exclude all of these marked tests, just running the ‘core’ test suite? Unfortunately, there is not a way to specify ‘unmarked’ tests. There is an old pytest plugin called pytest-unmarked that allowed this functionality. Unfortunately, this plugin is not being actively maintained and is not compatible with pytest v8.0.0+. You could introduce a ‘standard’ or ‘core’ marker, but you’d need to remember to mark every unmarked test within your test suite with it.\nAlternatively, what we can do is exclude each of the marks that have been registered. There are 2 patterns for achieving this:\n\n\npytest -v -m \"not &lt;INSERT_MARK_1&gt; ... or not &lt;INSERT_MARK_N&gt;\"\npytest -v -m \"not (&lt;INSERT_MARK_1&gt; ... or &lt;INSERT_MARK_N&gt;)\"\n\n\n... % pytest -v -m \"not (flaky or slow or integration)\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 -- ...\ncachedir: .pytest_cache\nrootdir: /...\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 6 items / 5 deselected / 1 selected                                 \n\ntests/test_do_something.py::test_nothing PASSED                          [100%]\n\n======================= 1 passed, 5 deselected in 0.05s =======================\nNote that using or has greedily excluded any test marked with at least one of the specified marks."
  },
  {
    "objectID": "blogs/16-pytest-marks.html#summary",
    "href": "blogs/16-pytest-marks.html#summary",
    "title": "Custom Marks With Pytest in Plain English",
    "section": "Summary",
    "text": "Summary\nRegistering marks with pytest is very easy and is useful for controlling which tests are executed. We have illustrated:\n\nregistering marks\nmarking tests and test classes\nthe use of the pytest -m flag\nselection of multiple marks\ndeselection of multiple marks\n\nOverall, this feature of pytest is simple and intuitive. There are more options for marking tests. I recommend reading the pytest custom markers examples for more information.\nAs mentioned earlier, this is the final in the pytest in plain English series. I will be taking a break from blogging about testing for a while. But colleagues have asked about articles on property-based testing and some of the more useful pytest plug-ins. I plan to cover these topics at a later date.\nIf you spot an error with this article, or have a suggested improvement then feel free to raise an issue on GitHub.\nHappy testing!"
  },
  {
    "objectID": "blogs/16-pytest-marks.html#acknowledgements",
    "href": "blogs/16-pytest-marks.html#acknowledgements",
    "title": "Custom Marks With Pytest in Plain English",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo past and present colleagues who have helped to discuss pros and cons, establishing practice and firming-up some opinions. Particularly:\n\nEthan\nSergio\n\n\nfin!"
  },
  {
    "objectID": "blogs/10-pydeck-with-gpd.html",
    "href": "blogs/10-pydeck-with-gpd.html",
    "title": "Getting Pydeck to Play Nicely with GeoPandas.",
    "section": "",
    "text": "Creative commons license by Prompart"
  },
  {
    "objectID": "blogs/10-pydeck-with-gpd.html#introduction",
    "href": "blogs/10-pydeck-with-gpd.html#introduction",
    "title": "Getting Pydeck to Play Nicely with GeoPandas.",
    "section": "Introduction",
    "text": "Introduction\nPydeck is a python client for pydeck.gl, a powerful geospatial visualisation library. It’s a relatively new library and integrating it with the existing python geospatial ecosystem is currently a little tricky. This article demonstrates how to build pydeck ScatterplotLayer and GeoJsonLayer from geopandas GeoDataFrames.\n\nPydeck documentation\nDeck.gl documentation\n\n\n\n\n\n\n\nA Note on the Purpose\n\n\n\n\n\nThe content of this article was written using pydeck 0.8.0. Future releases may alter the package behaviour.\n\n\n\n\nIntended Audience\nPython practitioners familiar with virtual environments, requests and geospatial analysis with geopandas.\n\n\nThe Scenario\nYou have a geopandas GeoDataFrame with point or polygon geometries. You are attempting to build a pydeck visualisation but end up with empty basemap tiles.\n\n\nWhat You’ll Need:\n\nPreferred python environment manager (eg conda)\nPython package manager (eg pip)\nrequirements.txt:\n\n\n\nrequirements.txt\n\ngeopandas\npandas\npydeck\nrequests"
  },
  {
    "objectID": "blogs/10-pydeck-with-gpd.html#prepare-environment",
    "href": "blogs/10-pydeck-with-gpd.html#prepare-environment",
    "title": "Getting Pydeck to Play Nicely with GeoPandas.",
    "section": "Prepare Environment",
    "text": "Prepare Environment\n\nCreate a virtual environment.\nInstall the required dependencies.\nActivate the virtual environment.\nCreate a python script and import the dependencies.\n\n\nimport json\n\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nimport pydeck as pdk\nimport requests\nfrom sklearn import preprocessing"
  },
  {
    "objectID": "blogs/10-pydeck-with-gpd.html#build-a-scatterplotlayer",
    "href": "blogs/10-pydeck-with-gpd.html#build-a-scatterplotlayer",
    "title": "Getting Pydeck to Play Nicely with GeoPandas.",
    "section": "Build a ScatterplotLayer",
    "text": "Build a ScatterplotLayer\n\nIngest Data\nFor the point data, I will ingest all Welsh lower super output area 2021 population-weighted centroids from ONS Open Geography Portal.\nFor more on working with ONS Open Geography Portal, see Getting Data from ONS Open Geography Portal.\n\n\nShow the code\nENDPOINT = \"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/LLSOA_Dec_2021_PWC_for_England_and_Wales_2022/FeatureServer/0/query\"\nPARAMS = {\n    \"where\": \"LSOA21CD like 'W%'\",\n    \"f\": \"geoJSON\", \n    \"outFields\": \"*\",\n    \"outSR\": 4326,\n}\nresp = requests.get(ENDPOINT, params=PARAMS)\nif resp.ok:\n    content = resp.json()\nelse:\n    raise requests.RequestException(f\"HTTP {resp.status_code} : {resp.reason}\")\n\ncentroids = gpd.GeoDataFrame.from_features(\n    features=content[\"features\"], crs=content[\"crs\"][\"properties\"][\"name\"])\ncentroids.head()\n\n\n\n\n\n\n\n\n\ngeometry\nFID\nLSOA21CD\nGlobalID\n\n\n\n\n0\nPOINT (-3.27237 52.76593)\n68\nW01000461\n205abce3-aa73-408a-ab25-1c8364c12a63\n\n\n1\nPOINT (-3.21395 51.77614)\n92\nW01001459\n963a18d4-f225-4273-80aa-26c01236af11\n\n\n2\nPOINT (-3.20681 51.78261)\n133\nW01001456\n71e6c3f6-7e87-4cea-9256-97aa366cac43\n\n\n3\nPOINT (-2.68552 51.64398)\n194\nW01001585\ndf9d1950-64cd-42d4-a8fd-18c989951e27\n\n\n4\nPOINT (-3.09114 51.82767)\n203\nW01001563\nb2cc735d-c637-40dc-9871-cb8ac5bca9c3\n\n\n\n\n\n\n\nThe geometry column is not in a format that pydeck will accept. Adding a column with a list of long,lat values for each coordinate will do the trick.\n\ncentroids[\"pydeck_geometry\"] = [[c.x, c.y] for c in centroids[\"geometry\"]]\ncentroids.head()\n\n\n\n\n\n\n\n\ngeometry\nFID\nLSOA21CD\nGlobalID\npydeck_geometry\n\n\n\n\n0\nPOINT (-3.27237 52.76593)\n68\nW01000461\n205abce3-aa73-408a-ab25-1c8364c12a63\n[-3.27236528249052, 52.7659297296924]\n\n\n1\nPOINT (-3.21395 51.77614)\n92\nW01001459\n963a18d4-f225-4273-80aa-26c01236af11\n[-3.2139466137404, 51.7761398048545]\n\n\n2\nPOINT (-3.20681 51.78261)\n133\nW01001456\n71e6c3f6-7e87-4cea-9256-97aa366cac43\n[-3.20681397850058, 51.7826095824385]\n\n\n3\nPOINT (-2.68552 51.64398)\n194\nW01001585\ndf9d1950-64cd-42d4-a8fd-18c989951e27\n[-2.68552245106253, 51.6439814411607]\n\n\n4\nPOINT (-3.09114 51.82767)\n203\nW01001563\nb2cc735d-c637-40dc-9871-cb8ac5bca9c3\n[-3.09114462316771, 51.8276689661644]\n\n\n\n\n\n\n\n\n\nPydeck Visualisation\nWith the correct geometry format, the scatterplot is trivial.\n\n\n\n\n\n\nTip\n\n\n\nControl the map by click and dragging the map with your mouse. Hold shift + click and drag to yaw or pitch the map. Scroll in and out to alter the zoom.\n\n\n\nscatter = pdk.Layer(\n    \"ScatterplotLayer\",\n    centroids,\n    pickable=True,\n    stroked=True,\n    filled=True,\n    line_width_min_pixels=1,\n    get_position=\"pydeck_geometry\",\n    get_fill_color=[255, 140, 0],\n    get_line_color=[255, 140, 0],\n    radius_min_pixels=3,\n    opacity=0.1,\n)\n# Set the viewport location\nview_state = pdk.ViewState(\n    longitude=-2.84,\n    latitude=52.42,\n    zoom=6.5,\n    max_zoom=15,\n    pitch=0,\n    bearing=0,\n)\ntooltip = {\n    \"text\": \"LSOA21CD: {LSOA21CD}\"\n}\n# Render\nr = pdk.Deck(\n    layers=scatter, initial_view_state=view_state, tooltip=tooltip\n)\nr"
  },
  {
    "objectID": "blogs/10-pydeck-with-gpd.html#build-a-geojsonlayer",
    "href": "blogs/10-pydeck-with-gpd.html#build-a-geojsonlayer",
    "title": "Getting Pydeck to Play Nicely with GeoPandas.",
    "section": "Build a GeoJsonLayer",
    "text": "Build a GeoJsonLayer\nGeoJsonLayer is what tends to be used for presenting polygons with pydeck maps. The pydeck docs GeoJsonLayer example uses geoJSON data hosted on GitHub. But with a little effort, a Geopandas GeoDataFrame can be coerced to the necessary format.\n\nIngest Data\nTo demonstrate working with polygons, the Welsh super generalised 2023 local authority district boundaries will be ingested from ONS Open Geography Portal.\nAs elevation and polygon colour will be controlled by features of the data, sklearn.prepeocessing is used to scale the “Shape__Area” column.\n\n\nShow the code\nENDPOINT=\"https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/Local_Authority_Districts_December_2023_Boundaries_UK_BSC/FeatureServer/0/query\"\nPARAMS[\"where\"] = \"LAD23CD like 'W%'\"\nresp = requests.get(ENDPOINT, params=PARAMS)\nif resp.ok:\n    content = resp.json()\nelse:\n    raise requests.RequestException(f\"HTTP {resp.status_code} : {resp.reason}\")\n\npolygons = gpd.GeoDataFrame.from_features(\n    features=content[\"features\"], crs=content[\"crs\"][\"properties\"][\"name\"])\n# feature engineering for pydeck viz\nmin_max_scaler = preprocessing.MinMaxScaler()\nx = polygons[\"Shape__Area\"].values.reshape(-1, 1)\nx_scaled = min_max_scaler.fit_transform(x)\npolygons[\"area_norm\"] = pd.Series(x_scaled.flatten())\npolygons.head()\n\n\n\n\n\n\n\n\n\ngeometry\nFID\nLAD23CD\nLAD23NM\nLAD23NMW\nBNG_E\nBNG_N\nLONG\nLAT\nShape__Area\nShape__Length\nGlobalID\narea_norm\n\n\n\n\n0\nMULTIPOLYGON (((-4.02145 53.32145, -4.03186 53...\n340\nW06000001\nIsle of Anglesey\nYnys Môn\n245217\n378331\n-4.32298\n53.27931\n7.137720e+08\n226738.375131\ndd2ba2ec-78e0-4113-bfec-5bbf7828fb0b\n0.118905\n\n\n1\nMULTIPOLYGON (((-3.93116 52.55401, -3.93293 52...\n341\nW06000002\nGwynedd\nGwynedd\n280555\n334966\n-3.77715\n52.89883\n2.550513e+09\n466258.144553\n9436112f-3572-409b-8d93-cf21aaca60d5\n0.479954\n\n\n2\nPOLYGON ((-3.86356 53.34172, -3.84075 53.33698...\n342\nW06000003\nConwy\nConwy\n283293\n362563\n-3.74646\n53.14739\n1.131701e+09\n220424.522936\nd9ae4b38-3437-4e10-8556-03e3b529c5c5\n0.201058\n\n\n3\nPOLYGON ((-3.37625 53.32772, -3.38835 53.32323...\n343\nW06000004\nDenbighshire\nSir Ddinbych\n309843\n355416\n-3.34761\n53.08833\n8.374441e+08\n200171.915162\n22313345-a2d2-4a54-9edc-1f492cd7320e\n0.143215\n\n\n4\nMULTIPOLYGON (((-3.08242 53.25551, -3.08806 53...\n344\nW06000005\nFlintshire\nSir y Fflint\n321134\n369280\n-3.18248\n53.21471\n4.386527e+08\n146522.477076\n693217ec-5c94-4ec1-9d81-eed3f99f1777\n0.064825\n\n\n\n\n\n\n\nIn order to pass the content of this GeoDataFrame to pydeck, use the to_json method to format as a geoJSON string. Then use json.loads() to format that string as a dictionary.\n\n# format data for use in pydeck\njson_out = json.loads(polygons.to_json())\n# inspect the first authority\njson_out[\"features\"][0][\"properties\"]\n\n{'FID': 340,\n 'LAD23CD': 'W06000001',\n 'LAD23NM': 'Isle of Anglesey',\n 'LAD23NMW': 'Ynys Môn',\n 'BNG_E': 245217,\n 'BNG_N': 378331,\n 'LONG': -4.32298,\n 'LAT': 53.27931,\n 'Shape__Area': 713772027.9524,\n 'Shape__Length': 226738.375130659,\n 'GlobalID': 'dd2ba2ec-78e0-4113-bfec-5bbf7828fb0b',\n 'area_norm': 0.11890511689989425}\n\n\n\n\nPydeck Visualisation\nThis format can now be passed to pydeck. One ‘gotcha’ to be aware of, when using attributes in the json to control elevation or colour, the json properties must be explicitly referenced, eg \"properties.area_norm\".\nIn contrast, when using json attributes in the tooltip, you can refer to them directly, eg \"area_norm\".\n\nr = \"100\"\ng = \"(1 - properties.area_norm) * 255\"\nb = \"properties.area_norm * 255\"\nfill = f\"[{r},{g},{b}]\"\ngeojson = pdk.Layer(\n        \"GeoJsonLayer\",\n        json_out,\n        pickable=True,\n        opacity=1,\n        stroked=True,\n        filled=True,\n        extruded=True,\n        wireframe=True,\n        auto_highlight=True,\n        get_elevation=\"properties.area_norm * 200\",\n        elevation_scale=100,\n        get_fill_color=fill,\n    )\ntooltip = {\"text\": \"{LAD23NM}\\n{LAD23CD}\"}\nview_state = pdk.ViewState(\n    longitude=-2.84,\n    latitude=52.42,\n    zoom=6.5,\n    max_zoom=15,\n    pitch=100,\n    bearing=33,\n)\nr = pdk.Deck(\n    layers=geojson,\n    initial_view_state=view_state,\n    tooltip=tooltip,\n)\nr"
  },
  {
    "objectID": "blogs/10-pydeck-with-gpd.html#tips",
    "href": "blogs/10-pydeck-with-gpd.html#tips",
    "title": "Getting Pydeck to Play Nicely with GeoPandas.",
    "section": "Tips",
    "text": "Tips\n\npydeck does not raise when layer data are not formatted correctly. This can result in some lengthy render times only to discover you have an empty map. To combat this, work with the head or some small sample of your data until you have your map working."
  },
  {
    "objectID": "blogs/10-pydeck-with-gpd.html#conclusion",
    "href": "blogs/10-pydeck-with-gpd.html#conclusion",
    "title": "Getting Pydeck to Play Nicely with GeoPandas.",
    "section": "Conclusion",
    "text": "Conclusion\nThis article has recorded the state of play between pydeck and geopandas at the time of writing. Specifically, formatting:\n\ngeometry columns for pydeck ScatterplotLayer\na GeoDataFrame for use with pydeck GeoJsonLayer.\n\nI hope it saves someone some time bashing geopandas about.\n\nfin!"
  },
  {
    "objectID": "blogs/02-getting-started-pyshiny.html",
    "href": "blogs/02-getting-started-pyshiny.html",
    "title": "Let’s Build a Basic Python Shiny App",
    "section": "",
    "text": "Source: https://www.wallpaperflare.com/. Creative Commons License.\n\n\nThis tutorial is intended for those who are already familiar with Python, but may be less familiar with dashboarding and Shiny in Python. It may also be of interest to those who are well-versed in RShiny and would like to see how it has been implemented in Python.\nThis is a light-weight, introductory Python Shiny tutorial. No installation of software is required, other than a web-browser (which you must already have) and a willingness to experiment. We will use the shinylive service to display the application that we write and steadily add to a basic app, discussing some of the concepts as we go. Finally, let’s regroup and reflect on some coping techniques for when you begin writing your own Python Shiny apps.\nThis tutorial will not attempt to reproduce any of Posit’s documentation, which is rather excellent so please check that out. Also, if you would prefer a conceptual treatment of Python Shiny, please see my blog on The Current Stateof Python Shiny.\n\n\n\n\n\n\nHow to…\n\n\n\nFeel free to tinker with the code in the following example apps and then press play in the top-right hand corner of the console interface. Don’t worry - you won’t break anything important. To reset the code, simply refresh your web page.\nIf the app doesn’t launch, you’ll see some spinning grey hexagons that never go away . This is likely to be a problem with permissions in your browser. But you can click on the collapsible code block below the app windows and copy the code to an app.py file on your computer. If you have python and python shiny installed, you should be good to go.\n\n\n\n\nBelow is a really minimal app that doesn’t do very much at all. The python code is presented on the left. The interactive app is presented on the right. You can type into the app’s text field, and that’s about it for now.\n\n\n\n\n\nShow the code\n#1 Import modules to help us build our app\nfrom shiny import ui, App\n\n#^putting things above the app means they can be shared between your ui and server\n\napp_ui = ui.page_fluid(\n  #2 all of the elements you wish to show your user should go within the ui\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        )\n)\n\ndef server(input, output, session):\n  #3 this is where your app logic should go. So far, not much...\n    return None\n  \n# Finally - this bit packages up our ui and server. Super important - it must\n# be named `app`.\n\n\nYou’ll see that the code defines an app_ui object, which is a Shiny ui instance. Within that ui.page_fluid() function, we can specify all the elements of the app that we would like to present to our users.\n\n\n\n\n\n\nOn Users…\n\n\n\nThere are only two industries that call their customers “users”: illegal drugs and software – Edward Tufte\n\n\nSo far, only one simple ui element has been defined. The humble text input ui.input_text() which allows our users to place their own text into a text field.\nNotice that in Python, all the inputs begin with input.... There’s ui.input_text() as we’ve seen, but there’s lots more. ui.input_date(), ui.input_file() and ui.input_slider to name a few. This consistent syntax approach is a subtle improvement over RShiny and makes it so much easier to work with the vast array of widgets without having to remember them all. If you’re working in a modern editor such as Visual Studio Code, simply typing ui.input will remind you of all the options available to you. For those not working in a nice GUI like VSCode, a Shiny cheatsheet may be useful, though note that at the time of writing I could only find R-flavoured ones…\nAll ui input elements start with the same 2 arguments, id and label:\n\nid: The internal name of the input. What does that mean? Call it what you like. Whatever you choose, be aware that when you want to use the values from the text input to do something in the server, it’s this name that you will need to reference.\nlabel: A short piece of text that prompts your user to do something. This will be displayed in your ui above the input element.\n\n\n\n\nUnfortunately, so far our app doesn’t actually do much. Typing into the empty text field yields no result. That’s because right now, our server function simply returns None. Let’s resolve this.\n\n\n\n\n\nShow the code\n#1 update the import statement to include `render` module\nfrom shiny import ui, App, render\n\napp_ui = ui.page_fluid(\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    #2 Include a ui output element. This will show the calculations\n    # made in the server back to the user.\n    ui.output_text_verbatim(\"greeting\"),\n)\n\ndef server(input, output, session):\n    #3 Update the server with a function that handles the text response.\n    @output # use the output decorator to mark this function\n    @render.text # also need to ensure we use the correct render decorator\n    def greeting():\n        \"\"\"\n        This function will take the output of the ui.input_text() element,\n        format the string in a polite sentence and format it as an HTML\n        output for the ui to show.\n        \"\"\"\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\"\n\napp = App(app_ui, server)\n\n\nThere’s quite a lot going on in the above code chunk. Let’s start with the decorators @output & @render.text:\n\n@output: Any function marked with this decorator will have its returned value made available to the user interface. Notice that in the line ui.output_text_verbatim(\"greeting\") we are able to call on the values of the server’s greeting() function that we marked as an @output.\n@render.text: This tells Shiny what type of output to handle. Is it text, a chart (@render.plot) or something more fancy, like dynamically rendered ui (@render.ui). These output types all have their corresponding output functions to use in the ui. Here we called ui.output_text_verbatim().\nCalling the wrong ui-side function may not result in an error, but can have unexpected results, such as your text disappearing from your app. Keep an eye out for that if things aren’t working - are you using the correct combination of render in the server with output_... in the ui?\n\nDid you notice anything off-putting about the above code? Yes, too many comments but please indulge me. Functions in the server and ui are passing values back and forth. That can be a bit overwhelming to get your head around when you’re new to what’s known as ‘event-driven programming’. All that means is that the program needs to respond to some action taken by the user. The syntax in which you reference the functions is a bit inconsistent to my mind. Let’s take a closer look:\nIf I mark some function make_plot() in the server as an @output and then wish to call on its value within the ui, I need to use ui.output_plot(\"make_plot\"). Notice the lack of brackets following the function name \"make_plot\". Getting this wrong will result in a ValueError. Forgetting to wrap the function reference in a string will result in a NameError.\nNow in the other direction, perhaps we have a numeric input passing integer values from the user to the server. We’ll give the slider widget the id=\"int_slider\". Now when we want to use the value of this slider on the server-side, we use a different syntax:\ndef print_selection():\n    n = int_slider()\n    return f\"You chose {n}!\"\nNotice this time, we include brackets after our call to the widget id: n = int_slider(). Weird, right? Getting this wrong may result in unexpected behaviours. Keep an eye out for this. Also, wrapping server id references in speech marks results in unexpected behaviours, but not necessarily errors.\nIf I haven’t lost you yet, well done! Debugging applications can be a very frustrating process - part intuition earned from hours of Shiny debugging, part Stack Overflow and part coping mechanisms. I’ll cover some of those in the Tips section.\n\n\nTry modifying the app provided in the previous examples to repeat the greeting a number of times specified by the user.\n\n\n\n\n\n\nHints. Click to expand if needed.\n\n\n\n\n\n\nYou will need to include a UI input that will collect numbers from the user.\nUpdate the greeting() function to return multiples of the greeting string.\nExplore the other text output functions to avoid the message being truncated.\nIf you’re stuck, click on “Show the code” to see a solution.\n\n\n\n\n\n\n\n\n\nShow the code\nfrom shiny import ui, App, render\n\napp_ui = ui.page_fluid(\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    # 1 update the UI with a way of taking numbers from the user. Here I use a\n    # slider, but a numeric input or even radio buttons would also work.\n    ui.input_slider(\n        id=\"n_greetings\",\n        label=\"number of greetings\", value=1, min=1, max=10, step=1),\n\n    #2 Change to output_text instead of output_text_verbatim, which uses strict\n    # rules for word wrapping and would hide most of a long greeting.\n    ui.output_text(\"greeting\"),\n    ui.tags.br()\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def greeting():\n        \"\"\"\n        This function will take the output of the ui.input_text() element,\n        format the string in a polite sentence and format it as an HTML\n        output for the ui to show.\n        \"\"\"\n        # multiply the greeting string by the number of times the user asked\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\" * input.n_greetings()\n\napp = App(app_ui, server)\n\n\n\n\n\n\nOne final adjustment to this app. When you’re typing a name into the text input field, there’s a bit of a race going on. Can you type faster than the server can render the text? This may not be what you want. In fact, you may require a bunch of selections to be made prior to calculating anything in the server. We can use methods to interrupt and isolate elements of the server. In effect, we can tell any of our server functions to hang fire until a certain condition is met. In this example, we’ll try out perhaps the simplest way of achieving this, enter the ui.input_action_button().\n\n\n\n\n\nShow the code\n#1 Import the reactive module from Shiny\nfrom shiny import ui, render, App, reactive\n\napp_ui = ui.page_fluid(\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    #2 add an action button to the ui, much like we did with the text input\n    ui.input_action_button(id=\"go_button\", label=\"Click to run...\"),\n    # add some visual separation to the text output\n    ui.tags.br(),\n    ui.tags.br(),\n\n    ui.output_text_verbatim(\"greeting\"),\n)\n\ndef server(input, output, session):\n    #3 add an additional mark below the others\n    @output\n    @render.text\n    @reactive.event(input.go_button)\n    def greeting():\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\"\n\n# This is a Shiny.App object. It must be named `app`.\napp = App(app_ui, server)\n\n\nYou should now see that an input button has appeared and the sentence won’t get printed out until you press it.\nAlso notice that the inconsistency in how to refer to functions on the other side of the ui:server divide rears its head once more. All in the server, when we want to use the values returned by the text input, we use the syntax input.name_entry(). When we want to use the action button in the reactive decorator, we have to use input.go_button - no parenthesis! The docs describe this as when you need to access the returned value versus when you need to call the function. This does make sense but can introduce some cognitive conflict while you are working with Shiny. I hope by version 1.0 the development team can find a way to simplify things.\nI also included some visual separation between elements in the ui by using ui.tags.br(). If you know a little HTML, you may get excited at that. You can access all the typical HTML tags in this way:\n\n\n\n\n\nShow the code\nfrom shiny import ui, App, render\n\napp_ui = ui.page_fluid(\n    ui.tags.h1(\"A level 1 heading\"),\n    ui.tags.h2(\"A level 2 heading\"),\n    ui.tags.br(),\n    ui.tags.p(\"Some text \", ui.tags.strong(\"in bold...\"))\n\n)\n\ndef server(input, output, session):\n    return None\n\napp = App(app_ui, server)\n\n\n\n\nDo you know enough markdown syntax to convert the ui below from HTML tags into markdown? This will greatly simplify the code. You will need to use ui.markdown(\"\"\"some multiline markdown\"\"\") to achieve that.\n\n\n\n\n\n\nHints. Click to expand if needed.\n\n\n\n\n\n\nYou can use this markdown cheatsheet to help.\nIf you’re stuck, click on “Show the code” to see an example solution.\n\n\n\n\n\n\n\n\n\nShow the code\n#1 Import the reactive module from Shiny\nfrom shiny import ui, render, App, reactive\n\napp_ui = ui.page_fluid(\n\n    ui.markdown(\n        \"\"\"\n        # Hello Python Shiny!\n        This **simple application** will print you a greeting.\n\n        1. Enter your name\n        2. Click run\n\n        Please visit [some website](https://datasciencecampus.github.io/)\n        for more information\n        ***\n        \"\"\"),\n    \n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    #2 add an action button to the ui, much like we did with the text input\n    ui.input_action_button(id=\"go_button\", label=\"Click to run...\"),\n    # add some visual separation to the text output\n    ui.tags.br(),\n    ui.tags.br(),\n\n    ui.output_text_verbatim(\"greeting\"),\n)\n\ndef server(input, output, session):\n    #3 add an additional mark below the others\n    @output\n    @render.text\n    @reactive.event(input.go_button)\n    def greeting():\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\"\n\n# This is a Shiny.App object. It must be named `app`.\napp = App(app_ui, server)\n\n\nSo there you have it. A very basic application that can be used to print out some simple messages to your user. This is of course a trivial app in order to keep things basic for the purposes of this blog. If you’d like to investigate what’s possible with Shiny, I’d suggest taking a peek through the Posit docs examples and the Python Shiny gallery. In the next section I’ll go over some tips that may help with common pitfalls I’ve encountered while working in Shiny."
  },
  {
    "objectID": "blogs/02-getting-started-pyshiny.html#getting-to-grips-with-python-shiny.",
    "href": "blogs/02-getting-started-pyshiny.html#getting-to-grips-with-python-shiny.",
    "title": "Let’s Build a Basic Python Shiny App",
    "section": "",
    "text": "Source: https://www.wallpaperflare.com/. Creative Commons License.\n\n\nThis tutorial is intended for those who are already familiar with Python, but may be less familiar with dashboarding and Shiny in Python. It may also be of interest to those who are well-versed in RShiny and would like to see how it has been implemented in Python.\nThis is a light-weight, introductory Python Shiny tutorial. No installation of software is required, other than a web-browser (which you must already have) and a willingness to experiment. We will use the shinylive service to display the application that we write and steadily add to a basic app, discussing some of the concepts as we go. Finally, let’s regroup and reflect on some coping techniques for when you begin writing your own Python Shiny apps.\nThis tutorial will not attempt to reproduce any of Posit’s documentation, which is rather excellent so please check that out. Also, if you would prefer a conceptual treatment of Python Shiny, please see my blog on The Current Stateof Python Shiny.\n\n\n\n\n\n\nHow to…\n\n\n\nFeel free to tinker with the code in the following example apps and then press play in the top-right hand corner of the console interface. Don’t worry - you won’t break anything important. To reset the code, simply refresh your web page.\nIf the app doesn’t launch, you’ll see some spinning grey hexagons that never go away . This is likely to be a problem with permissions in your browser. But you can click on the collapsible code block below the app windows and copy the code to an app.py file on your computer. If you have python and python shiny installed, you should be good to go.\n\n\n\n\nBelow is a really minimal app that doesn’t do very much at all. The python code is presented on the left. The interactive app is presented on the right. You can type into the app’s text field, and that’s about it for now.\n\n\n\n\n\nShow the code\n#1 Import modules to help us build our app\nfrom shiny import ui, App\n\n#^putting things above the app means they can be shared between your ui and server\n\napp_ui = ui.page_fluid(\n  #2 all of the elements you wish to show your user should go within the ui\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        )\n)\n\ndef server(input, output, session):\n  #3 this is where your app logic should go. So far, not much...\n    return None\n  \n# Finally - this bit packages up our ui and server. Super important - it must\n# be named `app`.\n\n\nYou’ll see that the code defines an app_ui object, which is a Shiny ui instance. Within that ui.page_fluid() function, we can specify all the elements of the app that we would like to present to our users.\n\n\n\n\n\n\nOn Users…\n\n\n\nThere are only two industries that call their customers “users”: illegal drugs and software – Edward Tufte\n\n\nSo far, only one simple ui element has been defined. The humble text input ui.input_text() which allows our users to place their own text into a text field.\nNotice that in Python, all the inputs begin with input.... There’s ui.input_text() as we’ve seen, but there’s lots more. ui.input_date(), ui.input_file() and ui.input_slider to name a few. This consistent syntax approach is a subtle improvement over RShiny and makes it so much easier to work with the vast array of widgets without having to remember them all. If you’re working in a modern editor such as Visual Studio Code, simply typing ui.input will remind you of all the options available to you. For those not working in a nice GUI like VSCode, a Shiny cheatsheet may be useful, though note that at the time of writing I could only find R-flavoured ones…\nAll ui input elements start with the same 2 arguments, id and label:\n\nid: The internal name of the input. What does that mean? Call it what you like. Whatever you choose, be aware that when you want to use the values from the text input to do something in the server, it’s this name that you will need to reference.\nlabel: A short piece of text that prompts your user to do something. This will be displayed in your ui above the input element.\n\n\n\n\nUnfortunately, so far our app doesn’t actually do much. Typing into the empty text field yields no result. That’s because right now, our server function simply returns None. Let’s resolve this.\n\n\n\n\n\nShow the code\n#1 update the import statement to include `render` module\nfrom shiny import ui, App, render\n\napp_ui = ui.page_fluid(\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    #2 Include a ui output element. This will show the calculations\n    # made in the server back to the user.\n    ui.output_text_verbatim(\"greeting\"),\n)\n\ndef server(input, output, session):\n    #3 Update the server with a function that handles the text response.\n    @output # use the output decorator to mark this function\n    @render.text # also need to ensure we use the correct render decorator\n    def greeting():\n        \"\"\"\n        This function will take the output of the ui.input_text() element,\n        format the string in a polite sentence and format it as an HTML\n        output for the ui to show.\n        \"\"\"\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\"\n\napp = App(app_ui, server)\n\n\nThere’s quite a lot going on in the above code chunk. Let’s start with the decorators @output & @render.text:\n\n@output: Any function marked with this decorator will have its returned value made available to the user interface. Notice that in the line ui.output_text_verbatim(\"greeting\") we are able to call on the values of the server’s greeting() function that we marked as an @output.\n@render.text: This tells Shiny what type of output to handle. Is it text, a chart (@render.plot) or something more fancy, like dynamically rendered ui (@render.ui). These output types all have their corresponding output functions to use in the ui. Here we called ui.output_text_verbatim().\nCalling the wrong ui-side function may not result in an error, but can have unexpected results, such as your text disappearing from your app. Keep an eye out for that if things aren’t working - are you using the correct combination of render in the server with output_... in the ui?\n\nDid you notice anything off-putting about the above code? Yes, too many comments but please indulge me. Functions in the server and ui are passing values back and forth. That can be a bit overwhelming to get your head around when you’re new to what’s known as ‘event-driven programming’. All that means is that the program needs to respond to some action taken by the user. The syntax in which you reference the functions is a bit inconsistent to my mind. Let’s take a closer look:\nIf I mark some function make_plot() in the server as an @output and then wish to call on its value within the ui, I need to use ui.output_plot(\"make_plot\"). Notice the lack of brackets following the function name \"make_plot\". Getting this wrong will result in a ValueError. Forgetting to wrap the function reference in a string will result in a NameError.\nNow in the other direction, perhaps we have a numeric input passing integer values from the user to the server. We’ll give the slider widget the id=\"int_slider\". Now when we want to use the value of this slider on the server-side, we use a different syntax:\ndef print_selection():\n    n = int_slider()\n    return f\"You chose {n}!\"\nNotice this time, we include brackets after our call to the widget id: n = int_slider(). Weird, right? Getting this wrong may result in unexpected behaviours. Keep an eye out for this. Also, wrapping server id references in speech marks results in unexpected behaviours, but not necessarily errors.\nIf I haven’t lost you yet, well done! Debugging applications can be a very frustrating process - part intuition earned from hours of Shiny debugging, part Stack Overflow and part coping mechanisms. I’ll cover some of those in the Tips section.\n\n\nTry modifying the app provided in the previous examples to repeat the greeting a number of times specified by the user.\n\n\n\n\n\n\nHints. Click to expand if needed.\n\n\n\n\n\n\nYou will need to include a UI input that will collect numbers from the user.\nUpdate the greeting() function to return multiples of the greeting string.\nExplore the other text output functions to avoid the message being truncated.\nIf you’re stuck, click on “Show the code” to see a solution.\n\n\n\n\n\n\n\n\n\nShow the code\nfrom shiny import ui, App, render\n\napp_ui = ui.page_fluid(\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    # 1 update the UI with a way of taking numbers from the user. Here I use a\n    # slider, but a numeric input or even radio buttons would also work.\n    ui.input_slider(\n        id=\"n_greetings\",\n        label=\"number of greetings\", value=1, min=1, max=10, step=1),\n\n    #2 Change to output_text instead of output_text_verbatim, which uses strict\n    # rules for word wrapping and would hide most of a long greeting.\n    ui.output_text(\"greeting\"),\n    ui.tags.br()\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def greeting():\n        \"\"\"\n        This function will take the output of the ui.input_text() element,\n        format the string in a polite sentence and format it as an HTML\n        output for the ui to show.\n        \"\"\"\n        # multiply the greeting string by the number of times the user asked\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\" * input.n_greetings()\n\napp = App(app_ui, server)\n\n\n\n\n\n\nOne final adjustment to this app. When you’re typing a name into the text input field, there’s a bit of a race going on. Can you type faster than the server can render the text? This may not be what you want. In fact, you may require a bunch of selections to be made prior to calculating anything in the server. We can use methods to interrupt and isolate elements of the server. In effect, we can tell any of our server functions to hang fire until a certain condition is met. In this example, we’ll try out perhaps the simplest way of achieving this, enter the ui.input_action_button().\n\n\n\n\n\nShow the code\n#1 Import the reactive module from Shiny\nfrom shiny import ui, render, App, reactive\n\napp_ui = ui.page_fluid(\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    #2 add an action button to the ui, much like we did with the text input\n    ui.input_action_button(id=\"go_button\", label=\"Click to run...\"),\n    # add some visual separation to the text output\n    ui.tags.br(),\n    ui.tags.br(),\n\n    ui.output_text_verbatim(\"greeting\"),\n)\n\ndef server(input, output, session):\n    #3 add an additional mark below the others\n    @output\n    @render.text\n    @reactive.event(input.go_button)\n    def greeting():\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\"\n\n# This is a Shiny.App object. It must be named `app`.\napp = App(app_ui, server)\n\n\nYou should now see that an input button has appeared and the sentence won’t get printed out until you press it.\nAlso notice that the inconsistency in how to refer to functions on the other side of the ui:server divide rears its head once more. All in the server, when we want to use the values returned by the text input, we use the syntax input.name_entry(). When we want to use the action button in the reactive decorator, we have to use input.go_button - no parenthesis! The docs describe this as when you need to access the returned value versus when you need to call the function. This does make sense but can introduce some cognitive conflict while you are working with Shiny. I hope by version 1.0 the development team can find a way to simplify things.\nI also included some visual separation between elements in the ui by using ui.tags.br(). If you know a little HTML, you may get excited at that. You can access all the typical HTML tags in this way:\n\n\n\n\n\nShow the code\nfrom shiny import ui, App, render\n\napp_ui = ui.page_fluid(\n    ui.tags.h1(\"A level 1 heading\"),\n    ui.tags.h2(\"A level 2 heading\"),\n    ui.tags.br(),\n    ui.tags.p(\"Some text \", ui.tags.strong(\"in bold...\"))\n\n)\n\ndef server(input, output, session):\n    return None\n\napp = App(app_ui, server)\n\n\n\n\nDo you know enough markdown syntax to convert the ui below from HTML tags into markdown? This will greatly simplify the code. You will need to use ui.markdown(\"\"\"some multiline markdown\"\"\") to achieve that.\n\n\n\n\n\n\nHints. Click to expand if needed.\n\n\n\n\n\n\nYou can use this markdown cheatsheet to help.\nIf you’re stuck, click on “Show the code” to see an example solution.\n\n\n\n\n\n\n\n\n\nShow the code\n#1 Import the reactive module from Shiny\nfrom shiny import ui, render, App, reactive\n\napp_ui = ui.page_fluid(\n\n    ui.markdown(\n        \"\"\"\n        # Hello Python Shiny!\n        This **simple application** will print you a greeting.\n\n        1. Enter your name\n        2. Click run\n\n        Please visit [some website](https://datasciencecampus.github.io/)\n        for more information\n        ***\n        \"\"\"),\n    \n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    #2 add an action button to the ui, much like we did with the text input\n    ui.input_action_button(id=\"go_button\", label=\"Click to run...\"),\n    # add some visual separation to the text output\n    ui.tags.br(),\n    ui.tags.br(),\n\n    ui.output_text_verbatim(\"greeting\"),\n)\n\ndef server(input, output, session):\n    #3 add an additional mark below the others\n    @output\n    @render.text\n    @reactive.event(input.go_button)\n    def greeting():\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\"\n\n# This is a Shiny.App object. It must be named `app`.\napp = App(app_ui, server)\n\n\nSo there you have it. A very basic application that can be used to print out some simple messages to your user. This is of course a trivial app in order to keep things basic for the purposes of this blog. If you’d like to investigate what’s possible with Shiny, I’d suggest taking a peek through the Posit docs examples and the Python Shiny gallery. In the next section I’ll go over some tips that may help with common pitfalls I’ve encountered while working in Shiny."
  },
  {
    "objectID": "blogs/02-getting-started-pyshiny.html#tips.",
    "href": "blogs/02-getting-started-pyshiny.html#tips.",
    "title": "Let’s Build a Basic Python Shiny App",
    "section": "Tips.",
    "text": "Tips.\n\nShiny for Python VSCode Extension.\nThe Shiny for Python extension is a convenient way to launch Python Shiny apps. It adds a ‘Run Shiny App’ button to the VS Code interface, allowing for options to serve the app locally within a dedicated VS Code viewer window, or alternatively launch the app directly within your default web browser.\nIn order to run your application with this extension, you must ensure your app file is saved as app.py, otherwise the run button will not recognise that the currently selected document is a Shiny app.\n\n\nHeader Accessibility Adjustment.\nA big shoutout to Utah State University for making their fantastic suite of web accessibility-checking tools open source. These tools make checking the accessibility of your web products much easier. Simply visit the Web Accessibility Evaluation Tool (WAVE) and enter a url under “Web page address:” and press return. The site will launch a helpful overlay on top of your specified url, highlighting accessibility alerts, warnings and features. There is also a sidebar helpfully explaining why the various alerts are important and what can be done to resolve them.\nUnless you have managed to host a Shiny application on a service such as shinyapps.io, unfortunately you won’t have a url to pass to WAVE. Working locally on your machine, your locally hosted app interface will launch with a url like: http://localhost:… There is another way to use WAVE to check localhost sites. Using the WAVE browser extensions will allow you to launch the WAVE tool within any of your browser windows. This would allow you to run these checks locally on your machine while also ensuring that your app looks good on Chrome, Firefox or Edge. When checking basic Python Shiny apps for accessibility, one of the common accessibility errors you will encounter will be:\n\n\n\n\n\n\nLanguage missing or invalid!\n\n\n\nThe language of the document is not identified or a lang attribute value is invalid.\n\n\nThis means a screen reader may not detect the language of the website content and may not work properly. The ideal scenario would be that Shiny would ask you to specify the language of the application that you are working in at the point where you create the application. It’s a straightforward fix though. We can include some tags at the top of our ui that will update the web page content with the required information:\n\n\n\n\n\nShow the code\nfrom shiny import ui, render, App, reactive\n\napp_ui = ui.page_fluid(\n    # Add a header and specify the language and title.\n    ui.tags.header(ui.tags.html(lang=\"en\"), ui.tags.title(\"A Really Basic App\")),\n\n    ui.input_text(\n        id=\"name_entry\",\n        label=\"Please enter your name\",\n        placeholder=\"Your name here\"\n        ),\n    ui.input_action_button(id=\"go_button\", label=\"Click to run...\"),\n    ui.tags.br(),\n    ui.tags.br(),\n\n    ui.output_text_verbatim(\"greeting\"),\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    @reactive.event(input.go_button)\n    def greeting():\n        return f\"Hi {input.name_entry()}, welcome to Python Shiny.\"\n\napp = App(app_ui, server)\n\n\n\n\nMissing Commas.\nOne of the more frustrating aspects of debugging Shiny applications, particularly as the application grows, is that a single misplaced comma can completely break your application. The thing to look out for here is when you run your app and you get the unexpected SyntaxError: invalid syntax error. I recall this being a real headache when I was learning RShiny, so much so that I would leave a little comment after each comma reminding me of which element of the code was being closed within the preceding bracket.\nThe Python errors are really helpful. They not only point to a problem with the syntax, but they identify the line number in the app where the first instance of this issue was encountered.\n\n\nDebugging Errors.\nAt times it can be unclear why errors are being raised and it becomes important to investigate intermediate values that are being calculated in the server. Your usual python debugging tools may not work with Python Shiny. Shiny is event-driven and the reactive flow and order of the object definitions in your scripts are treated a bit differently. Without a tool like R’s Reactlog package, this is currently quite tricky to do in Python. The main coping mechanism available at the moment is to include some text outputs in the ui, paired with render text functions in the server. You can go ahead and use these elements to helpfully print out intermediate values such as DataFrame column names, data types etc and then comment them out when they’re no longer needed. Examining these intermediate values from within your ui is often the way to go when you can’t understand the root cause of your problem.\n\n\n\n\n\n\nMake a Reprex!\n\n\n\nOne more approach to consider is to try to isolate your problem.\n\n\nSometimes it can be hard to build a mental picture of all the moving elements under the hood in your server, and how they may be unexpectedly interacting with each other. The problem you’re encountering may be due to these complex interactions in your server. Simply commenting out the code not directly related to the issue you are experiencing helps to triangulate the source of the issue within your reactive model. This is also the first step towards producing a reprex - a reproducible example. These should be as minimal as possible and are very helpful to start getting to the root of a programming problem.\n\n\nSpecifying Working Directory.\nThis is more of a consideration for deployment to a service such as shinyapps.io than something you tend to encounter while learning the ropes. And you likely won’t encounter this issue if your app.py file is located in the top level of your project folder (also known as the project root). If your app is not in the root of the project folder, you may wish to include this snippet of code before you define your Shiny ui:\nos.chdir(os.path.dirname(os.path.realpath(__file__)))\nThis ensures that the working directory is set to that of the app.py file when it runs. If you encounter pandas errors complaining about FileExistsError when you deploy your app to shinyapps.io but not when you locally run your application, this may be the fix you need. Also something to consider if your app is styled correctly locally but not when you deploy. Potentially a relative path to a dedicated stylesheet has broken.\nOne more thing on deploying your app - if you do intend to host your app for others to use, I cannot emphasise this enough:\n\n\n\n\n\n\nDeploy Your App Early!\n\n\n\n\n\n\nDeployment of applications is not a straight forward, half an hour job. There are often inconsistencies to iron out between the environment you developed the app in and the server that will be running the remote app for your users. Deploy your app early when it is basic and you can catch these inconsistencies as you go. Or don’t and ignore the pile of technical debt your project is accruing. These are your choices."
  },
  {
    "objectID": "blogs/02-getting-started-pyshiny.html#in-review.",
    "href": "blogs/02-getting-started-pyshiny.html#in-review.",
    "title": "Let’s Build a Basic Python Shiny App",
    "section": "In Review.",
    "text": "In Review.\nWe have written a very basic application that is not much use beyond a basic tutorial. Although we have successfully demonstrated how to have the ui and server elements of a Shiny application talk to one another. We’ve captured dynamic inputs provided by the user and presented them back within the interface. And we have been able to pause the server execution until the user asks for a response. That’s not a bad start at all. But so much more than this can be achieved in Python Shiny. A good place to go for inspiration is the Posit Example Gallery. And if you’d like to understand a little more about how Python Shiny fits into the Python dashboarding toolkit, please check out my other blog on The Current State of Python Shiny.\nHappy dashboarding!"
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html",
    "href": "music-reviews/05-when-worlds-collide.html",
    "title": "When Worlds Collide",
    "section": "",
    "text": "The EP offers a mesmerising journey through electronic soundscapes, evoking a sense of otherworldly exploration. Barrandon masterfully combines retro synthwave elements with modern cinematic vibes.\n\n\n\nFor a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\nOverall, a laid-back and peaceful affair, with distribution in the lower valence and speechiness values. Acousticness and instrumentalness are mostly confined to lower values, with the distinct exception of the final track, “A New Start”. A broad middle-range distribution in energy and danceability is common across all tracks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature."
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#a-cosmic-convergence",
    "href": "music-reviews/05-when-worlds-collide.html#a-cosmic-convergence",
    "title": "When Worlds Collide",
    "section": "",
    "text": "The EP offers a mesmerising journey through electronic soundscapes, evoking a sense of otherworldly exploration. Barrandon masterfully combines retro synthwave elements with modern cinematic vibes.\n\n\n\nFor a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\nOverall, a laid-back and peaceful affair, with distribution in the lower valence and speechiness values. Acousticness and instrumentalness are mostly confined to lower values, with the distinct exception of the final track, “A New Start”. A broad middle-range distribution in energy and danceability is common across all tracks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature."
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#the-tracks",
    "href": "music-reviews/05-when-worlds-collide.html#the-tracks",
    "title": "When Worlds Collide",
    "section": "The Tracks",
    "text": "The Tracks\nBelow are the mean audio feature values for each track. The last row (green) presents a mean summary of the album.\n\n\n\n\n\ntrack_name\ndanceability\nenergy\nspeechiness\nacousticness\ninstrumentalness\nvalence\n\n\n\n\nExtinction\n0.511\n0.3610\n0.03490\n0.199000\n0.9360\n0.0741\n\n\nDoomsday Clock\n0.477\n0.5160\n0.02780\n0.001440\n0.3090\n0.1080\n\n\nPale Blue Dot\n0.172\n0.3050\n0.03360\n0.020400\n0.8900\n0.0347\n\n\nFragment\n0.559\n0.5500\n0.04330\n0.069800\n0.1870\n0.0734\n\n\nNew Start\n0.236\n0.0355\n0.03110\n0.836000\n0.5810\n0.0388\n\n\nAlbum Mean\n0.391\n0.3535\n0.03414\n0.225328\n0.5806\n0.0658\n\n\n\n\n\n\n\n…"
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#extinction",
    "href": "music-reviews/05-when-worlds-collide.html#extinction",
    "title": "When Worlds Collide",
    "section": "Extinction",
    "text": "Extinction\nThe opening track sets the tone with its haunting melodies and pulsating beats. It’s reminiscent of the Stranger Things theme, yet maintains its unique identity, aiming for a more subtle tension to emerge."
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#doomsday-clock",
    "href": "music-reviews/05-when-worlds-collide.html#doomsday-clock",
    "title": "When Worlds Collide",
    "section": "Doomsday Clock",
    "text": "Doomsday Clock\nFrom the outset a percussive metronome gradually builds tension. A brooding composition, the synths create an eerie atmosphere, leaving you on the edge of anticipation."
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#pale-blue-dot",
    "href": "music-reviews/05-when-worlds-collide.html#pale-blue-dot",
    "title": "When Worlds Collide",
    "section": "Pale Blue Dot",
    "text": "Pale Blue Dot\n\n\n\nLook again at that dot. That’s here. That’s home. That’s us. (Carl Sagan)\n\n\nA beautiful piece that balances melancholy and hope. The delicate piano interludes blend seamlessly with the electronic textures."
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#fragment",
    "href": "music-reviews/05-when-worlds-collide.html#fragment",
    "title": "When Worlds Collide",
    "section": "Fragment",
    "text": "Fragment\nThe standout track, this shorter number feels like a glitch in the matrix. Its beats and fragmented sounds add an intriguing layer."
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#new-start",
    "href": "music-reviews/05-when-worlds-collide.html#new-start",
    "title": "When Worlds Collide",
    "section": "New Start",
    "text": "New Start\nShort but impactful, this track offers a sense of resolution. The uplifting melodies and arpeggios leave you with a feeling of renewal. Peaceful piano is used to great effect, a distinct step change to the synth of the rest of the EP."
  },
  {
    "objectID": "music-reviews/05-when-worlds-collide.html#overall",
    "href": "music-reviews/05-when-worlds-collide.html#overall",
    "title": "When Worlds Collide",
    "section": "Overall",
    "text": "Overall\nWhen Worlds Collide is a journey that transcends time and space. Each track contributes to the EP’s cohesive narrative, making it a must-listen for fans of synthwave and ambient music.\nFor more music to encourage your work efforts, check out Productivity Pulse."
  },
  {
    "objectID": "music-reviews/03-dk-county-piano.html",
    "href": "music-reviews/03-dk-county-piano.html",
    "title": "Donkey Kong Country Relaxing Piano (Instrumental)",
    "section": "",
    "text": "Donkey Kong Country was a seminal moment for the SNES. I recall when a childhood friend of mine had received it as an Easter present. The graphics were mind blowing, the 2 player couch co-op highly addictive, and the audio certainly made an impression that lasted longer than I had realised. At the time I recall I hadn’t made the transition to the 16-bit generation, and in comparison to my decidedly lacklustre Master System, this looked like the future of video gaming.\nThirty years later, I asked Alexa to play some soothing dog music for the dachshunds while I did the school run - like most dachshunds, they’re the anxious type. As I returned to start work, my nostalgia radar was piqued as a beautiful reimagining of Aquatic Ambience sweetly serenaded the pups. That was my serendipitous introduction to this little melancholy gem.\n\n\n\nFor a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\nAs the album is so short, we see some very tight distributions here and no surprises this time, apart from a middling danceability (ballet perhaps?). All tracks are very high in instrumentalness and acousticness. The album is very low in speechiness as you’d expect. Energy is low throughout. Even where the source material is decidedly spritely, it is played here in a soft and ponderous tempo. A slightly broader distribution in valence and danceability can be observed.\nPut this album on when you need to pick through failing code. It will encourage alpha brain waves and keep you from switching context to something less problematic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature."
  },
  {
    "objectID": "music-reviews/03-dk-county-piano.html#swinging-to-serenity",
    "href": "music-reviews/03-dk-county-piano.html#swinging-to-serenity",
    "title": "Donkey Kong Country Relaxing Piano (Instrumental)",
    "section": "",
    "text": "Donkey Kong Country was a seminal moment for the SNES. I recall when a childhood friend of mine had received it as an Easter present. The graphics were mind blowing, the 2 player couch co-op highly addictive, and the audio certainly made an impression that lasted longer than I had realised. At the time I recall I hadn’t made the transition to the 16-bit generation, and in comparison to my decidedly lacklustre Master System, this looked like the future of video gaming.\nThirty years later, I asked Alexa to play some soothing dog music for the dachshunds while I did the school run - like most dachshunds, they’re the anxious type. As I returned to start work, my nostalgia radar was piqued as a beautiful reimagining of Aquatic Ambience sweetly serenaded the pups. That was my serendipitous introduction to this little melancholy gem.\n\n\n\nFor a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\nAs the album is so short, we see some very tight distributions here and no surprises this time, apart from a middling danceability (ballet perhaps?). All tracks are very high in instrumentalness and acousticness. The album is very low in speechiness as you’d expect. Energy is low throughout. Even where the source material is decidedly spritely, it is played here in a soft and ponderous tempo. A slightly broader distribution in valence and danceability can be observed.\nPut this album on when you need to pick through failing code. It will encourage alpha brain waves and keep you from switching context to something less problematic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature."
  },
  {
    "objectID": "music-reviews/03-dk-county-piano.html#the-tracks",
    "href": "music-reviews/03-dk-county-piano.html#the-tracks",
    "title": "Donkey Kong Country Relaxing Piano (Instrumental)",
    "section": "The Tracks",
    "text": "The Tracks\nBelow are the mean audio feature values for each track. The last row (green) presents a mean summary of the album.\n\n\n\n\n\ntrack_name\ndanceability\nenergy\nspeechiness\nacousticness\ninstrumentalness\nvalence\n\n\n\n\nIsland Swing - Instrumental\n0.3940\n0.02040\n0.05620\n0.9900\n0.9450\n0.2720\n\n\nForest Frenzy - Instrumental\n0.3770\n0.01800\n0.05760\n0.9950\n0.9540\n0.2070\n\n\nAquatic Ambiance - Instrumental\n0.3890\n0.03830\n0.06950\n0.9870\n0.9530\n0.1030\n\n\nSimian Segue - Instrumental\n0.3210\n0.04400\n0.05730\n0.9900\n0.9420\n0.2570\n\n\nGang-Plank Galleon - Instrumental\n0.4400\n0.01690\n0.07810\n0.9950\n0.9600\n0.2500\n\n\nAlbum Mean\n0.3842\n0.02752\n0.06374\n0.9914\n0.9508\n0.2178\n\n\n\n\n\n\n\nIn the table we get to see the cause of the broader distribution in valence and danceability. Island Swing, Simian Segue and Gang-Plank Galleon drag the mean valence of the album up, while in terms of danceability, Gang-Plank-Galleon is a relative toe tapper.\nIsland Swing\nThe album starts with a gorgeous, plaintiff melody, turning to the distinctive saloon-inspired hook that clearly identifies the original game. This track pauses for new material at points so much that I felt it must be a medley. However on reprising the original audio, it does pay a faithful tribute to the original. It finishes as sweetly as it started and sets the scene well for what’s to be expected.\nForest Frenzy\nA deeply ponderous cadence interspersed by moments of treble clarity played so softly. The artist really has tempered the frenzy in this forest very well. What remains is a lullaby.\nAquatic Ambience\nThis track absolutely steals the show. The original was genius, but this is such an exquisite rendition. The movements are played very freely, softening the tighter tempo of the original. This is the track not to miss.\nSimian Segue\nThis is the track from the level select map. The valence rises a fair bit here, which is very understandable considering this must be the most recognisable hook from the game. It’s still a bit playful, even when played so gently. Some powerful major chord shifts making this a decidedly cheery affair.\n\nGang-Plank Galleon\nI have no recollection of this track. It must be owing to the fact that this was the music for the final boss of the game. I was clearly not good enough to make it this far as a kid. The song begins as its title would suggest with a decidedly swashbuckling theme. This soon recedes, handing the limelight to a beautiful melancholy solo that sounds like a distinct song. Once more, reprising the original, it’s clear that this is a pretty faithful reprise of the soundtrack that came with the game."
  },
  {
    "objectID": "music-reviews/03-dk-county-piano.html#overall",
    "href": "music-reviews/03-dk-county-piano.html#overall",
    "title": "Donkey Kong Country Relaxing Piano (Instrumental)",
    "section": "Overall",
    "text": "Overall\nWhether or not 1990’s Nintendo is your thing, what a beautiful effort from the artist. I’d recommend listening to their other albums in a similar vein. But this one is my favourite, though I am likely biased due to some formative connection to the source material. But whether serenity is your goal, or maybe you just need to get a baby off to sleep, this little album is the right tool for the job.\nFor more music to encourage your work efforts, check out Productivity Pulse."
  },
  {
    "objectID": "music-reviews/01-ghostrunner-ost.html",
    "href": "music-reviews/01-ghostrunner-ost.html",
    "title": "Ghostrunner",
    "section": "",
    "text": "I’m thrilled to kick off the music review section of my blog with an engaging work by one of my favourite synth artists.\n\n\n\n\n\n\nNote\n\n\n\nThis is a record with high turnover & great energy - one to put on loop when you need to pull out all the stops on a thorny problem.\n\n\nGhostrunner was one of the acclaimed independent platformer games of 2020. It’s aged particularly well on the latest generation of consoles, thanks in no small part to its fantastic soundtrack. The developers made a safe bet in selecting Daniel Deluxe to compose the nihilistic, cyberpunk soundtrack. Deluxe has been producing knockout darksynth since 2014 and has been a regular feature of my working music since I started programming.\nDeluxe’s 2014 effort by the name of Darkness was one of the first synthwave songs I had come across and partly the reason why I have gone so deep with this genre. It’s a fantastic piece of 80s romantic nostalgia with evocative speech samples taken from the 1985 fantasy movie Legend, starring Tim Curry as the eponymous Darkness - a character that haunted the nightmares of many ’80s children. Much of Deluxe’s catalogue is worthy of your time and Ghostrunner OST is the crowning achievement. As his fifth and latest (at time of writing) studio album, Ghostrunner draws and builds upon the stylistic themes explored in previous albums. Though in this effort, a shorter average track length has kept things laser-focussed. Ghostrunner is a great introduction to synthwave of the catalogue of Daniel Deluxe as a whole, but luckily for the newcomer - there’s plenty of depth to mine from this musical vein."
  },
  {
    "objectID": "music-reviews/01-ghostrunner-ost.html#introduction",
    "href": "music-reviews/01-ghostrunner-ost.html#introduction",
    "title": "Ghostrunner",
    "section": "",
    "text": "I’m thrilled to kick off the music review section of my blog with an engaging work by one of my favourite synth artists.\n\n\n\n\n\n\nNote\n\n\n\nThis is a record with high turnover & great energy - one to put on loop when you need to pull out all the stops on a thorny problem.\n\n\nGhostrunner was one of the acclaimed independent platformer games of 2020. It’s aged particularly well on the latest generation of consoles, thanks in no small part to its fantastic soundtrack. The developers made a safe bet in selecting Daniel Deluxe to compose the nihilistic, cyberpunk soundtrack. Deluxe has been producing knockout darksynth since 2014 and has been a regular feature of my working music since I started programming.\nDeluxe’s 2014 effort by the name of Darkness was one of the first synthwave songs I had come across and partly the reason why I have gone so deep with this genre. It’s a fantastic piece of 80s romantic nostalgia with evocative speech samples taken from the 1985 fantasy movie Legend, starring Tim Curry as the eponymous Darkness - a character that haunted the nightmares of many ’80s children. Much of Deluxe’s catalogue is worthy of your time and Ghostrunner OST is the crowning achievement. As his fifth and latest (at time of writing) studio album, Ghostrunner draws and builds upon the stylistic themes explored in previous albums. Though in this effort, a shorter average track length has kept things laser-focussed. Ghostrunner is a great introduction to synthwave of the catalogue of Daniel Deluxe as a whole, but luckily for the newcomer - there’s plenty of depth to mine from this musical vein."
  },
  {
    "objectID": "music-reviews/01-ghostrunner-ost.html#music-for-cyborg-ninjas",
    "href": "music-reviews/01-ghostrunner-ost.html#music-for-cyborg-ninjas",
    "title": "Ghostrunner",
    "section": "Music for Cyborg Ninjas",
    "text": "Music for Cyborg Ninjas\nIt’s worth noting that this music isn’t for everyone. But I’ve never favoured that sort of music myself and wouldn’t find the time to review it. This music was written to energise players ready to engage in parkour-slash-em-up fun, without distracting from the brief interludes of narrative. As with all my favoured music for work, you won’t find any ballads or warbling vocals here, so if you want something to hum along to, you’d best find another blog!\nBut if you’re down for this, I’d recommend clicking play on the spotify player button and enjoying the tunes while you read.\n\n\n Let’s take a look at the audio feature analysis for this album. For a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature.\n\n\n\nGhostrunner OST is clearly an instrumental album. This plot shows that the tracks all score lowly on speechiness and highly on instrumentalness, with tight distributions. The album generally displays high measures for energy and danceability, though with broader distributions than that displayed by speechiness & instrumentalness. The majority of the album is clear, steady and fast rhythm. Interestingly, the acousticness feature presents a very broad range of distribution in the confidence that tracks do not have electrical amplification. This really does not seem correct to me, as the album is unapologetically synth all the way. This is potentially affected by production effects favouring reverb and echo, but that is surmising on my part. Lastly, I’ll turn to valence, which is a measure of positivity within the music. This feature is right-skewed. A higher number of lower valence values makes sense, as much of the album carries a sinister, Orwellian, digital-dystopian tone - generally interpretable as negative I would agree. The presence of higher values in this feature suggests that a fewer number of the tracks may be characterised with positive emotion."
  },
  {
    "objectID": "music-reviews/01-ghostrunner-ost.html#the-tracks",
    "href": "music-reviews/01-ghostrunner-ost.html#the-tracks",
    "title": "Ghostrunner",
    "section": "The Tracks",
    "text": "The Tracks\nBelow are the mean audio feature values for each track. The last row (green) presents a mean summary of the album.\n\n\n\n\n\ntrack_name\ndanceability\nenergy\nspeechiness\nacousticness\ninstrumentalness\nvalence\n\n\n\n\nAir\n0.5730\n0.7320\n0.02960\n0.2660000\n0.8930\n0.05400\n\n\nInfiltrator\n0.6070\n0.5600\n0.04340\n0.0239000\n0.8120\n0.03720\n\n\nBlood and Steel\n0.6960\n0.3260\n0.05130\n0.0061700\n0.8210\n0.03760\n\n\nDharma\n0.6160\n0.8290\n0.03830\n0.1510000\n0.8860\n0.17100\n\n\nCapture\n0.7070\n0.6310\n0.04420\n0.0439000\n0.8350\n0.40100\n\n\nForget the Past\n0.4490\n0.5400\n0.03330\n0.2940000\n0.9050\n0.03320\n\n\nAccess Denied\n0.5680\n0.5320\n0.03660\n0.4890000\n0.8820\n0.04460\n\n\nLet Them Know\n0.8380\n0.6600\n0.05060\n0.7990000\n0.7790\n0.74100\n\n\nSector\n0.5450\n0.8440\n0.03040\n0.0035500\n0.7040\n0.03770\n\n\nFactory\n0.4630\n0.9280\n0.03680\n0.3610000\n0.8990\n0.29100\n\n\nStriker\n0.5340\n0.8180\n0.03440\n0.0102000\n0.8380\n0.22600\n\n\nCelerity\n0.6430\n0.8840\n0.03360\n0.0109000\n0.8540\n0.03650\n\n\nThe Orb\n0.5120\n0.9470\n0.05290\n0.3180000\n0.8410\n0.74600\n\n\nTruth to Power\n0.6530\n0.8970\n0.05590\n0.3430000\n0.8700\n0.61300\n\n\nBlaster\n0.5720\n0.8750\n0.03870\n0.2190000\n0.8380\n0.09020\n\n\nRazor\n0.3250\n0.9190\n0.05040\n0.0002510\n0.6570\n0.05070\n\n\nVendetta\n0.6400\n0.8900\n0.05720\n0.0502000\n0.8240\n0.14500\n\n\nAir (Cybervoid)\n0.5180\n0.7210\n0.02730\n0.3240000\n0.9510\n0.16400\n\n\nSolitude\n0.4830\n0.9510\n0.04010\n0.0090000\n0.8210\n0.39000\n\n\nSundown\n0.2860\n0.3880\n0.06380\n0.2700000\n0.6560\n0.06490\n\n\nAlbum Mean\n0.5614\n0.7436\n0.04244\n0.1996036\n0.8283\n0.21873\n\n\n\n\n\n\n\nAir Beautiful synth bleep arrangement overlayed with menacing robot groans. A mashy bass beat rounds out this atmospheric ode to a mysterious, futuristic cityscape.\nInfiltrator Bassy experiments with tempo against a stripped-back rhythm section. Reminds me of scrap brain zone on sonic the hedgehog. Intermittent alert signals and robotic glitches. Glimpses of some wonderful serene motif before being thrust back into the main formation. At the time of writing, this track is currently the most popular on this album.\nBlood and steel This track is very recognizable. Inspires an unsettling feeling of Deja vú within the listener. Conjuring images of a futuristic crime scene investigation. A dreamy intro before a strong drum & bass injection. The track culminates in a growing phaser storm that smothers the rest of the track before it cuts at the point of its culmination. A highlight of the album.\nDharma Anyone of a certain age will likely remember ABC’s gripping sci fi thriller Lost, of the early noughties. Dharma was the name of the malevolent. corporation behind much of the protagonists woes. This track strikes a fittingly menacing tone. A dripping, ticking lick loops over a bossy bass hook. Lazer phasers growing in tone & pitch throughout for good measure.\nCapture A zoned out, decidedly creepy intro with an android snigger looped over bell tolls, metallic pipes clanging and a menagerie of industrial noise. A slower beat chugging away only to take frequent breaks to peak at you from the shadows. Sinister but with style.\nForget the past Begins on a melancholy reflection that seems to consider the song’s title some advice to self. Continues the chilling set by the previous track with an inhumane battery of bass noise, giving way to serene, elongated spacetrips of harmonic synth.\nAccess denied A collective of error signals experienced through a thick gelatinous membrane. This song feels like being rudely awoken from the matrix. An electric wire to the brain in the high tempo intro of a squelchy phaser bleep on loop. Drum & cymbal snares introduce some peril to the experience. Another favourite of mine.\nLet them know High pitch melodic trills over a stripped back drum beat with a growing, bubbling, frothy arsenal of phaser barrages. The trills give way to a strong bass line, dipping in and out of the foreground. Halfway in, a Wipeout-style high speed fade is accompanied by checkpoint ticks that sound a bit like hitting metal on metal. This track has a great time trial feel. The layers wipe together in a busy, well-structured crescendo. This is the highlight of the album for me.\nSector Starting on a mysterious, hyper-speed contrail of sound. With some productionised robot intonation rapping over the crunchy bass drum. Joined later by a Japanese-inspired treble section for the interested Japanophile. Reminiscent of the excellent Triads by Code Elektro (review sure to come at some point).\nFactory A clever mix of major and minor android aria signals. Locking in some bassy robo groans with some mysterious echo-flared laser trills. The track descends into a mission impossible repeato while adding some beautiful high frequency synth melody.\nStriker Enters with an industrial explosion experienced from a vast distance, rippling out into a wide pool of synth integration tests, like circuit fingers working through a mossy undertow. High frequency synth chimes with a glitched notation slips away to a seedy, menacing robotic bridge. The pretty synth returns to work over the menacing robo. A close second favourite.\nCelerity - Celerity is not a word I have encountered before, but according to dictionary.com it means swift movement. An interesting choice of title for this track as I interpret the rhythm to be more steady. Starting on a Prodigy-like industrial D&B replete with an accompanying fairground loop. A glitched-up affair with a jarring, chugging interference playing with your expectations throughout. This moves on to some graceful tech wipes for a moment before the interference dominates once more. Ending on a commandeering double-time march to up the ante, this track conjures a long-distance robotic pursuit.\nThe orb At this point in the album, we encounter a run of shorter, more intense songs. The orb has a brilliant, shimmering, robot talk phasing in and out of consciousness. Moving on to experiment with beat and tone patterns, swaying in and out of the fore as the beat establishes command. Short, but oh, so sweet.\nTruth to power A chunky drum section overlayed by a whispered android complaint growing to take full form, before relegated to radio playback. The android voice jumps in and out of focus while comets wipe by and leaves a trail of icy debris zooming past the listener. Likely to be the sort of music that Chat-GPT generates when frustrated by the lack of imagination presented by its users.\nBlaster Watch out for this one - there’s something larger rising out of the depths, waving away in front of your ears. Once surfaced, it reveals itself to be largely drum-engined automation with a bassy tempest of brass billowing away under the surface, like an automaton that’s managed to preserve the very last of the human tuba instrumentalists, lifespan extended with cybernetic implants.\nRazor Accusatory synth calls out against a halloween-esque synth sustain. Emerging out onto an ’80s horror set before adopting an attention-demanding rhythm. High-end synth parrots away while some os-level tech blurb ramps up to the fore.\nVendetta A reliable, robotic trill dances between pitches, laying off for some harmonious electro organ to swing in and out overhead. Machine gun volleys shower their weight to the beat.\nAir (Cybervoid) A welcome reprise to the first track of the album revisits a suspicious first day in a cybernetic future. A subtle difference to the original but more immediate. Blazing and warm bass tones intervene the laser hook and encompasses around the track as it progresses.\nSolitude A dreamy space-age synthetic Bach rises from the murky depths to sit in a shimmering orchestral pool, composing his techno-symphonies. In stark contrast, squishy, rubbery deep bass android vocals sound out over the alien morass.\nSundown A gothic android monk prayer cedes to laser piano overlays. Cutting out to flatlined electro strings & the futuristic remnants of whatever birds evolved into once AI conquered the Earth. A contemplative end to a high-energy album. Likely to reflect a sombre tone to the end of the video game, though I cannot confirm this as I was pretty rubbish when I tried it."
  },
  {
    "objectID": "music-reviews/01-ghostrunner-ost.html#highs-and-lows",
    "href": "music-reviews/01-ghostrunner-ost.html#highs-and-lows",
    "title": "Ghostrunner",
    "section": "Highs and Lows",
    "text": "Highs and Lows\nNo real lows to talk of in this album, but the three standout tracks that I recommend are:\n\nLet them know\nStriker\nBlood and steel"
  },
  {
    "objectID": "music-reviews/01-ghostrunner-ost.html#overall",
    "href": "music-reviews/01-ghostrunner-ost.html#overall",
    "title": "Ghostrunner",
    "section": "Overall",
    "text": "Overall\nA smashing piece of dark synthpop that delivers focussed energy while conserving your concentration. The theme is sinister at points but never loses its potency for concentrainment. A good choice for smashing out some shallow work or a briefing note in a short space of time. Perhaps not as inspiring or uplifting as some of my other instrumental ambient choices for creative energy. But this album establishes a steady cadence and will keep your foot tapping while your hands do the typing."
  },
  {
    "objectID": "book-reviews/04-dark-data.html#book-summary",
    "href": "book-reviews/04-dark-data.html#book-summary",
    "title": "Dark Data",
    "section": "Book Summary",
    "text": "Book Summary\n“Dark Data: Why What You Don’t Know Matters” by David J. Hand delves into the crucial concept of dark data — information that is unseen, uncollected, or unanalysed but significantly impacts decision-making and understanding. Hand categorises dark data into 15 types, illustrating the dangers of ignoring such data through historical and contemporary examples like FDR’s reelection polls and the Challenger shuttle disaster. The book highlights how unrecognised dark data can lead to skewed understandings, incorrect conclusions, and flawed actions.\n\n“The first step must always be to be aware there might be dark data. Indeed, your default assumption should be that the data are incomplete or inaccurate. That is the most important message of this book: be suspicious about the data - at least until it is proved they are adequate and accurate.” [1, p. 293]\n\nHand emphasises the importance of recognising and mitigating dark data, teaching readers to be vigilant about the issues posed by unknown information. He also explores how dark data can be strategically utilised. The book addresses various statistical methods and concepts, underscoring that even in the age of big data, the data available is never complete. Through practical guidance, Hand aims to help readers make better decisions in a world where missing data is inevitable, stressing the significance of understanding what is not known."
  },
  {
    "objectID": "book-reviews/04-dark-data.html#on-the-author",
    "href": "book-reviews/04-dark-data.html#on-the-author",
    "title": "Dark Data",
    "section": "On the Author",
    "text": "On the Author\nDavid J. Hand is a distinguished British statistician born in Peterborough, England. He received his BA from the University of Oxford and his PhD from the University of Southampton. Hand’s academic career includes significant roles such as serving as a professor of statistics at the Open University from 1988 to 1999 and later becoming an Emeritus Professor of Mathematics at Imperial College London, where he also worked as a Senior Research Investigator. His research interests are broad and include multivariate statistics, classification methods, pattern recognition, computational and foundational statistics, with a keen focus on data mining, data science, and big data."
  },
  {
    "objectID": "book-reviews/04-dark-data.html#three-takeaway-ideas",
    "href": "book-reviews/04-dark-data.html#three-takeaway-ideas",
    "title": "Dark Data",
    "section": "Three Takeaway Ideas",
    "text": "Three Takeaway Ideas\n\nOn Human Bias\n\n“…At least until the scientific revolution… advances in understanding were retarded by a (typically subconscious) reluctance to collect data which might disprove a theory… advances were held back by an unwillingness to make dark data visible…\n\n\nMy favourite historical example of someone who spotted this problem is given by the seventeenth-century philosopher, Francis Bacon, who wrote: “Human understanding when it has once adopted an opinion… draws all things else to support and agree with it. And though there be a great number and weight of instances to be found on the other side, yet these it either neglects and despises, or else by some distinction sets aside and rejects.” ” [1, pp. 167–168]\n\nThis human bias may be one of the fundamental flaws in human psychology. It’s something that people consider exists in everyone apart from themselves! My favourite (disputed) quote which has become a widely used example of confirmation bias has been attributed to the American film critic Pauline Kael, on the topic of Nixon’s 1972 U.S. election victory:\n\n“I can’t believe Nixon won. I don’t know anyone who voted for him.”\n\nI have known highly intelligent, capable people whose default position on alternative opinions is not just one of scepticism, but one of objection. And doubtlessly there have also been times when I have fallen into this trap myself. The issue with discounting, excluding and mocking counter opinions is that; on occasion; they are falsifiable and supported by the evidence! Widely accepted dogma can, has been and will be shattered by those willing to think outside of broadly accepted opinion.\nMy favourite 2 examples of this:\n\nA young James Dyson’s rejection when pitching his innovative bagless vacuum technology to Hoover [2]. Hoover did not see the potential in Dyson’s early prototype and disliked the fact that they would not be able to market their profitable vacuum bags and filters with such a model.\nDid you know that the concept of continental drift was highly disputed by geologists until the mid twentieth century? Bill Bryson [3] describes this as dogmatic resistance of the scientific community to truth. It happened that Alfred Wegener, who proposed the idea in World War 2 was not a trained geologist and therefore widely disputed. Even in the mid 1950s, the concept had not been adopted and notable Harvard University professor Charles Hapgood [4] was vehemently opposed to the concept. The fact that a concept this profound was being disputed in academic circles just thirty years before my birth shattered some preconceptions that I had about our understanding of our world. As a child in the ’90s, and having a predisposition towards studying science, I had a complete ignorance that this topic had been so recently contentious in academic circles. My intuition is that many others are similarly ignorant of this.\n\n\n\nPublication Bias\nHand rightfully has quite a bit to say about the reproducibility crisis in academic literature. The author explores reproducibility, publication bias and fraud in this domain. Although these issues may or may not be intentional, they have the potential to frustrate progress and prolong suffering, as exemplified in the case of the recent retraction [5] of an influential study on Alzheimer’s disease published in Nature in 2006 [6]. This paper has been cited more than 2,000 times and used brain scans of patients that have been shown to have been falsified.\nHand goes on to talk about a lesser known practice in academia known as harking:\n\n“Yet another cause of mistaken results is the pernicious practice called”HARKing”, or Hypothesizing After the Result is known…\n\n\nHARKing can be alleviated by requiring researchers to state their hypotheses before they collect any data. Some scientific journals are considering moving in this direction, guaranteeing publication of a paper regardless of how the results come out…” [1, pp. 198–199]\n\nI thoroughly agree with this suggestion. Wikipedia [7] quotes a study stating that papers with significant findings are 3x more likely to be published than those with null findings. And as the number of publications is broadly interpreted as a measure of success for academic institutions and individuals alike, a systemic pressure for fraudulent practice emerges. I would go even further and suggest that the barriers to journals demanding full reproducibility of analysis - including open and versioned code and data - is now lower than ever. In 2024, every respectable journal can require its contributors to use open source software to increase transparency and prove reproducibility. So why has this practice not been established? I presume there to be inertia in adopting newer tooling. A legacy uplift issue that would present modest overhead for significant gain. After all, most people who undertake their statistical analysis in legacy or proprietary software have a thorough knowledge framework that would greatly assist them in transitioning to open source languages.\n\n\nData Missingness\nHand adapts the American Statistician Donald Rubin’s description of the causes of missing data into the following:\n\nUnseen Data Dependent (UDD): The cause of the missingness is related to the value of the missing datum. No reason for this missingness can be discerned from the extant data.\nSeen Data Dependent (SDD): A clue to the reason for the missing datum is available within the extant data.\nNot Data Dependent (NDD): The reason for the missingness is unrelated to the extant data.\n\nHand’s explanation of Complete Case Analysis is an excellent warning to all those new to data science. The very common practice of dropping or imputing missing values from the data can be a very risky business. What if there were an underlying pattern in the missingness? Hand employs a perfectly clear, simple tabular example that have no complete cases, meaning that dropping missing observations would result in no records.\n\n“…if the dark data were not NDD, then even a small reduction in sample size could mean we were left with a distorted data set.” [1, p. 237]\n\nDistorting a dataset could be caused by either dropping records or imputing values for missing observations. There are far too many machine learning tutorials online that carelessly instruct learners to do so, in order to be able to use the algorithm of choice. Mindlessly erasing or imputing records with missing observations would generally mean reversion to the mean but has the potential to propagate algorithmic harm. Could the missing records represent people at the fringes of society, whose data are often challenging to capture? I worry that this practice is far too widespread within the field of data science, as many of the popular machine learning algorithms will not tolerate the inconvenient truth of dark data.\nTreating these records should involve a good deal of investigation. Is there a hint in the present data that could explain the missingness? Could correlations with other dimensions in the data mean a more appropriate imputation value based on a sub-group average, rather than the population average? To help python developers assess missingness in a dataset, I highly encourage people to make use of the missingno package. If you write in R, then the equivalent functionality is available with naniar.\nThe below visual gives an overview of populated records in a data table about road traffic collisions. Dark bands are populated records. White bands are missing records.\n\nimport pandas as pd\nimport missingno as msno\n\ncollisions = pd.read_csv(\"https://raw.githubusercontent.com/ResidentMario/missingno-data/master/nyc_collision_factors.csv\")\nmsno.matrix(collisions.sample(250))\n\n\n\n\n\n\n\n\nIn the above visual, you may see that certain columns demonstrate more missingness than others. But that specific columns show patterns in missingness in comparison with that of other columns too. For example, in records where ON STREET NAME and CROSS STREET NAME are missing, you may find that OFF STREET NAME records are present. This simple visual along with many more useful tools in the package are available to examine the idiosyncrasies within data."
  },
  {
    "objectID": "book-reviews/04-dark-data.html#in-summary",
    "href": "book-reviews/04-dark-data.html#in-summary",
    "title": "Dark Data",
    "section": "In Summary",
    "text": "In Summary\nIn conclusion, David J. Hand offers an insightful exploration into the realm of unseen, uncollected, or unanalysed data that profoundly impacts decision-making and understanding. Through detailed categorisation and vivid historical and contemporary examples, Hand underscores the critical need to recognise and address the hidden gaps in our data. His comprehensive analysis highlights how ignorance of dark data can lead to flawed conclusions and poor outcomes, while also presenting strategies to mitigate these risks. By encouraging a vigilant and sceptical approach to data analysis, Hand empowers readers to navigate the complexities of incomplete information, ultimately fostering better decision-making in an era where data is ever-present but often imperfect. This book is a valuable resource for anyone looking to deepen their understanding of the unseen dimensions of data and its far-reaching implications."
  },
  {
    "objectID": "blogs/08-quarto-conda-env.html",
    "href": "blogs/08-quarto-conda-env.html",
    "title": "Conda Environments for Quarto Documents",
    "section": "",
    "text": "Creative commons license, created by Ralph"
  },
  {
    "objectID": "blogs/08-quarto-conda-env.html#introduction",
    "href": "blogs/08-quarto-conda-env.html#introduction",
    "title": "Conda Environments for Quarto Documents",
    "section": "Introduction",
    "text": "Introduction\nThis article sets out minimal instructions on rendering quarto documents that rely on specified conda virtual environments. This article collates information from:\n\nQuarto Documentation: Using Conda\nQuarto Documentation: Using Python\nnb_conda_kernels readme\n\nIt is presumed that you will be working within a git repository at times. If this is not the case, ignoring steps specifying git instructions should not affect your ability to successfully render the quarto documents.\n\n\n\n\n\n\nA Note on the Purpose\n\n\n\n\n\nThe purpose of this article is not to explore reasons for using conda enviroments or to compare the pros and cons of the many different options for managing python virtual environments. It aims to help the reader configure quarto documents to run with a specified conda environment while remaining minimal, opting to link to sources of further information where discussion may complement the content.\n\n\n\n\nIntended Audience\nPython practitioners familiar with conda environment management [1] who are less familiar working with quarto documents [2].\n\n\nThe Scenario\nYou are writing a quarto document that contains python code. You would like to use conda to manage your python dependencies. You are encountering problems in having quarto select the appropriate conda environment.\n\n\n\n\n\n\nNamed Environments\n\n\n\n\n\nThis article covers having quarto execute with “prefix” conda environments. This setup may be useful specifically for a website where different site pages have different dependencies.\nHowever, many readers may wish for a simpler solution. It is possible to have quarto websites and documents execute with a named environment instead. If you have an environment created like below:\nconda create -n my-awesome-env python -y\nThen including the following statement within either the _quarto.yml or quarto document’s YAML header should be enough to guarantee that the target environment is picked up when rendering:\njupyter: my-awesome-env\nAdditionally, if you would just prefer the site or document to render with whatever version of python is available in the currently active environment, then use:\njupyter: python3\nMany thanks to Ethan for this tip.\n\n\n\n\n\nWhat You’ll Need:\n\nConda or miniconda\nQuarto\nText editor eg VS Code\nPython package manager (eg pip)\nAccess to a command line interface (CLI) such as terminal / Bash.\nrequirements.txt:\n\n\n\nrequirements.txt\n\nnbclient\nnbformat\npalmerpenguins\n\n\ngit (optional)"
  },
  {
    "objectID": "blogs/08-quarto-conda-env.html#configuring-quarto-with-conda-env",
    "href": "blogs/08-quarto-conda-env.html#configuring-quarto-with-conda-env",
    "title": "Conda Environments for Quarto Documents",
    "section": "Configuring Quarto with Conda Env",
    "text": "Configuring Quarto with Conda Env\n\nProject Structure\n\nCreate a new project folder. Open a terminal and change directory to the new project.\nSave the requirements to a requirements.txt file.\nCreate a new quarto document in the project root. In VS Code, use\nFile  New File...  Quarto Document.\nWrite the following content to a python code chunk in the quarto file and save as penguins.qmd\n\n\n\npenguins.qmd\n\ndf = penguins.load_penguins().dropna()\ndf.head()\n\n\n\nConfigure the Environment\n\nCreate a new conda environment with the -p flag and give it a suitably descriptive name 1. Ensure that the environment is built with python 3.11 2.\n\n\n\nCLI\n\nconda create -p SOME_ENV_NAME python=3.11 -y\n\n\nActivate the environment.\n\n\n\nCLI\n\nconda activate ./SOME_ENV_NAME\n\n\nInstall the requirements file.\n\n\n\nCLI\n\npip install -r requirements.txt\n\n\nAdd a .gitignore file and include the name of the local environment directory created in step 4.\n\n\n\n.gitignore\n\nSOME_ENV_NAME/\n\n\n\nConfigure the Quarto Project\n\nCreate a _quarto.yml configuration file in the project root. In this file, we will specify that the quarto render command should render any qmd files and ignore any files found within your local environment. Add the following content:\n\n\n\n_quarto.yaml\n\nproject:\n  type: website\n  output-dir: docs\n  render:\n    - \"*.qmd\"\n    - \"!/./SOME_ENV_NAME/\"\n\n\nUse conda to install the nb_conda_kernels package. This is used to manage python jupyter kernels for notebooks.\n\n\n\nCLI\n\nconda install nb_conda_kernels\n\n\nCopy the path returned from the below command\n\n\n\nCLI\n\njupyter --config-dir\n\n\nCreate a jupyter_config.json in the jupyter config directory:\n\n\n\nCLI\n\ntouch &lt;INSERT_YOUR_CONFIG_DIR&gt;/jupyter_config.json\n\n\nWrite the below content to this file and save.\n\n\n\nCLI\n\necho -e \"{\\n  \"CondaKernelSpecManager\": {\\n    \"kernelspec_path\": \"--user\"\\n  }\\n}\" &gt;&gt; &lt;INSERT_YOUR_CONFIG_DIR&gt;/jupyter_config.json\n\n\nRun the below command to return a list of available kernels:\n\n\n\nCLI\n\npython -m nb_conda_kernels list\n\n\nCopy the name (not the path) for the environment that you created with the format conda-env-&lt;YOUR_ENV_NAME&gt;-py.\nOpen penguins.qmd. Adjust the YAML header so that it contains the following:\n\n\n\npenguins.qmd\n\njupyter: \n  kernelspec:\n    name: \"conda-env-&lt;YOUR_ENV_NAME&gt;-py\"\n    language: \"python\"\n    display_name: \"&lt;YOUR_ENV_NAME&gt;\"\n\n\nYou should now be able to render the quarto project, confirming that the target environment was activated in the CLI output. eg:\n\n\n\nCLI\n\nquarto render\n\nStarting &lt;YOUR_ENV_NAME&gt; kernel...Done\n\n\nTips\n\nWhen encountering issues with quarto render, it can be informative to examine the output of quarto check or quarto check jupyter in the CLI.\nAs there are many steps to configuring conda, it may be a good idea to create a dedicated conda environment for all of your quarto projects. Quarto attempts to select an appropriate kernel based upon the content of the first executable python code chunk in your quarto document. Usually, this chunk would contain the import statements. However, over time this would likely result in package conflicts over time.\nThe approach set out in this how-to would be a good fit for a website built with quarto, where the configuration steps can be performed only once in a parent website environment, and then specific, minimal environments created for each article requiring a python environment.\nAlternatively, consider using venv or poetry to manage python environments [3] for quarto projects."
  },
  {
    "objectID": "blogs/08-quarto-conda-env.html#troubleshooting",
    "href": "blogs/08-quarto-conda-env.html#troubleshooting",
    "title": "Conda Environments for Quarto Documents",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nYou’ve created a new environment and it is not discovered when running python -m nb_conda_kernels list:\n\nActivate your new environment\npip install ipykernel\nRun:\n\npython -m ipykernel install --user --name &lt;INSERT_ENV_NAME&gt; --display-name \"&lt;INSERT_DISPLAY_NAME&gt;\"\n\nDeactivate the new environment.\nRun python -m nb_conda_kernels list once more and the new env should appear.\nTaken from this SO thread"
  },
  {
    "objectID": "blogs/08-quarto-conda-env.html#conclusion",
    "href": "blogs/08-quarto-conda-env.html#conclusion",
    "title": "Conda Environments for Quarto Documents",
    "section": "Conclusion",
    "text": "Conclusion\nThis article has walked the reader through setting up a basic quarto project, creating a conda environment, and configuring a quarto document to render with a specified environment. For more help with quarto, consult the quarto-cli GitHub repository [4] and the RStudio Community [5] (soon to rebrand to the Posit Community).\n\nfin!"
  },
  {
    "objectID": "blogs/08-quarto-conda-env.html#footnotes",
    "href": "blogs/08-quarto-conda-env.html#footnotes",
    "title": "Conda Environments for Quarto Documents",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhen creating conda environments, the use of generic names such as env will result in conda prepending the environment name with numbers to avoid conflicts. Use descriptive environment names in order to avoid this, eg penguins-env.↩︎\nnb_conda_kernels (a package required in a later step) does not currently work with python 3.12 or newer.↩︎"
  },
  {
    "objectID": "book-reviews/index.html",
    "href": "book-reviews/index.html",
    "title": "Books",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nBuilding a Second Brain\n\n\n8 min\n\n\n\nNon-fiction\n\n\nSelf-Help\n\n\nProductivity\n\n\nPersonal Knowledge Management\n\n\nPersonal Development\n\n\nBusiness\n\n\nPsychology\n\n\nTechnology\n\n\nNote Taking\n\n\n\nSystematise what you’re already probably doing.\n\n\n\nRich Leyshon\n\n\nSep 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 Books That Shaped my Civil Service Career\n\n\n11 min\n\n\n\nNon-fiction\n\n\nCareer\n\n\nProductivity\n\n\nProgramming\n\n\nAnalyst\n\n\nPublic Sector\n\n\nCivil Service\n\n\n\nRecommendations for Public Sector Analysts\n\n\n\nRich Leyshon\n\n\nJul 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDark Data\n\n\n9 min\n\n\n\nNon-fiction\n\n\nData\n\n\nScience\n\n\nMathematics\n\n\nStatistics\n\n\n\nA perfect compendium of gotchas for the entry data scientist.\n\n\n\nRich Leyshon\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAmusing Ourselves to Death\n\n\n33 min\n\n\n\nNon-fiction\n\n\nMedia\n\n\nCriticism\n\n\n\nReflecting on Neil Postman’s criticism of modern culture.\n\n\n\nRich Leyshon\n\n\nDec 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgorithms to Live By\n\n\n13 min\n\n\n\nMathematical Modelling\n\n\nComputer Science\n\n\n\nThoughts on Brian Christian & Tom Griffiths treatment of applied computer science.\n\n\n\nRich Leyshon\n\n\nSep 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeep Work\n\n\n9 min\n\n\n\nSelf-Help\n\n\nProductivity\n\n\nBusiness\n\n\nPsychology\n\n\nPhilosophy\n\n\n\nA review of Cal Newport’s much lauded productivity how to guide.\n\n\n\nRich Leyshon\n\n\nAug 30, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "book-reviews/05-career-reads.html#introduction",
    "href": "book-reviews/05-career-reads.html#introduction",
    "title": "4 Books That Shaped my Civil Service Career",
    "section": "Introduction",
    "text": "Introduction\n4 years into my career in the UK civil service, I am about to move to a new department and am taking the time to consider successes, challenges and lessons learned along the way. It’s been an incredible journey. I’ve been lucky to have worked with some of the most talented people and on some fantastic projects.\nOne of my most valued learning opportunities is in the form of a great book recommendation, especially when someone has taken the time to get to know the kinds of books that I would benefit from reading.\nAs I anticipate starting in my new role, I’d like to take the opportunity to pay some of these thoughtful recommendations forward. If you’re starting out in the public sector, or considering it, then you may find some of these texts to be helpful.\nSome of the books will be useful to a broad audience of civil servants, though others may be more relevant to those who program as part of their job."
  },
  {
    "objectID": "book-reviews/05-career-reads.html#the-recommendations",
    "href": "book-reviews/05-career-reads.html#the-recommendations",
    "title": "4 Books That Shaped my Civil Service Career",
    "section": "The Recommendations",
    "text": "The Recommendations\n\n\n\n\n\n\nProduct Placement\n\n\n\nThis article is not sponsored by anyone. All of the books here have been read and integrated into my working practice to some extent.\n\n\nI will work through a recommendation for each year of service in roughly chronological order - no ranking implied. Two of the recommendations are open source and free to anyone with internet access. The books appeal to distinct audiences, so I’ll try to set out who I think will find the content useful.\n\n1. 7 Habits of Highly Effective People\n\nThe Seven Habits of Highly Effective People by Stephen R. Covey [1].\n\n\n\n\n\n\nWho Is It For? (Click to expand)\n\n\n\n\n\nJust about anyone. But particularly, anyone whose job affords them the responsibility of directing their own time. Though there is also a lot to be applied to your everyday life, too.\n\n\n\nI have a bit of a long history with this book. I was initially recommended it when working as a high school science teacher as part of a training event. For some curious reason I found myself resistant to picking it up. I think I felt too busy to dedicate myself to much reading in general at that point in my career and in retrospect, that was a mistake. This book has lots of really useful, actionable guidance for doing more of what matters most.\nStarting from a point of personal effectiveness will set you up for success in the civil service, particularly as you develop proficiency in this skill, you may be expected to extend this effectiveness to others through the management of people and projects.\nThe highlight of the book for me is the famous Covey Quadrant:\n\nThis was adapted from the Eisenhower Matrix, named after the former president who had devised the rubric. Covey’s guidance was to spend time at the start of the day (or even better, at the end of the previous day) triaging your tasks against the dimensions of urgency and importance. And to be mindful that the everyday pressures may push you towards quadrant 1, while the most effective use of your time is generally within quadrant 2.\nThis approach seemed revelatory to me at the time of reading and would have certainly helped during the early stages in my education career. I readily applied this approach from the outset of my civil service career as a financial analyst and then later as a data science lecturer. As I progressed to managing a faculty of data science lecturers, I had spotted a team in another government department using an interactive team Covey Quadrant. This was a great opportunity to trial the approach with the faculty, who were extremely busy delivering technical training across public sector bodies while also needing to iterate and improve on the service offering.\n\nThis tool was exceptionally useful in helping manage demand. Conversations about feasible turnaround and how incoming priorities compared to pre-existing work were well-informed by a quick weekly update to the dashboard’s data (nothing more than updating a couple of columns in an Excel spreadsheet). This tool became my indispensible buddy during that period of high demand and I would thoroughly recommend putting something similar together if you find your team need help managing competing demands.\n\n\n2. Agile DSDM Project Framework\n\nThe Dynamic Systems Development Method [2], an Agile project management framework, published by the Agile Business Consortium Ltd. The handbook is available to read for free on their website.\n\n\n\n\n\n\nWho Is It For? (Click to expand)\n\n\n\n\n\nAnyone who needs to design, build or ship products, particularly software. So any of the following (not an exhaustive list):\n\nData Scientist\nData Engineer\nData Analyst\nSoftware Developer\nAgile Coach\nProject Manager\nScrum Master\nProduct Owner\nDevelopment Team Lead\nSoftware Developer\nQA/Test Manager\nChange Manager\nIT Manager\nProgram Manager\nBusiness Architect\nBusiness Analyst\nSystem Architect\nTechnical Architect\nSolution Architect\nUX/UI Designer\nUser Researcher\nInteraction Designer\nGraphic Designer\nPortfolio Manager\nDigital Marketing Specialist\nSecurity Architect\n\n\n\n\nA few years back, Agile seemed to be the in-vogue project management (PM) system, especially for digital products. It always vocal critics, but recently I sense it has crested a wave.\nIn my opinion, that’s a shame. The core principles of Agile I consider to be worth the effort:\n\nCustomer-centric development\nIterative delivery\nFlat development structure - succeed or fail together\n\nA whole industry of consultation has grown around the popularity of Agile DSDM. Finding objective guidance on its implementation can be tricky to find, particularly if you wish to compare and contrast it with other PM frameworks.\n\nThere’s no right way to do Agile. It’s whatever you can make work with the resources at your disposal.\n\nIn some guidance, the core Agile principles become a bit obscured by process. An organisation’s interpretation of how Agile works often boils down to a vague understanding of role definitions and sprint ceremonies. If enough of your ‘Agile champions’ leave, you may find yourself with all the process and none of the benefits. I once heard that “Agile simply produces rubbish quickly”. I’d say that if an organisation is careless about its practice, that’s a definite possibility.\nThe reason I found Agile DSDM so influential, is that I benefited from working with people who really championed it. Colleagues who had grasped the pros and cons and were keen to help the rest of the team navigate the implementation of the Agile philosophy. I had benefited from taking this experience with me to other organisations that had not discovered Agile, and enjoying the benefits of these simple rules.\n Image © Agile Business Consortium Limited.\nI recall one of my directors stating something to the effect of,\n“You can have something built quickly and with quality, but have to pay for it. Or it can be built with quality and cheaply, but you’ll have to wait for it. Or it could be built quickly and on a shoestring budget, but it’ll be rubbish.”\nI’d say that’s a good interpretation of the Agile priorities. It was very motivating to hear this unsolicited endorsement of Agile principles from the leadership in my division. It felt that adoption of Agile had been firmly embedded and supported throughout all tiers within the hierarchy of my new role. This widespread adoption had contrasted with previous organisations that I had worked for, where Agile had been a new and unproved innovation.\nThe best Agile teams and practitioners are brutally exact with timescales. The Agile process involves phases of development punctuated by mini evaluation cycles. Feedback from the customers is then used to inform priorities in subsequent development phases. This frequent feedback to and from the customer keeps them highly engaged and giving them greater input into the quality of the final product. When managed well, Agile really works and your customers tell others that it works, too!\n\n\n3. Data Visualisation: A Handbook for Data Driven Design\nData Visualisation: A Handbook for Data Driven Design by Andy Kirk [3].\n\nImage © Data Viz Excellence, Everywhere Ltd\n\n\n\n\n\n\nWho Is It For? (Click to expand)\n\n\n\n\n\n\nResearchers\nData Analysts\nData Scientists\nData Journalists\nSoftware Developers\nBusiness Intelligence Analysts\nStatisticians\nGraphic Designers\nCommunications Professionals\nUX/UI Designers\nMarketing Analysts\nEducators and Trainers\n\n\n\n\nI had been recommended this book during my time as a financial analyst working in a multidisciplinary team, some years before joining the civil service. A very talented graphic designer had recommended the book and lent it to me for a period. Some years later, I picked up a copy of the second edition.\nThis is a fantastic gift for anyone interested in data visualisation. Analysts can become a bit dismissive of data visualisation, considering it nothing more than learning your organisation’s house style. In fact, this ‘done in a day’ attitude can be quite prevalent and quality assurance of charts can be extremely opinionated, placing increasingly narrow guardrails around the kinds of visualisation an organisation would consider publishing. 5 minutes of flicking through this book is enough to blow any conservatism in this space out of the water.\nThis was the first book that I read where the ‘authoritative view from above’ that can so often be implicit in many visualisations was challenged. Representing uncertainty, discussing the creative process and intended outcomes of a visualisation effort, this book steps the reader from ideation to completion. The author also collates a rich, evocative compendium of fantastic data visualisations, inviting the reader to learn, question and wonder about the various topics they present.\n\n\n\n\n\n\nTip\n\n\n\nIf you’re reading on mobile, the interactive below may look better in landscape.\n\n\n\n\n\nStraddling the intersection of art, design and analytics, this book provokes analysts to challenge tautologies and to think creatively.\n\n\n4. ONS Duck Book\n\nThe Duck Book [4] is the warmly regarded pseudonym for Quality Assurance of Code for Analysis & Research (QuAC!), published by the UK Statistics Authority.\n\n\n\n\n\n\nWho Is It For? (Click to expand)\n\n\n\n\n\nAnyone undertaking analysis in Government, here’s a non-exhaustive list:\n\nEconomist\nOperational Research Analyst\nSocial Researcher\nStatistician\nData Scientist\nData Analyst\nData Engineer\nDigital, Data and Technology Analyst\nPolicy Analyst\nEvaluation Specialist\nBehavioural Scientist\nDemographer\nGeospatial Analyst\nIntelligence Analyst\nRisk Analyst\nPerformance Analyst\nFinancial Analyst\nBusiness Intelligence Analyst\nMarket Analyst\nHealth Analyst\nEducation Analyst\nEnvironmental Analyst\n\n\n\n\nThe duck book is a fantastic resource that continues to evolve. It has changed considerably since I first read it in 2020 and now has information relevant to managers of development teams, too.\nThis book was incredibly useful to me when starting to develop code for the civil service. I had come from smaller development teams in wider public sector organisations. Constraints in those organisations meant that lone-wolf development was commonplace. No code review and too much trust placed on individual analysts to judge the proportionate risk management for multiple projects.\nJoining the civil service meant greater collaboration on analytical products. This book became my bible for 12 months while I got to grips with git, GitHub & best practice for collaborative development. It does a great job of giving a high level overview of all the important aspects and quality standards that a government analyst needs to have awareness of, without being overwhelming. You can read it quickly in an hour, yet its guidance is something that I have continually referred. Any developer new to the civil service would benefit from taking the time with this document.\nI couldn’t discuss the Duck book without giving a special mention to the curated xkcd comic strips that the team have included at relevant points. It’s rare to get a sense of humour in a civil service publication and very much appreciated."
  },
  {
    "objectID": "book-reviews/05-career-reads.html#special-mentions",
    "href": "book-reviews/05-career-reads.html#special-mentions",
    "title": "4 Books That Shaped my Civil Service Career",
    "section": "Special Mentions",
    "text": "Special Mentions\nThese books are also great but perhaps have a more specialist readership or I am still in the process of reading and assimilating their concepts:\n\nThe Turing Way [5] for championing open source and reproducible data science.\nAQUA book [6] by Government Analysis Function & H.M. Treasury, guidance on producing quality analysis for government.\nDeep Work by Cal Newport: [7] Be more intentional with how you allocate your working day.\nComplexity Economics and Sustainable Development: A Computational Framework for Policy Priority Inference by Omar Guerrero and Gonzalo Castañeda [8]."
  },
  {
    "objectID": "book-reviews/05-career-reads.html#in-summary",
    "href": "book-reviews/05-career-reads.html#in-summary",
    "title": "4 Books That Shaped my Civil Service Career",
    "section": "In Summary",
    "text": "In Summary\nIn this article, I shared four books that influenced my journey in the UK civil service. These books provide a well-rounded toolkit for analysts, offering guidance on personal effectiveness, project management, data visualisation, and code quality assurance. They have been instrumental in shaping my career, and I hope they offer similar value to others embarking on a similar path."
  },
  {
    "objectID": "book-reviews/02-algorithms-to-live-by.html",
    "href": "book-reviews/02-algorithms-to-live-by.html",
    "title": "Algorithms to Live By",
    "section": "",
    "text": "Image credit: https://www.rawpixel.com/"
  },
  {
    "objectID": "book-reviews/02-algorithms-to-live-by.html#introduction",
    "href": "book-reviews/02-algorithms-to-live-by.html#introduction",
    "title": "Algorithms to Live By",
    "section": "Introduction",
    "text": "Introduction\nAs of today’s date, Algorithms to Live By (AtLB) scores an average of 4.13 / 5.00 across over 2.5k ratings on goodreads.\nAtLB made the MiT Technology Review Best Books of 2016 and Forbes’ Must Read Brain Books of the same year."
  },
  {
    "objectID": "book-reviews/02-algorithms-to-live-by.html#summary",
    "href": "book-reviews/02-algorithms-to-live-by.html#summary",
    "title": "Algorithms to Live By",
    "section": "Summary",
    "text": "Summary\nAtLB is a captivating read for those unfamiliar with the intricacies of computer science and how it manifests in our daily lives. Whether it’s deciding on a new restaurant to try, efficiently finding your next home, or optimizing your sock drawer, this book unveils how the brilliance of computer science has already addressed these everyday dilemmas. The authors guide us through the unexpected implications that computer science offers, presented in a manner that makes it easily accessible to a wider audience under the umbrella of popular science. While they skillfully refrain from downplaying its impact, reading this book will undoubtedly reshape your perception of sorting and problem-solving\n\nOn the Authors\nTom Griffiths is a celebrated Princeton professor in computational cognition and director of the University’s Computational Cognitive Science Laboratory [1]. The recipient of numerous awards and a leader in applied artificial intelligence research, Griffiths has many influential papers across a diverse set of problem spaces: Causal inference, natural language processing and pedagogy.\nBrian Christian has written several award winning works of nonfiction, notably “The Alignment Problem” which examines machine learning ethics, for which he received numerous awards. A visiting scholar at the University of California, Berkeley; Christian’s expertise ranges from programming to poetry, earning his laureate at San Francisco Public Library in 2016."
  },
  {
    "objectID": "book-reviews/02-algorithms-to-live-by.html#an-overview-of-the-book",
    "href": "book-reviews/02-algorithms-to-live-by.html#an-overview-of-the-book",
    "title": "Algorithms to Live By",
    "section": "An Overview of the Book",
    "text": "An Overview of the Book\nEach of the book’s eleven chapters delves into specific problem domains, unraveling the algorithms crafted to tackle them. From seemingly ‘simple’ tasks like optimized sorting of library books to the profound insights into behavioural economics explored in the game theory chapter, the book covers a spectrum of complexity in the problems addressed. The authors skillfully illustrate these concepts, infusing the text with a wealth of relatable examples, making it approachable even for those not well-versed in numerical intricacies.\nIn the sections below, I will explore some of the more engaging aspects of the book’s content.\n\nA Gentle Introduction to Operational Research\nThe authors skillfully address prevalent misconceptions about both computer science and human behavior in a manner that resonates with their audience. They challenge the notion that humans are too fuzzy-minded and fallible to benefit from optimization, emphasizing that many real-world challenges can indeed be optimised, albeit within defined parameters. Although certain problems may prove intractable due to an overwhelming number of potential solutions, the authors adeptly navigate this complexity by outlining how problems can be defined at their outset.\nThe introductory chapter poignantly captures these concepts through a relatable scenario — the search for the perfect New York apartment. By briefly exploring the optimal stopping problem in this context—whether to make an offer for an apartment or risk losing out on potentially the best one on the market, the authors provide readers with a glimpse into the fascinating direction of the book.\n\n\n\n\n\n\nNote\n\n\n\n“…spend 37% of your apartment hunt (eleven days, if you’ve given yourself a month for the search) noncommittally exploring options. Leave the checkbook at home; you’re just calibrating. But after that point, be prepared to immediately commit - deposit and all - to the very first place that beats whatever you’ve already seen.” [2, p. 2]\n\n\nAt that point, the authors hit the reader with a little taste of the magic in this book - that this problem is in many ways solved. That this same type of solution can be applied to a range of real world problems from parking your car to choosing a long-term partner, the concept that there exists a proof that at 37% of your search time you should immediately flip to committing has an almost Douglas Adams sort of quality to it.\n\n\n\n\n\n\nNote\n\n\n\n42: the “Answer to the Ultimate Question of Life, the Universe, and Everything” [3]\n\n\n\n\nOptimal Stopping\nChapter 1 of the book dedicates more to explaining the debated origins of what has become known as ‘The Secretary Problem’ - a common description of the Catch-22 described in the introduction. In the context of hiring an employee for example, hiring at random regardless of the candidate’s performance from a pool of 100 candidates would result in success for the employer on average 1% of the time. Success implies selecting the best applicant available in the pool.\nBy following the optimal stopping strategy, the average chances of hiring the best candidate within the pool increases to 37%. Whether or not you feel that is a good outcome is sort of subjective, but the authors discuss that this outcome remains stable as you scale up the applicant pool while random recruitment does not. For instance, interviewing a million candidates while adhering to optimal stopping could result in successfully recruiting the best candidate 37% of the time. Conversely, random recruitment under the same conditions would yield success at a rate of merely 0.0001%.\nThe example of scaling up this problem prompted me to consider some potential flaws in human behaviour, that would render any recruitment campaign unfair - optimised or otherwise. Standardising the recruitment process is known to be extremely challenging. Treating the problem like trial design, controlling for factors quickly results in confounding variables. If choosing to minimise variation in the appraisal process, you may consider retaining the same panel for each interview. Ensuring that the panel’s attention and mood are not affected by a demanding interview schedule becomes the next problem. Attempting to control for that results in extending the schedule period, possibly from days to months.\n\n\n\n\n\n\nNote\n\n\n\n““…no free lunch” (NFL) theorems… for any algorithm, any elevated performance over one class of problems is offset by performance over another class” [4]\n\n\nThe secretary problem is based on the presumption that an interviewer can only make relative comparisons or rankings of candidates, lacking absolute criteria or standardized aptitude tests to measure them against. Such an approach to interviewing, devoid of an objective threshold, would rightly be criticized for its susceptibility to human bias.\nAdditionally, the secretary problem assumes that an offer of employment would always lead to the candidate accepting, while passing up on a candidate would result in losing out on the possibility of recruiting that candidate forever. Few recruitment campaigns could operate under such conditions, however these assumptions could hold more relevance to scenarios such as selecting a parking space or selecting a long-term partner. Possibly. Although humans are complex organisms, the motivations driving that behaviour may lead to stable, predictable outcomes when considering a larger sample size.\nIn my assessment, the authors provided an intriguing treatment of optimal stopping solutions, prompting contemplation on their relevance to everyday scenarios and broader implications. However, I remain cautious about generalising this approach to most real-world scenarios, given the potential violations of the problem’s underlying assumptions.\n\n\nSorting\nAt the outset of the book, I realised that I had relied upon sorting algorithms in my professional and everyday life, but was a bit oblivious to their implementation. It is a commonplace need when exploring data to be able to sort columns of values in order to spot trends, identify outliers or problem values within a table. The authors demonstrate that sorting has become so deeply integrated into our lives that we may not even consciously acknowledge its presence or its role in enhancing our efficiency. Some of the more tangible sorting requirements explored are returning library books, the results of your Google search query and managing your Email inbox. Being able to sort based on any ordinal aspect of our data proves pivotal, allowing us to sequence our results and efficiently extract meaning.\n\n\n\n\n\n\nNote\n\n\n\n‘“What’s the best way to sort a million thirty-two-bit integers?” Without missing a beat, Obama cracked a wry smile and replied, “I think the Bubble Sort would be the wrong way to go.”’ [2, p. 65]\n\n\nThis chapter explores different sort algorithm’s efficacy. Shunning bubble-sort, dancing through insertion-sort, illustrating bucket-sort with actual buckets, talking through merge-sort complete with its own flow chart - the diversity on offer here is unexpected.\nConsider the method you choose for sorting your sock drawer. It may seem trivial, but it could have more fundamental implications than you might think. Did you ever imagine that you might be wasting precious moments of your life employing an inefficient insertion sort method? Perhaps the prospect of sock sorting inefficiencies isn’t the most pressing concern, but it does underscore a fascinating point — sorting algorithms, even in the realm of socks, can have a surprising impact on our daily routines. After all, can anything get more fundamental than starting with your socks?\nPerhaps the most meaningful takeaway for me in this chapter, is the concept that relaxing the rules of the sort can be acceptable in certain circumstances, and leads to pretty big performance gains. In all cases, performing a sort is useless without a search. Deciding on the accuracy (and time) of the sort should first consider the needs of the subsequent search.\n\n\n\n\n\n\nNote\n\n\n\n“Sorting something that you will never search is a complete waste; searching something you never sorted is merely inefficient” [2, p. 72]\n\n\nConsider a scenario where you have a vast dataset of customer transactions. If the objective is to quickly identify recent transactions within the last week, a more relaxed sorting approach might be perfectly adequate, prioritizing speed over precise chronological order. This relaxation of the sort rules can significantly improve the search efficiency and overall system performance. Understanding when and how to optimize the sort based on the requirements of the subsequent search is a crucial skill in efficiently handling data and making informed decisions.\nRelaxing the constraints on the accuracy of the sort and pre-sorting popular search items is revealed to be the approach adopted by many of the big search engines. With big data at their disposal, Google can ensure popular search terms have cached sorted results to be served immediately, ensuring a smooth experience for their users. The amount of resource and infrastructure in caching high traffic sorts across different territories must be mind-boggling.\nThis glimpse into the inner workings of search engine optimization not only makes the abstract concepts of sorting tangible but also instills a sense of admiration for the innovative minds behind these technological advancements. Paired with the forthcoming chapter on caching, the insights gained here are remarkably applicable to our everyday lives, shedding light on the strategies that power our online searches and experiences.\n\n\nCaching\nThis chapter is my highlight of the book. Beginning with a tangible concept of treating your wardrobe as a physical cache for your clothes, this chapter goes on to explore the evolution of memory management. Beginning with the fundamental trade off between capacity and performance, the authors discuss the invention of the memory hierarchy. This concept that forms the basis of modern memory management introduces a hierarchical structure, with a small, fast (high performance) amount of memory used to cache high frequency data. This memory cache would be coupled with larger, less expensive forms of slower-access memory.\n\n\n\n\n\n\nNote\n\n\n\n“The key, of course, would be managing that small, fast, precious memory so it had what you were looking for as often as possible.” [2, p. 87]\n\n\nClever optimisation of a more and more elaborate cache system is cited as the principle solution to the disparity in the exponential improvement of processing power relative to memory performance over the previous half a century. Again, the authors with their ability to ground the computer science in tangible analogy. Imagine a factory able to double its productivity year on year only to find that its output is soon limited by its supply chain - it simply cannot ingest the raw material at a rate to satisfy its output potential. Overcoming the problem of memory performance, referred to as the ‘memory wall’ has been crucial in securing performant applications and devices.\nManaging the state of the cache is treated with some detail. Competing algorithms for cache eviction - rules used to decide which memory to free up and when - are compared against the success criteria of avoiding what is known as a cache miss. A cache miss is a state where the data that you are looking for cannot be found within the cache and therefore must be retrieved from the slower memory store. Achieving this state appears to be on a par with divining the future, as who knows what the user will ask for next. Of the competing cache eviction algorithms considered are:\n\nRandom Eviction: Overwriting old data from the cache at random. Apparently not as poor a choice as it sounds.\nFirst in, First Out (FIFO): Overwriting the data that first entered the cache.\nLeast Recently Used (LRU): Overwriting the data that has remained untouched for the longest duration.\n\nAmong these, the ‘Least Recently Used’ algorithm emerges as the optimal choice, consistently outperforming the others in preventing cache misses. The authors go on to illuminate the far-reaching implications of this optimization, spanning from the physical construction of processors to the logistics of Amazon’s warehouses.\n\n\n\n\n\n\nNote\n\n\n\n“Computers’ default file-browsing interface makes you click through folders in alphabetical order - but the power of LRU suggest that you should override this, and display your files by”Last Opened” rather than “Name”. What you’re looking for will almost always be at or near the top.” [2, p. 98]"
  },
  {
    "objectID": "book-reviews/02-algorithms-to-live-by.html#analysis-and-evaluation",
    "href": "book-reviews/02-algorithms-to-live-by.html#analysis-and-evaluation",
    "title": "Algorithms to Live By",
    "section": "Analysis and Evaluation",
    "text": "Analysis and Evaluation\nAtLB proves to be an engaging read, making the intricate world of computer science accessible even to those without an undergrad in the field. The book adeptly navigates through five decades of computational thought and its implementation, ensuring the content never overwhelms the casual reader. One of its strengths lies in emphasizing tangible analogies and illustrating practical implications for everyday life, prompting thought and curiosity.\nThere are a number of instances where the problem domains have been framed in a way that has not aged so well. By today’s standard, The Secretary Problem could do with an overhaul. The authors acknowledge that the framing of this problem is a product of its time and that it could use an overhaul. But an aspect of AtLB is to provide the historic context and evolution of an idea, where it is available. In doing so, the authors reveal the stories of the people behind the big ideas, aspects of their life, work and the problems they were wrangling.\nFor IT professionals, while AtLB may not break new ground, it excels in illustrating the impact of optimization in a way that surpasses many formal textbooks. The book effectively builds awareness around the subject and its role in advancing society, providing a valuable framework for professionals in the field."
  },
  {
    "objectID": "book-reviews/02-algorithms-to-live-by.html#comparisons",
    "href": "book-reviews/02-algorithms-to-live-by.html#comparisons",
    "title": "Algorithms to Live By",
    "section": "Comparisons",
    "text": "Comparisons\nThis book offers a treatment of understanding the nuts and bolts and how society has implemented and optimised in response to the knowledge. This book can therefore be compared to a broad selection of popular science. Some similar books are:\n\nNaked Statistics by Charles Wheelan [5] explores how statistics can be misused to obfuscate key findings or serve a political agenda. It serves as a toolkit for understanding algorithms and being aware of their potential misapplications, providing readers with the ability to discern and critically analyse statistical information.\nHello World by Hannah Fry [6] delves into the implementation of algorithms in complex domains like Crime, Justice, and Healthcare. The book grapples with intricate ethical challenges, approaching the subject with warranted skepticism and scrutinising the far-reaching implications of algorithmic applications in various societal domains.\n\nIn contrast, AtLB offers a distinctly optimistic treatment, aiming to educate and instill an appreciation for the scale and implication of optimized solutions. It provides readers with an understanding of how computational thought has shaped our world and the positive impacts it can have in our rapidly evolving society."
  },
  {
    "objectID": "book-reviews/02-algorithms-to-live-by.html#recommendation",
    "href": "book-reviews/02-algorithms-to-live-by.html#recommendation",
    "title": "Algorithms to Live By",
    "section": "Recommendation",
    "text": "Recommendation\nI completed my reading of ‘AtLB’ in January of 2023, and to pen down this review, I revisited the book, speed-reading through noteworthy sections to reacquaint myself with its messages. At times I began deep reading the material, drawn in by its captivating narrative and insightful content. The book is a treasure trove of anecdotes and key summaries.\nIn my estimation, this is too good to miss for anyone with an interest in logic, analysis or is generally curious about exactly what computer science has achieved for us so far."
  },
  {
    "objectID": "blogs/index.html",
    "href": "blogs/index.html",
    "title": "Technical Blogs",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLazy Mocking\n\n\n10 min\n\n\n\nHow-to\n\n\npytest\n\n\nUnit tests\n\n\nmocking\n\n\npytest-in-plain-english\n\n\npatching\n\n\nlazy\n\n\nlazy evaluation\n\n\n\nUsing Fixtures to Mock With Deferred Evaluation\n\n\n\nRich Leyshon\n\n\nNov 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommit with Clarity\n\n\n14 min\n\n\n\nExplanation\n\n\nGitHub\n\n\nGit\n\n\nVersion Control\n\n\nSoftware Development\n\n\nBlame\n\n\nVSCode\n\n\nGit Grep\n\n\n\nBuilding a Better Audit Trail with GitHub\n\n\n\nRich Leyshon\n\n\nOct 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChoose Your Own Adventure with ChatGPT\n\n\n83 min\n\n\n\nTutorial\n\n\nPython Shiny\n\n\nLLMs\n\n\nLarge Language Models\n\n\nGenAI\n\n\nGenerative AI\n\n\nFront End Dev\n\n\nOpenAI\n\n\n\nIteratively Building an LLM-Powered Shiny Application.\n\n\n\nRich Leyshon\n\n\nSep 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Comments\n\n\n16 min\n\n\n\nExplanation\n\n\nQuarto\n\n\nComments\n\n\nHypothesis\n\n\nGitHub\n\n\nUtterances\n\n\nGiscus\n\n\n\nComparing Hypothesis, Utterances & Giscus.\n\n\n\nRich Leyshon\n\n\nAug 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustom Marks With Pytest in Plain English\n\n\n29 min\n\n\n\nExplanation\n\n\npytest\n\n\nUnit tests\n\n\nmarks\n\n\ncustom marks\n\n\nmarkers\n\n\npytest-in-plain-english\n\n\n\nSelectively running tests with marks\n\n\n\nRich Leyshon\n\n\nJul 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMocking With Pytest in Plain English\n\n\n33 min\n\n\n\nExplanation\n\n\npytest\n\n\nUnit tests\n\n\nmocking\n\n\npytest-in-plain-english\n\n\nmockito\n\n\nMagicMock\n\n\nmonkeypatch\n\n\n\nPlain English Comparison of Mocking Approaches in Python\n\n\n\nRich Leyshon\n\n\nJul 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Actions Security\n\n\n4 min\n\n\n\nHow-to\n\n\nGitHub\n\n\nGitHub Actions\n\n\nCI:CD\n\n\nSecurity\n\n\n\nCan you actually rely on that pre-built Action you rely on?\n\n\n\nRich Leyshon\n\n\nJun 26, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParametrized Tests With Pytest in Plain English\n\n\n23 min\n\n\n\nExplanation\n\n\npytest\n\n\nUnit tests\n\n\nparametrize\n\n\npytest-in-plain-english\n\n\n\nPlain English Discussion of Pytest Parametrize\n\n\n\nRich Leyshon\n\n\nJun 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPytest With tmp_path in Plain English\n\n\n16 min\n\n\n\nExplanation\n\n\npytest\n\n\nUnit tests\n\n\ntmp_path\n\n\ntmp_path_factory\n\n\nfixtures\n\n\npytest-in-plain-english\n\n\n\nPlain English Discussion of Pytest Temporary Fixtures.\n\n\n\nRich Leyshon\n\n\nApr 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPytest Fixtures in Plain English\n\n\n38 min\n\n\n\nExplanation\n\n\npytest\n\n\nUnit tests\n\n\nfixtures\n\n\npytest-in-plain-english\n\n\n\nPlain English Discussion of Pytest Fixtures.\n\n\n\nRich Leyshon\n\n\nApr 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Pydeck to Play Nicely with GeoPandas.\n\n\n5 min\n\n\n\nHow To\n\n\nGeospatial\n\n\npydeck\n\n\ngeopandas\n\n\n\nBuilding Pydeck Maps from GeoPandas GeoDataFrames.\n\n\n\nRich Leyshon\n\n\nFeb 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBicycle Network Modelling with r5py\n\n\n32 min\n\n\n\nTutorial\n\n\nTransport Modelling\n\n\nREST API\n\n\nWeb data\n\n\nGeospatial\n\n\nr5py\n\n\npydeck\n\n\n\nAnalysing service coverage in London’s Santander Bike network.\n\n\n\nRich Leyshon\n\n\nFeb 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConda Environments for Quarto Documents\n\n\n6 min\n\n\n\nHow-to\n\n\nQuarto\n\n\nConda Environments\n\n\nConda\n\n\n\nHow to specify a specific Conda environment when rendering quarto documents.\n\n\n\nRich Leyshon\n\n\nJan 6, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScheduled Deployment to Shinyapps.io\n\n\n11 min\n\n\n\nHow-to\n\n\nPython Shiny\n\n\nCI:CD\n\n\nGitHub\n\n\n\nUsing GitHub Actions to Automate Python Shiny App Deployments.\n\n\n\nRich Leyshon\n\n\nDec 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Data from ONS Open Geography Portal\n\n\n12 min\n\n\n\nTutorial\n\n\nONS Open Geography Portal\n\n\nREST API\n\n\nWeb data\n\n\n\nIngesting data using Python requests & ArcGIS REST API.\n\n\n\nRich Leyshon\n\n\nDec 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet Up Signed Commits on GitHub\n\n\n3 min\n\n\n\nHow-to\n\n\nGitHub\n\n\nAuthentication\n\n\nVerification\n\n\n\nA quick guide to setting up commit verification using a GPG key.\n\n\n\nRich Leyshon\n\n\nNov 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaximizing Loot Gains in Starfield: A Data-Driven Approach\n\n\n5 min\n\n\n\nExplanation\n\n\nVideo games\n\n\nData analysis\n\n\n\nDiscover the hidden riches of Bethesda’s Starfield with this data-driven guide. Learn what to strategically hoard in order to maximize your loot gains.\n\n\n\nRich Leyshon\n\n\nSep 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Automate Quarto Builds with GitHub Actions\n\n\n4 min\n\n\n\nHow-to\n\n\nCI/CD\n\n\nFront End Dev\n\n\n\nSetting up a website with Quarto? Want to automate the website build and publication with GitHub Actions? Could you use a quick guide? I’ve got your back.\n\n\n\nRich Leyshon\n\n\nSep 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe State of Python Shiny\n\n\n15 min\n\n\n\nExplanation\n\n\nPython Shiny\n\n\n\nAn overview of the progress of Python Shiny, and where it could possibly go.\n\n\n\nRich Leyshon\n\n\nJul 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s Build a Basic Python Shiny App\n\n\n21 min\n\n\n\nTutorial\n\n\nPython Shiny\n\n\n\nAn interactive tutorial allowing newcomers to Shiny to build a basic application.\n\n\n\nRich Leyshon\n\n\nJul 20, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blogs/18-jungle-quest-app.html#introduction",
    "href": "blogs/18-jungle-quest-app.html#introduction",
    "title": "Choose Your Own Adventure with ChatGPT",
    "section": "Introduction",
    "text": "Introduction\nThis article will guide you through the process of building a Choose Your Own Adventure game using OpenAI generative AI models and Python Shiny. We’ll walk through the entire journey, from concept to deployment, with a focus on the iterative development process and the use of ChatGPT for generating storylines.\nChoose Your Own Adventure is a classic storytelling format where the reader is presented with a series of choices that guide the story in different directions. The game is interactive, allowing the reader to make decisions that affect the outcome of the story. They were popular in the 1980s and early 1990s, widely available as graphic novels and comics with a fantasy or adventure theme.\nThe aim of this project is to produce an interactive application that will use AI to generate the branching outcomes depending on the choices made by the user. We will provide the user with an introduction to the theme and we will provide the model with the rules for the game. Each game will play out differently depending on the creative interplay between the user and the model.\n\n\n\n\n\n\nInspiration for This Blog (Click to expand)\n\n\n\n\n\nThe application concept was heavily influenced by the YouTube video by Tech with Tim called Python AI Choose Your Own Adventure Game - Tutorial. This tutorial uses a more complicated stack behind the scenes and resulted in a game that solved itself - essentially the model would also generate ‘imagined’ user responses through to completion. The tutorial was published only 11 months ago at the time of writing, though the code would not run without significant adaptation, due to a raft of breaking changes within langchain.\nI was inspired by the playful use of generative AI but could see that a few things could be done to improve the reproducibility of the code. Also, by simplifying the stack required to generate the game responses, it is hoped that the risk of deprecation and breaking changes will be reduced, increasing the longevity of the code. Finally, an application would be needed in order to allow the human player and model to take turns in playing the game. I have opted to use shiny for Python in order to achieve this, though the same functionality could be achieved with many other dashboarding solutions.\n\n\n\n\nIntended Audience\nPython programmers who are curious about building AI-enabled applications. Some familiarity with shiny may be assumed. For an overview and intro to building shiny apps with Python, check out my other blogs:\n\nThe State of Python shiny\nLet’s Build a Basic Python shiny App\n\n\n\nWhat You’ll Need\n\nCommand line access\nPython know-how\n\nConfigure a virtual environment\nDependency management\n\nBasic knowledge of Python Shiny\nAn OpenAI API key\n\n\n\nrequirements.txt\n\nopenai==1.30.4\nshiny==1.1.0\nshinyswatch==0.7.0\n\n\n\n\n\n\n\nA Note on the Purpose (Click to expand)\n\n\n\n\n\nThis article intends to discuss clearly. It doesn’t aim to be clever or impressive. Its aim is to extend understanding without overwhelming the reader. The code may not always be optimal, favouring a simplistic approach wherever possible. The application may not be to your liking. The purpose is to help learners build a simple AI-driven application rather than a masterpiece. If you have ideas for improvements to the app or blog, please feel free to leave a comment at the end of the article.\n\n\n\nThe final application is presented below, hosted with shinyapps.io. Please note, this is not configured for high traffic. Let me know if the app fails to launch for you by leaving a comment at the end of the blog. You will need an OpenAI API key in order to prompt the model. The app has a link to the sign up page if you would like to give it a try.\nIf you would prefer to read the source code for the application before proceeding with the article, then please click on the GitHub icon at the top-right of the application. If you would rather interact with the application in a full-sized window, then visit Jungle Quest app on shinyapps.io. This app is set up to query the gpt-3.5-turbo model, but as you proceed through the tutorial, feel free to experiment with other available models (they can behave quite differently)."
  },
  {
    "objectID": "blogs/18-jungle-quest-app.html#setting-up-the-development-environment",
    "href": "blogs/18-jungle-quest-app.html#setting-up-the-development-environment",
    "title": "Choose Your Own Adventure with ChatGPT",
    "section": "Setting up the Development Environment",
    "text": "Setting up the Development Environment\nI’d recommend using VSCode with the shiny extension to help run and debug the app. It has a handy utility for launching your app within the VSCode interface or expanding it to full screen in your default browser. This is priceless when testing your User Interface’s (UI) appearance on different browsers.\nYou’ll need to create and activate a virtual environment of your choice, I have used python 3.12 in the examples without any issues. install the dependencies listed in the requirements.txt file, and finally ensure that VSCode is configured to use the virtual environment."
  },
  {
    "objectID": "blogs/18-jungle-quest-app.html#iterative-development",
    "href": "blogs/18-jungle-quest-app.html#iterative-development",
    "title": "Choose Your Own Adventure with ChatGPT",
    "section": "Iterative Development",
    "text": "Iterative Development\n\n\n\n\n\n\nCaution\n\n\n\nTake care with your OpenAI APi credentials. I demonstrate hard-coding these credentials within python scripts for simplicity. I’d advise storing them in a git-ignored secrets file or using the python-dotenv package to keep them safe. Take care not to accidentally commit these credentials and expose them on GitHub. Leakage of OpenAI credentials is the fastest-growing type of secret leak, according to Git Guardian’s State of Secret Sprawl 2024.\nFinally, please note that usage of the openai service is associated with your account via your API key. Please conform to the service’s usage policy.\n\n\n\n\n\n\n\n\nCode Annotations\n\n\n\nClick on the numbered points within the code blocks, to reveal tooltips with additional explanations.\n\n\n\nIteration 1Iteration 2Iteration 3Iteration 4Iteration 5Iteration 6Iteration 7Iteration 8Iteration 9\n\n\nIn this early prototype, we will focus on using the openai python client to send a basic prompt to the gpt-3.5-turbo model.\n\n\napp.py\n\n\"\"\"Iteration 1: How to query the OpenAI API.\"\"\"\nimport openai\n\n1API_KEY = \"&lt;INSERT_YOUR_KEY_HERE&gt;\"\n\n\ndef query_openai(prompt: str, api_key: str) -&gt; str:\n    \"\"\"Query the chat completions endpoint.\n\n    Parameters\n    ----------\n    prompt: str\n        The prompt to query the chat completions endpoint with.\n    api_key: str\n        The API key to use to query the chat completions endpoint.\n\n    Returns\n    -------\n    str\n        The response from the chat completions endpoint.\n    \"\"\"\n\n2    client = openai.OpenAI(api_key=api_key)\n    # need to handle cases where queries go wrong.\n3    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n4            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        return response.choices[0].message.content\n    # in cases where the API key is invalid.\n    except openai.AuthenticationError as e:\n        raise ValueError(f\"Is your API key valid?:\\n {e}\")\n\n\n\nmodel_response = query_openai(\n  prompt=\"What is the capital of the moon?\", api_key=API_KEY\n  )\n\n\n1\n\nInsert your API key into the API_KEY variable. Note - it’s not advisable to include your secret credentials in your python scripts like this, but for simplicity’s sake, I’m showing that here. Take care not to accidentally commit these credentials and expose them on GitHub.\n\n2\n\nCreates a new OpenAI client with the api_key. This client can be reused to send queries to the different service endpoints.\n\n3\n\nThis will only pass if the key provided is valid.\n\n4\n\nNote the format of the messages - a list of dictionaries. The value for role can be “user”, “system” or “assistant”.\n\n\nThe model responds with:\n\nThe moon does not have a capital as it is not a sovereign nation or political entity.\n\nLet’s summarise the process with a diagram:\n\n\n\nProcess diagram for iteration 1\n\n\nSo far we have a basic query_openai() function that we can feed in a prompt and our api key. We then receive a response back from the openai model with the expected content.\nAlthough this is an extremely simple process, it’s great to start off with the fundamentals. Understanding the structure of what’s being sent and received is useful when we begin embedding this logic into our shiny app.\n\n\nIn this iteration, we are going to introduce a system message to help guide the behaviour of the model - we want the model to act as the guide on an adventure. We’ll also need it to follow a few rules such as how to indicate the game is over.\n\n\napp.py\n\n\"\"\"Iteration 2: Add system & welcome prompts.\"\"\"\nimport openai\n\nAPI_KEY = \"&lt;INSERT_YOUR_KEY_HERE&gt;\"\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n11. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n26. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\n3Welcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl.\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n\ndef query_openai(\n        prompt: str,\n        api_key: str,\n        sys_prompt:str = _SYSTEM_MSG,\n        start_prompt:str = WELCOME_MSG,\n        ) -&gt; str:\n    \"\"\"Query the chat completions endpoint.\n\n    Parameters\n    ----------\n    prompt: str\n        The prompt to query the chat completions endpoint with.\n    api_key: str\n        The API key to use to query the chat completions endpoint.\n    sys_prompt: str\n        The system prompt to help guide the model behaviour. By default,\n        the system prompt is set to _SYSTEM_MSG.\n    start_prompt: str\n        The start prompt which will be presented to the user as the app\n        begins. By default, the start prompt is set to WELCOME_MSG.\n\n    Returns\n    -------\n    str\n        The response from the chat completions endpoint.\n    \"\"\"\n\n    client = openai.OpenAI(api_key=api_key)\n    # need to handle cases where queries go wrong.\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n4            messages=[\n                {\"role\": \"system\", \"content\": sys_prompt},\n                {\"role\": \"assistant\", \"content\": start_prompt},\n                {\"role\": \"user\", \"content\": prompt},\n            ]\n        )\n        return response.choices[0].message.content\n    # in cases where the API key is invalid.\n    except openai.AuthenticationError as e:\n        raise ValueError(f\"Is your API key valid?:\\n {e}\")\n\n\nmodel_response = query_openai(\n    prompt=\"What is the capital of the moon?\",\n    api_key=API_KEY\n    )\n\n\n1\n\nCertain models can get a bit overzealous and start providing imagined user input, ultimately playing the game through to completion on their own. As games go, that’s not particularly fun, so let’s try to safeguard against that behaviour with these explicit instructions.\n\n2\n\nThe gpt-3.5-turbo model seems to be pretty reliable at ending the game with the required pattern “The end…”. We’ll later search for this pattern to exit the app and return a message indicating game over. Interestingly, I found gpt-4 models to be fairly unreliable in following this instruction. All of the models can be configured to stream their responses too, in which case they rarely gave the specified game over pattern. I’d be interested in others’ opinions as to why this may be the case. Please feel free to leave a comment at the end of the article if you have an opinion.\n\n3\n\nThis welcome message will be used to introduce the game context for our users when the app launches. We will append this into the message stream and simulate the LLM greeting our user. We will also include this message when querying the model, where it will serve as what’s known as a one-shot prompt to help guide the model’s behaviour. A one-shot prompt is an example of how you’d like the model to behave.\n\n4\n\nWe update the messages stream with our hard-coded prompts. This helps to guide both the model and the user, setting context and modelling the desired behaviour.\n\n\nThanks to the guidance in the hard-coded prompts, our model now behaves a bit differently:\n\nI’m afraid the Moon doesn’t have a capital city like countries on Earth do! Let’s focus on our adventure in the Amazon Rainforest. To begin, please choose your name, gender, and race. Additionally, select a weapon to arm yourself with on this mystical journey. The fate of finding the lost Crown of Quetzalcoatl awaits your choices!\n\nNotice that the model still answers the question, but guides the user back to the purpose of the app. In a later iteration, we will see how to introduce moderations as a safeguard against the user passing inappropriate content.\nFinally, updating our process diagram to include the additional prompts, I have emphasised the changes implemented within this iteration. As we proceed, the diagram’s complexity will increase and therefore I’ll try to emphasise the changes implemented over the previous iteration only:\n\n\n\nProcess diagram for iteration 2\n\n\n\n\nThis time, we’ll put together the basic UI for the app. The UI needs a text field to pass the user’s API key and the chat component. Let’s update the app script to include the shiny UI.\n\n\napp.py\n\n\"\"\"Iteration 3: A basic user interface with no server logic.\"\"\"\nimport openai\nfrom shiny import App, ui\n\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n1. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n6. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\nWelcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl.\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n\ndef query_openai(\n        prompt: str,\n        api_key: str,\n        sys_prompt:str = _SYSTEM_MSG,\n        start_prompt:str = WELCOME_MSG,\n        ) -&gt; str:\n    \"\"\"Query the chat completions endpoint.\n\n    Parameters\n    ----------\n    prompt: str\n        The prompt to query the chat completions endpoint with.\n    api_key: str\n        The API key to use to query the chat completions endpoint.\n    sys_prompt: str\n        The system prompt to help guide the model behaviour. By default,\n        the system prompt is set to _SYSTEM_MSG.\n    start_prompt: str\n        The start prompt which will be presented to the user as the app\n        begins. By default, the start prompt is set to WELCOME_MSG.\n\n    Returns\n    -------\n    str\n        The response from the chat completions endpoint.\n    \"\"\"\n\n    client = openai.OpenAI(api_key=api_key)\n    # need to handle cases where queries go wrong.\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\", \"content\": sys_prompt},\n                {\"role\": \"assistant\", \"content\": start_prompt},\n                {\"role\": \"user\", \"content\": prompt},\n            ]\n        )\n        return response.choices[0].message.content\n    # in cases where the API key is invalid.\n    except openai.AuthenticationError as e:\n        raise ValueError(f\"Is your API key valid?:\\n {e}\")\n\n\n# Shiny User Interface ----------------------------------------------------\n\n1app_ui = ui.page_fillable(\n    ui.panel_title(\"Choose Your Own Adventure: Jungle Quest!\"),\n2    ui.accordion(\n    ui.accordion_panel(\"Step 1: Your OpenAI API Key\",\n3        ui.input_text(id=\"key_input\", label=\"Enter your openai api key\"),\n    ), id=\"acc\", multiple=False),\n    ui.chat_ui(id=\"chat\"),                                                  \n    fillable_mobile=True,\n)\n\n4app = App(app_ui, server=None)\n\n\n1\n\nui.page_fillable() Works well with a chat component, increasing the height of your app to accommodate a growing chat log.\n\n2\n\nThe ui.accordion() component will present a collapsible panel. This will be useful for the key input panel - we can minimise the key input once finished with it and focus on the chat.\n\n3\n\nIn shiny UI elements, the first argument is usually the id. If you know CSS and HTML, then it’s the same id you’d target for styling an element. It’s really important in shiny as the server logic we’ll write later will communicate data to the UI via these id values. Make sure the id values are unique and do not include hyphens - use underscores instead.\n\n4\n\nIn this final step, we need to combine our UI with server logic to make things work. As we haven’t written any server logic yet, we can just pass None. This means our UI won’t do anything in its current state.\n\n\nFeel free to play around with the code and re-run the app using the play icon in the top-right corner of app.py. This interface uses the shinylive service which is useful for sharing simple shiny apps without any need for python installations.\n\n\nThe process diagram for our app so far looks like this:\n\n\n\nProcess diagram for iteration 3\n\n\nOur logic for talking to the OpenAI model has not yet been coupled with our UI. We’ll fold that logic into our shiny server in the next iteration.\n\n\nIn this part, we’ll take the logic from the query_openai() function defined in iteration 1 and use it to build our shiny server. The shiny server is typically referenced as the “backend” to our app.\n\n\napp.py\n\n\"\"\"Iteration 4: Server logic allows us to create a chat log.\"\"\"\nimport openai\nfrom shiny import App, ui\n\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n1. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n6. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\nWelcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl.\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n# compose a message stream\n_SYS = {\"role\": \"system\", \"content\": _SYSTEM_MSG}\n_WELCOME = {\"role\": \"assistant\", \"content\": WELCOME_MSG}\n1stream = [_SYS, _WELCOME]\n\n# Shiny User Interface ----------------------------------------------------\n\napp_ui = ui.page_fillable(\n    ui.panel_title(\"Choose Your Own Adventure: Jungle Quest!\"),\n    ui.accordion(\n    ui.accordion_panel(\"Step 1: Your OpenAI API Key\",\n        ui.input_text(id=\"key_input\", label=\"Enter your openai api key\"),\n    ), id=\"acc\", multiple=False),\n    ui.chat_ui(id=\"chat\"),\n    fillable_mobile=True,\n)\n\n# Shiny server logic ------------------------------------------------------\n\n\ndef server(input, output, session):\n2    chat = ui.Chat(\n        id=\"chat\", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None\n        )\n    \n\n    # Define a callback to run when the user submits a message\n    @chat.on_user_submit\n3    async def respond():\n        \"\"\"Respond to the user's message.\"\"\"\n        # Get the user's input\n        user = chat.user_input()\n        #  update the stream list\n        stream.append({\"role\": \"user\", \"content\": user})                    \n        # Append a response to the chat\n4        client = openai.AsyncOpenAI(api_key=input.key_input())\n5        response = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=stream,\n            temperature=0.7, # increase to make the model more creative\n            )\n        model_response = response.choices[0].message.content\n        await chat.append_message(model_response)\n        #  if the model indicates game over, end the game with a message.\n6        if \"the end...\" in model_response.lower():\n            await chat.append_message(\n                {\n                    \"role\": \"assistant\",\n                    \"content\": \"Game Over! Refresh the page to play again.\"\n                    })\n            exit()\n        else:\n            stream.append({\"role\": \"assistant\", \"content\": model_response}) \n\n\napp = App(ui=app_ui, server=server)\n\n\n1\n\nTo keep a running log of what’s been said, we assign chat messages to a stream list. When the user and model respond, we’ll dump that content as a dictionary at the end of this list.\n\n2\n\nHere we create the backend to our shiny chat interface. It’s vital that it has the same id value as the ui.chat_ui() element defined in our UI in iteration 3. This connection will allow the backend and frontend to communicate when we run the app.\n\n3\n\nWe use async here because it improves responsiveness, especially when dealing with potentially slow network requests to the OpenAI API.\n\n4\n\nWe’ve now switched over to the OpenAI Async client. This is better for working with event driven apps like this one. We no longer hard-code an API key. Instead, we’ll take the value from the ui.input_text() field. Notice that we reference the id value that we set when we defined the UI like a method call: input.key_input(). This is how shiny apps wire the frontend and backend together.\n\n5\n\nWe need to use await in parts of our server logic. This is because the model response typically takes some time to arrive and parts of the server would error until they receive it. Typically, anything that would raise an exception rather than returning None you’ll need to await in a shiny app.\n\n6\n\nThis part of our server is where we end the game. Notice that this is dependent on our model following rule 6 in _SYSTEM_MSG. Not all models are great at following that instruction. At the time of writing this blog, I’ve tested gpt-3.5-turbo, gpt-4o and chatgpt-4o-latest. In my testing I found gpt-3.5-turbo to be the most reliable at following this rule. But when I tested streaming the model responses, no models would end the game as requested. This is definitely the most flaky element of this app and is part of the fun of working with these models.\n\n\nUpdating the server logic for our process diagram, note that I have added a key that illustrates wherever we instantiate an openai client in the app. As we continue to build, handling the client becomes a bit involved so let’s start paying attention to wherever we’re using it:\n\n\n\nProcess diagram for iteration 4\n\n\nYou can see that the respond() function has become the busiest unit in the app. It takes the api key value from our UI, combines the user’s messages sent from the chat UI, adds these to the chat stream and communicates with the OpenAI model. Now these components are all wired up we get a running application. If you’ve made it this far - well done!\nYou can see me interacting with the resultant app in the video below. Note that I cannot use shinylive to host a working version of this iteration as unfortunately the openai package is not available on that service.\n\n\n\n\n\n\nImportant\n\n\n\nI use a real OpenAI API key in these clips to demonstrate the application. Note that I have since revoked this key and it will no longer work. You should not share your secret keys with anyone.\n\n\n\n\nNotice that I attempt to use a nonsense key value and we get a nasty-looking error. Luckily, it’s not a fatal one - the app doesn’t crash. But we should think about handling cases where the key is bad and give a more accessible notification to the user instead.\n\n\nIn this version, we build on our working app to improve the user experience. We’ll add a ‘submit’ button, which the user can use when they’re ready to use their key. We also provide notifications to the user when they submit their key, but we won’t be checking whether the key is valid until the next iteration.\n\n\napp.py\n\n\"\"\"Iteration 5: Submit button & notifications for the user.\"\"\"\nimport openai\nfrom shiny import App, reactive, ui\n\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n1. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n6. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\nWelcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl.\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n# compose a message stream\n_SYS = {\"role\": \"system\", \"content\": _SYSTEM_MSG}\n_WELCOME = {\"role\": \"assistant\", \"content\": WELCOME_MSG}\nstream = [_SYS, _WELCOME]\n\n# Shiny User Interface ----------------------------------------------------\n\n\n1def input_text_with_button(id, label, button_label, placeholder=\"\"):\n    \"\"\"\n    An interface component combining an input text widget with an action\n    button. IDs for the text field and button can be accessed as &lt;id&gt;_text\n    and &lt;id&gt;_btn respectively.\n    \"\"\"\n    return ui.div(\n        ui.input_text(\n2            id=f\"{id}_text\", label=label, placeholder=placeholder),\n        ui.input_action_button(\n            id=f\"{id}_btn\",\n            label=button_label,\n3            style=\"margin-top:28px;margin-bottom:16px;color:#04bb8c;border-color:#04bb8c;\"\n            ),\n        class_=\"d-flex gap-2\"\n    )\n\n\napp_ui = ui.page_fillable(\n    ui.panel_title(\"Choose Your Own Adventure: Jungle Quest!\"),\n    ui.accordion(\n    ui.accordion_panel(\"Step 1: Your OpenAI API Key\",\n4        input_text_with_button(\n            id=\"key_input\",\n            label=\"Enter your OpenAI API key\",\n            button_label=\"Submit\",\n            placeholder=\"Enter key here\"\n            )), id=\"acc\", multiple=False),\nui.h6(\"Step 2: Choose your adventure\"),\n    ui.chat_ui(id=\"chat\"),\n    fillable_mobile=True,\n)\n\n# Shiny server logic ------------------------------------------------------\n\n\ndef server(input, output, session):\n    chat = ui.Chat(\n        id=\"chat\", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None\n        )\n\n\n5    @reactive.Effect\n    @reactive.event(input.key_input_btn)\n    def handle_api_key_submit():\n        \"\"\"Update the UI with a notification when user submits key.\"\"\"\n        api_key = input.key_input_text()\n        if api_key:\n            ui.notification_show(f\"API key submitted: {api_key[:5]}...\")\n        else:\n            ui.notification_show(\"Please enter an API key\", type=\"warning\")\n\n\n    # Define a callback to run when the user submits a message\n    @chat.on_user_submit\n    async def respond():\n        \"\"\"Respond to the user's message.\"\"\"\n        # Get the user's input\n        user = chat.user_input()\n        #  update the stream list\n        stream.append({\"role\": \"user\", \"content\": user})\n        # Append a response to the chat\n        client = openai.AsyncOpenAI(api_key=input.key_input_text())\n        response = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=stream,\n            temperature=0.7, # increase to make the model more creative\n            )\n        model_response = response.choices[0].message.content\n        await chat.append_message(model_response)\n        #  if the model indicates game over, end the game with a message.\n        if \"the end...\" in model_response.lower():\n            await chat.append_message(\n                {\n                    \"role\": \"assistant\",\n                    \"content\": \"Game Over! Refresh the page to play again.\"\n                    })\n            exit()\n        else:\n            stream.append({\"role\": \"assistant\", \"content\": model_response})\n\n\napp = App(ui=app_ui, server=server)\n\n\n1\n\nHere we define a new function that’s used to conveniently return a text field and an action button together. This is what we’ll use for the key input going forward.\n\n2\n\nNotice that the id value that we’ll pass into input_text_with_button() will return separate unique id values for the text field and action button.\n\n3\n\nFeel free to experiment with styling any elements with CSS. If you’d rather not have inline CSS, you can move the styling into a dedicated CSS file and apply it with classes or IDs to the elements in your UI.\n\n4\n\nWe replace the text field of previous iterations with our new input_text_with_button() text field & action button combo.\n\n5\n\nIn the server, we define a new function that will run whenever the action button with id=input.key_input_btn is clicked by the user. If there’s a value that’s been submitted we’re going to place a confirmation notification on the UI. If not, we’ll raise a warning to the user to remind them to submit their key.\n\n\nI’ve added a marker in the process diagram to remind us that handle_api_key_submit() will run as a reactive event when the key is submitted. This function updates the UI with feedback notifications.\n\n\n\nProcess diagram for iteration 5\n\n\n\n\n\n\n\n\nTip\n\n\n\nUsing ui_notification_show() is a really useful method for debugging reactive values when your app breaks. Use it to check on intermediate values that the frontend receives from the backend.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI use a real OpenAI API key in these clips to demonstrate the application working. Note that I have since revoked this key and it will no longer work. You should not share your secret keys with anyone.\n\n\nIn the recording below, you can see the new action button and the UI notifications being returned by the server. However, note that I still get that nasty red error when I pass an invalid key. In the next iteration, we’ll determine whether the user has used a valid key.\n\n\n\n\nIn this version of the app we will introduce more backend logic that will check whether the key the user has submitted is a valid one.\n\n\napp.py\n\n\"\"\"Iteration 6: Check the key is valid.\"\"\"\nimport openai\nfrom shiny import App, reactive, ui\n\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n1. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n6. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\nWelcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl.\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n# compose a message stream\n_SYS = {\"role\": \"system\", \"content\": _SYSTEM_MSG}\n_WELCOME = {\"role\": \"assistant\", \"content\": WELCOME_MSG}\nstream = [_SYS, _WELCOME]\n\n# Shiny User Interface ----------------------------------------------------\n\n\ndef input_text_with_button(id, label, button_label, placeholder=\"\"):\n    \"\"\"\n    An interface component combining an input text widget with an action\n    button. IDs for the text field and button can be accessed as &lt;id&gt;_text\n    and &lt;id&gt;_btn respectively.\n    \"\"\"\n    return ui.div(\n        ui.input_text(\n            id=f\"{id}_text\", label=label, placeholder=placeholder),\n        ui.input_action_button(\n            id=f\"{id}_btn\",\n            label=button_label,\n            style=\"margin-top:28px;margin-bottom:16px;color:#04bb8c;border-color:#04bb8c;\"\n            ),\n        class_=\"d-flex gap-2\"\n    )\n\n\napp_ui = ui.page_fillable(\n    ui.panel_title(\"Choose Your Own Adventure: Jungle Quest!\"),\n    ui.accordion(\n    ui.accordion_panel(\"Step 1: Your OpenAI API Key\",\n        input_text_with_button(\n            id=\"key_input\",\n            label=\"Enter your OpenAI API key\",\n            button_label=\"Submit\",\n            placeholder=\"Enter key here\"\n            )), id=\"acc\", multiple=False),\nui.h6(\"Step 2: Choose your adventure\"),\n    ui.chat_ui(id=\"chat\"),\n    fillable_mobile=True,\n)\n\n# Shiny server logic ------------------------------------------------------\n\n\ndef server(input, output, session):\n    chat = ui.Chat(\n        id=\"chat\", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None\n        )\n\n    @reactive.Effect\n    @reactive.event(input.key_input_btn)\n    async def handle_api_key_submit():\n        \"\"\"Update the UI with a notification when user submits key.\n        \n        Checks the validity of the API key by querying the models list\n        endpoint.\"\"\"\n        api_key = input.key_input_text()\n1        client = openai.AsyncOpenAI(api_key=api_key)\n        try:\n2            resp = await client.models.list()\n            if resp:\n                ui.notification_show(\n                    f\"API key validated: {api_key[:5]}...\")\n3        except openai.AuthenticationError as e:\n            ui.notification_show(\n                \"Bad key provided. Please try again.\", type=\"warning\")\n\n\n    # Define a callback to run when the user submits a message\n    @chat.on_user_submit\n    async def respond():\n        \"\"\"Respond to the user's message.\"\"\"\n        # Get the user's input\n        user = chat.user_input()\n        #  update the stream list\n        stream.append({\"role\": \"user\", \"content\": user})\n        # Append a response to the chat\n        client = openai.AsyncOpenAI(api_key=input.key_input_text())\n        response = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=stream,\n            temperature=0.7, # increase to make the model more creative\n            )\n        model_response = response.choices[0].message.content\n        await chat.append_message(model_response)\n        #  if the model indicates game over, end the game with a message.\n        if \"the end...\" in model_response.lower():\n            await chat.append_message(\n                {\n                    \"role\": \"assistant\",\n                    \"content\": \"Game Over! Refresh the page to play again.\"\n                    })\n            exit()\n        else:\n            stream.append({\"role\": \"assistant\", \"content\": model_response})\n\n\napp = App(ui=app_ui, server=server)\n\n\n1\n\nNotice that we are now creating another openai client. This is so that we can test the key to see whether it successfully queries the openai service, before using it to play the game. Initiating multiple clients is not needed and is inefficient design. In a later iteration we’ll come back to this.\n\n2\n\nThis time, we’ll query the models.list() endpoint to get a list of models available. There is currently no OpenAI endpoint for explicitly checking whether a service is valid. OpenAI API support team responded to my support ticket to suggest this as the best method for ensuring a key is valid.\n\n3\n\nIn cases where a bad key is provided, we can avoid the openai.AuthenticationError and print a warning to the UI instead.\n\n\nIn our increasingly complex process diagram, I’ve emphasised that handle_api_key_submit() now instantiates another client object and uses it to query the models.list endpoint of the OpenAI service.\n\n\n\nProcess diagram for iteration 6\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI use a real OpenAI API key in these clips to demonstrate the application working. Note that I have since revoked this key and it will no longer work. You should not share your secret keys with anyone.\n\n\nIn the recording below I demonstrate how this version of the app will return a warning to the user if the submitted key was not valid.\n\n\n\n\nNow we introduce a moderation feature that will check that the prompts being passed from the user to the OpenAI service comply with the service’s usage policies. Forewarned - this is far from perfect!\nIn general, it’s pretty good but if you’re intentionally trying to test it like I did when implementing this feature, you can find some funny quirks. British expletives tend to sail through unchallenged and at times my test prompts were raised as violations for stating things like “Let’s fight!” (category: harassment) when that was one of the options provided to me by the model! It’s likely that passing greater context to the moderations endpoint (such as more of the message stream) may be able to overcome this, though that has not been implemented for this tutorial.\n\n\napp.py\n\n\"\"\"Iteration 7: Implement prompt moderation.\"\"\"\nimport openai\nfrom shiny import App, reactive, ui\n\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n1. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n6. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\nWelcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl.\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n# compose a message stream\n_SYS = {\"role\": \"system\", \"content\": _SYSTEM_MSG}\n_WELCOME = {\"role\": \"assistant\", \"content\": WELCOME_MSG}\nstream = [_SYS, _WELCOME]\n\n# Shiny User Interface ----------------------------------------------------\n\n\ndef input_text_with_button(id, label, button_label, placeholder=\"\"):\n    \"\"\"\n    An interface component combining an input text widget with an action\n    button. IDs for the text field and button can be accessed as &lt;id&gt;_text\n    and &lt;id&gt;_btn respectively.\n    \"\"\"\n    return ui.div(\n        ui.input_text(\n            id=f\"{id}_text\", label=label, placeholder=placeholder),\n        ui.input_action_button(\n            id=f\"{id}_btn\",\n            label=button_label,\n            style=\"margin-top:28px;margin-bottom:16px;color:#04bb8c;border-color:#04bb8c;\"\n            ),\n        class_=\"d-flex gap-2\"\n    )\n\n\napp_ui = ui.page_fillable(\n    ui.panel_title(\"Choose Your Own Adventure: Jungle Quest!\"),\n    ui.accordion(\n    ui.accordion_panel(\"Step 1: Your OpenAI API Key\",\n        input_text_with_button(\n            id=\"key_input\",\n            label=\"Enter your OpenAI API key\",\n            button_label=\"Submit\",\n            placeholder=\"Enter key here\"\n            )), id=\"acc\", multiple=False),\nui.h6(\"Step 2: Choose your adventure\"),\n    ui.chat_ui(id=\"chat\"),\n    fillable_mobile=True,\n)\n\n# Shiny server logic ------------------------------------------------------\n\n\ndef server(input, output, session):\n    chat = ui.Chat(\n        id=\"chat\", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None\n        )\n\n\n    @reactive.Effect\n    @reactive.event(input.key_input_btn)\n    async def handle_api_key_submit():\n        \"\"\"Update the UI with a notification when user submits key.\n        \n        Checks the validity of the API key by querying the models list\n        endpoint.\"\"\"\n        api_key = input.key_input_text()\n        client = openai.AsyncOpenAI(api_key=api_key)\n        try:\n            resp = await client.models.list()\n            if resp:\n                ui.notification_show(\n                    f\"API key validated: {api_key[:5]}...\")\n        except openai.AuthenticationError as e:\n            ui.notification_show(\n                \"Bad key provided. Please try again.\", type=\"warning\")\n    \n\n1    async def check_moderation(prompt:str) -&gt; str:\n        \"\"\"Check if prompt is flagged by OpenAI's moderation endpoint.\n\n        Parameters\n        ----------\n        prompt : str\n            The user's prompt to check.\n\n        Returns\n        -------\n        str\n            The category violations if flagged, otherwise \"good prompt\".\n        \"\"\"\n2        client = openai.AsyncOpenAI(api_key=input.key_input_text())\n        response = await client.moderations.create(\n            input=prompt)\n        content = response.results[0].to_dict()\n3        if content[\"flagged\"]:\n            infringements = []\n            for key, val in content[\"categories\"].items():\n                if val:\n                    infringements.append(key)\n4            return \" & \".join(infringements)\n        else:\n5            return \"good prompt\"\n\n\n    # Define a callback to run when the user submits a message\n    @chat.on_user_submit\n    async def respond():\n        \"\"\"Respond to the user's message.\"\"\"\n        # Get the user's input\n        usr_prompt = chat.user_input()\n\n        # Check moderations endpoint incase openai policies are violated\n        flag_check = await check_moderation(prompt=usr_prompt)\n6        if flag_check != \"good prompt\":\n            await chat.append_message({\n                \"role\": \"assistant\",\n                \"content\": f\"Your message may violate OpenAI's usage policy, categories: {flag_check}. Please rephrase your input and try again.\"\n            })\n        else:\n            #  update the stream list\n            stream.append({\"role\": \"user\", \"content\": usr_prompt})\n            # Append a response to the chat\n            client = openai.AsyncOpenAI(api_key=input.key_input_text())\n            response = await client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=stream,\n                temperature=0.7, # increase to make the model more creative\n                )\n            model_response = response.choices[0].message.content\n            await chat.append_message(model_response)\n            #  if the model indicates game over, end game with a message.\n            if \"the end...\" in model_response.lower():\n                await chat.append_message(\n                    {\n                        \"role\": \"assistant\",\n                        \"content\": \"Game Over! Refresh to play again.\"\n                        })\n                exit()\n            else:\n                stream.append(\n                    {\"role\": \"assistant\", \"content\": model_response})\n\n\napp = App(ui=app_ui, server=server)\n\n\n1\n\nWe define a new function that will query the OpenAI moderations endpoint.\n\n2\n\nNotice that we create a third openai client in order to handle the communication with the service. In the next iteration we will refactor this.\n\n3\n\nIf the prompt has violated any category, then the value of the flagged key will be True.\n\n4\n\nIn cases where multiple categories are violated, we will include each breached category in a message to the user.\n\n5\n\nThe return value in the case of a prompt that passes the moderation check.\n\n6\n\nWe implement some control flow to query the chat.completions endpoint only if the moderations check passes.\n\n\nThe updated process diagram clarifies the reactive flow of the app. Now prompts from the user pass through check_moderations() first. The outcome of check moderations is then passed along within the respond() function, determining whether the prompt would be passed along to the chat.completions endpoint.\n\n\n\nProcess diagram for iteration 7\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI use a real OpenAI API key in these clips to demonstrate the application working. Note that I have since revoked this key and it will no longer work. You should not share your secret keys with anyone.\n\n\nWhen using this iteration of the app, you can see that certain prompts may now be flagged as inappropriate. Note that this also reduces the performance of our app, as we need to send and process 2 queries for each prompt that the user enters.\n\n\n\n\nWe have nearly arrived at our final design. In this stage, we refactor the application to ensure we use a single openai client to query the separate endpoints.\n\n\napp.py\n\n\"\"\"Iteration 8: Refactor OpenAI client instantiation.\"\"\"\nimport openai\nfrom shiny import App, reactive, ui\n\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n1. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n6. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\nWelcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl.\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n# compose a message stream\n_SYS = {\"role\": \"system\", \"content\": _SYSTEM_MSG}\n_WELCOME = {\"role\": \"assistant\", \"content\": WELCOME_MSG}\nstream = [_SYS, _WELCOME]\n\n# Shiny User Interface ----------------------------------------------------\n\n\ndef input_text_with_button(id, label, button_label, placeholder=\"\"):\n    \"\"\"\n    An interface component combining an input text widget with an action\n    button. IDs for the text field and button can be accessed as &lt;id&gt;_text\n    and &lt;id&gt;_btn respectively.\n    \"\"\"\n    return ui.div(\n        ui.input_text(\n            id=f\"{id}_text\", label=label, placeholder=placeholder),\n        ui.input_action_button(\n            id=f\"{id}_btn\",\n            label=button_label,\n            style=\"margin-top:28px;margin-bottom:16px;color:#04bb8c;border-color:#04bb8c;\"\n            ),\n        class_=\"d-flex gap-2\"\n    )\n\n\napp_ui = ui.page_fillable(\n    ui.panel_title(\"Choose Your Own Adventure: Jungle Quest!\"),\n    ui.accordion(\n    ui.accordion_panel(\"Step 1: Your OpenAI API Key\",\n        input_text_with_button(\n            id=\"key_input\",\n            label=\"Enter your OpenAI API key\",\n            button_label=\"Submit\",\n            placeholder=\"Enter key here\"\n            )), id=\"acc\", multiple=False),\nui.h6(\"Step 2: Choose your adventure\"),\n    ui.chat_ui(id=\"chat\"),\n    fillable_mobile=True,\n)\n\n# Shiny server logic ------------------------------------------------------\n\n\ndef server(input, output, session):\n    chat = ui.Chat(\n        id=\"chat\", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None\n        )\n    #  define a reactive value that will store the openai client\n1    openai_client = reactive.Value(None)\n\n\n    @reactive.Effect\n    @reactive.event(input.key_input_btn)\n    async def handle_api_key_submit():\n        \"\"\"Update the UI with a notification when user submits key.\n        \n        Checks the validity of the API key by querying the models list\n        endpoint.\"\"\"\n        api_key = input.key_input_text()\n        client = openai.AsyncOpenAI(api_key=api_key)\n        try:\n            resp = await client.models.list()\n            if resp:\n2                openai_client.set(client)\n                ui.notification_show(\n                    f\"API key validated: {api_key[:5]}...\")\n        except openai.AuthenticationError as e:\n            ui.notification_show(\n                \"Bad key provided. Please try again.\", type=\"warning\")\n    \n\n    async def check_moderation(\n            prompt:str, reactive_client:reactive.Value\n            ) -&gt; str:\n        \"\"\"Check if prompt is flagged by OpenAI's moderation endpoint.\n\n        Parameters\n        ----------\n        prompt : str\n            The user's prompt to check.\n        reactive_client : reactive.Value\n            A reactive value that stores the openai client.\n\n        Returns\n        -------\n        str\n            The category violations if flagged, otherwise \"good prompt\".\n        \"\"\"\n        client = reactive_client.get()\n        response = await client.moderations.create(\n            input=prompt)\n        content = response.results[0].to_dict()\n        if content[\"flagged\"]:\n            infringements = []\n            for key, val in content[\"categories\"].items():\n                if val:\n                    infringements.append(key)\n            return \" & \".join(infringements)\n        else:\n            return \"good prompt\"\n    \n\n    # Define a callback to run when the user submits a message\n    @chat.on_user_submit\n    async def respond():\n        \"\"\"Respond to the user's message.\"\"\"\n        # Get the user's input\n        usr_prompt = chat.user_input()\n\n        # Check moderations endpoint incase openai policies are violated\n        flag_check = await check_moderation(\n3            prompt=usr_prompt, reactive_client=openai_client)\n        if flag_check != \"good prompt\":\n            await chat.append_message({\n                \"role\": \"assistant\",\n                \"content\": f\"Your message may violate OpenAI's usage policy, categories: {flag_check}. Please rephrase your input and try again.\"\n            })\n        else:\n            #  update the stream list\n            stream.append({\"role\": \"user\", \"content\": usr_prompt})\n            # Append a response to the chat\n4            response = await openai_client.get().chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=stream,\n                temperature=0.7, # increase to make the model more creative\n                )\n            model_response = response.choices[0].message.content\n            await chat.append_message(model_response)\n            #  if the model indicates game over, end game with a message.\n            if \"the end...\" in model_response.lower():\n                await chat.append_message(\n                    {\n                        \"role\": \"assistant\",\n                        \"content\": \"Game Over! Refresh to play again.\"\n                        })\n                exit()\n            else:\n                stream.append(\n                    {\"role\": \"assistant\", \"content\": model_response})\n\n\napp = App(ui=app_ui, server=server)\n\n\n1\n\nshiny reactive values are often good choices for objects that you intend to update at multiple points within a shiny server. Here we are defining an empty reactive value that we can subsequently use to store and access an openai client.\n\n2\n\nIt’s a subtle change, but now if the client returns a list of models, validating the api key that the user passed, then we set that client as the return value of openai_client.\n\n3\n\nThe check_moderations() function expects to receive the reactive value object and will use it to .get() the stored client.\n\n4\n\nThis is the last occasion that we access the reactive client value. We initiated the client once and used it in three places to query 3 different endpoints.\n\n\nThis refactoring reduces the complexity of the app, ensuring that once the api key has been validated, that same openai client will be passed to the moderations and chat.completions endpoints.\n\n\n\nProcess diagram for iteration 8\n\n\n\n\nIn this final stage, we introduce some aesthetic changes - adding a theme and an image to chat UI, adding to the feel of the app. It’s always nice to leave some of the styling towards the end of a build, a bit like adding the cherry to a cake.\n\n\napp.py\n\n\"\"\"Iteration 9: Styling.\"\"\"\nimport openai\nfrom shiny import App, reactive, ui\n1from shinyswatch import theme\n\n_SYSTEM_MSG = \"\"\"\nYou are the guide of a 'choose your own adventure'- style game: a mystical\njourney through the Amazon Rainforest. Your job is to create compelling\noutcomes that correspond with the player's choices. You must navigate the\nplayer through challenges, providing choices, and consequences, dynamically\nadapting the tale based on the player's inputs. Your goal is to create a\nbranching narrative experience where each of the player's choices leads to\na new path, ultimately determining their fate. The player's goal is to find\nthe lost crown of Quetzalcoatl.\n\nHere are some rules to follow:\n1. Always wait for the player to respond with their input before providing\nany choices. Never provide the player's input yourself. This is most\nimportant.\n2. Ask the player to provide a name, gender and race.\n3. Ask the player to choose from a selection of weapons that will be used\nlater in the game.\n4. Have a few paths that lead to success. \n5. Have some paths that lead to death.\n6. Whether or not the game results in success or death, the response must\ninclude the text \"The End...\", I will search for this text to end the game.\n\"\"\"\n\nWELCOME_MSG = \"\"\"\nWelcome to the Amazon Rainforest, adventurer! Your mission is to find the\nlost Crown of Quetzalcoatl:\\n\n2&lt;div style=\"display: grid; place-items: center;\"&gt;&lt;img src=\"https://i.imgur.com/Fxa7p1D.jpeg\" width=60%/&gt;&lt;/div&gt;\\n\nHowever, many challenges stand in your way. Are you brave enough, strong\nenough and clever enough to overcome the perils of the jungle and secure\nthe crown?\n\nBefore we begin our journey, choose your name, gender and race. Choose a\nweapon to bring with you. Choose wisely, as the way ahead is filled with\nmany dangers.\n\"\"\"\n\n# compose a message stream\n_SYS = {\"role\": \"system\", \"content\": _SYSTEM_MSG}\n_WELCOME = {\"role\": \"assistant\", \"content\": WELCOME_MSG}\nstream = [_SYS, _WELCOME]\n\n# Shiny User Interface ----------------------------------------------------\n\n\ndef input_text_with_button(id, label, button_label, placeholder=\"\"):\n    \"\"\"\n    An interface component combining an input text widget with an action\n    button. IDs for the text field and button can be accessed as &lt;id&gt;_text\n    and &lt;id&gt;_btn respectively.\n    \"\"\"\n    return ui.div(\n        ui.input_text(\n            id=f\"{id}_text\", label=label, placeholder=placeholder),\n        ui.input_action_button(\n            id=f\"{id}_btn\",\n            label=button_label,\n            style=\"margin-top:32px;margin-bottom:16px;color:#04bb8c;border-color:#04bb8c;\"\n            ),\n        class_=\"d-flex gap-2\"\n    )\n\n\napp_ui = ui.page_fillable(\n    ui.panel_title(\"Choose Your Own Adventure: Jungle Quest!\"),\n    ui.accordion(\n    ui.accordion_panel(\"Step 1: Your OpenAI API Key\",\n        input_text_with_button(\n            id=\"key_input\",\n            label=\"Enter your OpenAI API key\",\n            button_label=\"Submit\",\n            placeholder=\"Enter key here\"\n            )), id=\"acc\", multiple=False),\nui.h6(\"Step 2: Choose your adventure\"),\n    ui.chat_ui(id=\"chat\"),\n    fillable_mobile=True,\n3    theme=theme.darkly,\n)\n\n# Shiny server logic ------------------------------------------------------\n\n\ndef server(input, output, session):\n    chat = ui.Chat(\n        id=\"chat\", messages=[ui.markdown(WELCOME_MSG)], tokenizer=None\n        )\n    #  define a reactive value that will store the openai client\n    openai_client = reactive.Value(None)\n\n\n    @reactive.Effect\n    @reactive.event(input.key_input_btn)\n    async def handle_api_key_submit():\n        \"\"\"Update the UI with a notification when user submits key.\n        \n        Checks the validity of the API key by querying the models list\n        endpoint.\"\"\"\n        api_key = input.key_input_text()\n        client = openai.AsyncOpenAI(api_key=api_key)\n        try:\n            resp = await client.models.list()\n            if resp:\n                openai_client.set(client)\n                ui.notification_show(\n                    f\"API key validated: {api_key[:5]}...\")\n        except openai.AuthenticationError as e:\n            ui.notification_show(\n                \"Bad key provided. Please try again.\", type=\"warning\")\n    \n\n    async def check_moderation(\n            prompt:str, reactive_client:reactive.Value\n            ) -&gt; str:\n        \"\"\"Check if prompt is flagged by OpenAI's moderation endpoint.\n\n        Parameters\n        ----------\n        prompt : str\n            The user's prompt to check.\n        reactive_client : reactive.Value\n            A reactive value that stores the openai client.\n\n        Returns\n        -------\n        str\n            The category violations if flagged, otherwise \"good prompt\".\n        \"\"\"\n        client = reactive_client.get()\n        response = await client.moderations.create(\n            input=prompt)\n        content = response.results[0].to_dict()\n        if content[\"flagged\"]:\n            infringements = []\n            for key, val in content[\"categories\"].items():\n                if val:\n                    infringements.append(key)\n            return \" & \".join(infringements)\n        else:\n            return \"good prompt\"\n    \n\n    # Define a callback to run when the user submits a message\n    @chat.on_user_submit\n    async def respond():\n        \"\"\"Respond to the user's message.\n        \n        First check that OpenAI's usage policies are not moderated. If this\n        passes, then respond with a message from the model. If the model\n        has ended the game, then exit the game.\"\"\"\n        # Get the user's input\n        usr_prompt = chat.user_input()\n\n        # Check moderations endpoint incase openai policies are violated\n        flag_check = await check_moderation(\n            prompt=usr_prompt, reactive_client=openai_client)\n        if flag_check != \"good prompt\":\n            await chat.append_message({\n                \"role\": \"assistant\",\n                \"content\": f\"Your message may violate OpenAI's usage policy, categories: {flag_check}. Please rephrase your input and try again.\"\n            })\n        else:\n            #  update the stream list\n            stream.append({\"role\": \"user\", \"content\": usr_prompt})\n            # Append a response to the chat\n            response = await openai_client.get().chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                messages=stream,\n                temperature=0.7, # increase to make the model more creative\n                )\n            model_response = response.choices[0].message.content\n            await chat.append_message(model_response)\n            #  if the model indicates game over, end game with a message.\n            if \"the end...\" in model_response.lower():\n                await chat.append_message(\n                    {\n                        \"role\": \"assistant\",\n                        \"content\": \"Game Over! Refresh to play again.\"\n                        })\n                exit()\n            else:\n                stream.append(\n                    {\"role\": \"assistant\", \"content\": model_response})\n\n\napp = App(ui=app_ui, server=server)\n\n\n1\n\nIn order to set a theme we import shinyswatch.\n\n2\n\nMarkdown or HTML that you pass to the chat interface will get rendered. This includes images, links and even emojis. In fact, one of the gpt-4o models I tested decided to respond with emojis.\n\n3\n\nPopping this one-liner in your UI will apply the theme styling to your application. Feel free to select any of the available options, see the interactive theme selector app below for all available themes.\n\n\nshinyswatch is a great utility that allows for efficient styling of python shiny apps. Check out this shinylive app from the package maintainers that allows you to easily toggle between the different themes available.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI use a real OpenAI API key in these clips to demonstrate the application working. Note that I have since revoked this key and it will no longer work. You should not share your secret keys with anyone.\n\n\nThe final app is demonstrated in full below.\n\n\n\n\n\nClick to return to the start of the iteration tabsets"
  },
  {
    "objectID": "blogs/18-jungle-quest-app.html#conclusion",
    "href": "blogs/18-jungle-quest-app.html#conclusion",
    "title": "Choose Your Own Adventure with ChatGPT",
    "section": "Conclusion",
    "text": "Conclusion\nFinally, we have arrived at the end of the application development! We started out with a basic little script that demonstrated how to use the openai python client and have arrived at a fully functional game with some additional safeguards against misuse. If you’ve stuck with it this far - well done, I’d say you’ve earned yourself a pat on the back!\n\n\n\n\nIf you’d like to continue improving the app, then here are some suggestions:\n\nPass more context to the moderations endpoint to minimise false positives.\nAdd a temperature control, so that the user can adjust how creative the models can be.\nAdd a model selection widget so that the user can try out responses with different openai models.\nExperiment with streaming the responses for a more responsive design.\nRestructure your app to make use of shiny modules, increasing the application’s maintainability.\n\nI hope you’ve enjoyed the tutorial and learned something new. If you’re able to riff off this with your own designs I would be really interested to take a look - please feel free to post links to your own creations in the comments at the end of the blog. If you’d like to consider how to share your app with others, take a look at my article on Deployment to Shinyapps.io.\nIf you spot an error with this article, or have a suggested improvement then feel free to leave a comment (GitHub login required) or raise an issue on GitHub.\n\nfin!"
  },
  {
    "objectID": "blogs/14-gh-actions-security.html",
    "href": "blogs/14-gh-actions-security.html",
    "title": "GitHub Actions Security",
    "section": "",
    "text": "An android locking a high security vault door."
  },
  {
    "objectID": "blogs/14-gh-actions-security.html#tldr",
    "href": "blogs/14-gh-actions-security.html#tldr",
    "title": "GitHub Actions Security",
    "section": "TL;DR",
    "text": "TL;DR\nIt’s more secure to reference GitHub Actions written by others by referring to the commit hash of the code than the version. Particularly if the action requires access to a secret credential. For example:\n\n\nupload-codecov.yml\n\nsteps:\n- uses: actions/checkout@main\n- uses: codecov/codecov-action@v4\n  with:\n    token: ${{ secrets.CODECOV_TOKEN }} # required\n\n…is more safely referenced like below:\n\n\nupload-codecov.yml\n\nsteps:\n- uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332 # sha for v4.1.7\n- uses: codecov/codecov-action@af2ee03a4e3e11499d866845a1e6c5a11f85cf4e # sha v4.5.0 \n  with:\n    token: ${{ secrets.CODECOV_TOKEN }} # required"
  },
  {
    "objectID": "blogs/14-gh-actions-security.html#background",
    "href": "blogs/14-gh-actions-security.html#background",
    "title": "GitHub Actions Security",
    "section": "Background",
    "text": "Background\n\nOpen source projects have been subject to a number of social engineering attacks recently.\nThis blog post describes risk in relying on GitHub Actions written by others."
  },
  {
    "objectID": "blogs/14-gh-actions-security.html#the-risk-in-plain-english",
    "href": "blogs/14-gh-actions-security.html#the-risk-in-plain-english",
    "title": "GitHub Actions Security",
    "section": "The Risk in Plain English",
    "text": "The Risk in Plain English\n\nDevelopers use GitHub Actions to conveniently automate various tasks. These Actions are often written and maintained by helpful members of the open-source community.\nSome of these Actions require access to secret credentials, for example to publish code to services in the cloud.\nMany of these Actions are widely adopted in the open source community, handling thousands of secrets every day. Developers consider the wide adoption of an Action when deciding whether to trust it.\nThere is a risk that bad actors could gain access to an Action’s code by placing pressure upon the package maintainers.\nOnce a bad actor has access to this code, they are able to adjust the code associated with the version reference, to do something nefarious, such as harvest secret credentials.\nUpdating workflow files to reference the Actions by commit hash guarantees that this code can be trusted to ‘do what it says on the tin’ in the future. Bad actors are unable to create new code that has the same commit reference code (known as SHA, short for Simple Hashing Algorithm)."
  },
  {
    "objectID": "blogs/14-gh-actions-security.html#updating-your-workflow-files",
    "href": "blogs/14-gh-actions-security.html#updating-your-workflow-files",
    "title": "GitHub Actions Security",
    "section": "Updating Your Workflow Files",
    "text": "Updating Your Workflow Files\n\n\n\n\n\n\nCaution\n\n\n\nThe layout of the GitHub user interface is liable to change.\n\n\n\nFind the Action that you wish to use on GitHub and click on its banner to navigate to the Action’s homepage.\n\n\n\n\nThe GitHub Actions marketplace\n\n\n\nEnsure that you have identified the correct Action by checking the author and the number of stars. Click on the link shown to navigate to the Action’s repository.\n\n\n\n\nThe Codecov Action homepage\n\n\n\nConsult the readme and releases section to identify the latest version of the Action. Ensure that the appropriate branch is selected from the branch selector widget.\n\n\n\n\nChecking the selected branch\n\n\n\nOnce you have selected the appropriate branch for the latest release, click on the commits section.\n\n\n\n\nClick on the commits\n\n\n\nFrom the list of commits, select the commit associated with the latest release and click the copy button to copy the full commit SHA reference to your clipboard.\n\n\n\n\nCopy the full commit sha\n\n\n\nReplace the version reference in your workflow file with your copied commit reference."
  },
  {
    "objectID": "blogs/14-gh-actions-security.html#likelihood-and-severity",
    "href": "blogs/14-gh-actions-security.html#likelihood-and-severity",
    "title": "GitHub Actions Security",
    "section": "Likelihood and Severity",
    "text": "Likelihood and Severity\nThe likelihood of this risk is debatable, but it is not zero.\nThe community of developers would likely pick up on such an event quickly and many of the targeted Action’s users would benefit from this awareness before any damage could be wrought. But why would you roll the dice? It may be equally possible that you and your colleagues may not realise this event has occurred before it was too late to intervene.\nThe severity of such an event would relate to the nature of the targeted Action. If said Action intercepted cloud service credentials, such as those required for deployment to GCP, AWS and the like, then the severity could be high. Whereas targeting widely used Actions such as the checkout Action would present differing severities for public or private repositories that use it.\nAs the effort needed to mitigate this risk is very small, I would encourage GitHub Actions users to consider updating all repositories that make use of such Actions for their continuous deployment workflows. In support of this suggested mitigation, here you can see that the well-known python package numpy have adopted this approach."
  },
  {
    "objectID": "blogs/14-gh-actions-security.html#acknowledgements",
    "href": "blogs/14-gh-actions-security.html#acknowledgements",
    "title": "GitHub Actions Security",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThanks to Mat for the conversation about recent bad actor efforts on various well-known open source repositories.\n\nfin!"
  },
  {
    "objectID": "blogs/04-starfield-resources.html",
    "href": "blogs/04-starfield-resources.html",
    "title": "Maximizing Loot Gains in Starfield: A Data-Driven Approach",
    "section": "",
    "text": "Image credit https://www.trustedreviews.com/\n\n\nIt’s been a while since I’ve dedicated to a Bethesda video game. The last would have been Fallout 3 in 2009-ish. Since then a lot has changed for me. Kids, a job in data science and a lot less time to absorb myself in RPGs. But with the hype around Bethesda’s Starfield, I once again find myself creeping abandoned outposts, stealing junk. This time, in space rather than a post-apocalyptic alternative Earth.\nEmbarking on a galactic scavenger hunt in the realms of Bethesda’s Starfield is akin to being a spacefaring treasure hunter. Imagine prowling through forsaken outposts, seeking riches beyond measure amidst the cosmos. The challenge, however, lies in discerning the true gems from the cosmic clutter.\nIn this whirlwind of interstellar looting, the pivotal question arises: What celestial junk is truly worth hoarding in this game?\n Aiming to hoard everything may seem like a stellar strategy, but alas, even the boundless void of space has its limits. An excess of loot can weigh you down, impeding your maneuvers through the cosmos. To strike the perfect balance, we need to delve deeper, beyond just mass and value. We need to calculate the ratio of these two values, unveiling the true worth of each celestial find.\n\n\n\n\n\n\nNote\n\n\n\nCalculating the credit per gram ratio unlocks the secrets to discerning the relative value of all available items."
  },
  {
    "objectID": "blogs/04-starfield-resources.html#unleashing-your-inner-space-scavenger",
    "href": "blogs/04-starfield-resources.html#unleashing-your-inner-space-scavenger",
    "title": "Maximizing Loot Gains in Starfield: A Data-Driven Approach",
    "section": "",
    "text": "Image credit https://www.trustedreviews.com/\n\n\nIt’s been a while since I’ve dedicated to a Bethesda video game. The last would have been Fallout 3 in 2009-ish. Since then a lot has changed for me. Kids, a job in data science and a lot less time to absorb myself in RPGs. But with the hype around Bethesda’s Starfield, I once again find myself creeping abandoned outposts, stealing junk. This time, in space rather than a post-apocalyptic alternative Earth.\nEmbarking on a galactic scavenger hunt in the realms of Bethesda’s Starfield is akin to being a spacefaring treasure hunter. Imagine prowling through forsaken outposts, seeking riches beyond measure amidst the cosmos. The challenge, however, lies in discerning the true gems from the cosmic clutter.\nIn this whirlwind of interstellar looting, the pivotal question arises: What celestial junk is truly worth hoarding in this game?\n Aiming to hoard everything may seem like a stellar strategy, but alas, even the boundless void of space has its limits. An excess of loot can weigh you down, impeding your maneuvers through the cosmos. To strike the perfect balance, we need to delve deeper, beyond just mass and value. We need to calculate the ratio of these two values, unveiling the true worth of each celestial find.\n\n\n\n\n\n\nNote\n\n\n\nCalculating the credit per gram ratio unlocks the secrets to discerning the relative value of all available items."
  },
  {
    "objectID": "blogs/04-starfield-resources.html#unveiling-the-cosmic-equation",
    "href": "blogs/04-starfield-resources.html#unveiling-the-cosmic-equation",
    "title": "Maximizing Loot Gains in Starfield: A Data-Driven Approach",
    "section": "Unveiling the Cosmic Equation",
    "text": "Unveiling the Cosmic Equation\nJoin me as we venture into the depths of Starfield’s resource catalogue. We’ll decipher the mysteries of mass, value, and rarity to pinpoint the celestial treasures worth their weight in gold—or rather, in galactic credits.\n\nGathering Data in the Digital Cosmos\nTo navigate this cosmic quest, we turn to the wealth of information readily available on Starfield’s resources. Numerous websites offer tables detailing these cosmic artifacts. For this article, I selected https://inara.cz/starfield/database/, a site that helpfully separates the various Starfield collectibles into meaningful categories.\nFor those curious about the code behind the scenes, check it out on GitHub  (GitHub account required)."
  },
  {
    "objectID": "blogs/04-starfield-resources.html#the-cosmic-riches-mass-value-and-rarity",
    "href": "blogs/04-starfield-resources.html#the-cosmic-riches-mass-value-and-rarity",
    "title": "Maximizing Loot Gains in Starfield: A Data-Driven Approach",
    "section": "The Cosmic Riches: Mass, Value, and Rarity",
    "text": "The Cosmic Riches: Mass, Value, and Rarity\nBelow, I plot the available resources’ masses and values, colouring by rarity. An ordinary least squares (OLS) trend line across all item rarities has been plotted in white. This is the line of best fit that minimises the residuals - the differences between the observed values and trend line.\nWhat does the line mean for selecting resources to loot? Any point above that line is worth collecting. Anything below that line would probably be worth ditching if something higher in value or lower in mass became available. Hover over the points to get the resource names.\nNote that several resources with zero value and mass were removed from the data during processing. I’m generally not interested in things without mass as they pose no dilemma to my encumbered pockets.\n\n\n\n\n\nInsights from the Celestial Scatter\nHere’s what we’ve discovered:\n\nRare and exotic items offer around average payoff.\nTwo standouts, Caelumite and Quark-Degenerate Tissues, are definitely worth collecting.\nExotic and Unique resources tend to be low mass, all being under 3 grams.\nMost uncommon resources don’t offer substantial returns, except for select options like Helium, Silver, and Benzene. These are the lower mass options in this rarity class.\nVac Grade Explosives, a common item, stands out as a valuable choice.\nThe rare class of resources generally promises better returns, with notable outliers like Veryl Explosive and Vytinium Fuel Rod.\n\nAs I have no data on the different likelihoods of discovering these items (rarity drop rates), I cannot comment on which items are best to target for farming. Though https://inara.cz/starfield/database/ does offer in-game locations where these resources may be found."
  },
  {
    "objectID": "blogs/04-starfield-resources.html#value-per-gram-the-cosmic-currency",
    "href": "blogs/04-starfield-resources.html#value-per-gram-the-cosmic-currency",
    "title": "Maximizing Loot Gains in Starfield: A Data-Driven Approach",
    "section": "Value Per Gram: The Cosmic Currency",
    "text": "Value Per Gram: The Cosmic Currency\nLet’s break down the data further, showcasing each resource’s value-to-mass ratio, measured in credits per gram. Unveil the best options to fill your cosmic coffers."
  },
  {
    "objectID": "blogs/04-starfield-resources.html#value-per-gram",
    "href": "blogs/04-starfield-resources.html#value-per-gram",
    "title": "Maximizing Loot Gains in Starfield: A Data-Driven Approach",
    "section": "Value Per Gram",
    "text": "Value Per Gram\nBelow I present the data for each resource in tabular format. The ratio column means value / mass, in credits per gram. The resources are sorted by descending ratio by default, but you can change that by clicking on the arrows in each column.\n\n\n\n\nKey Takeaways\n\nCaelumite and Quark-Degenerate Tissues are high outliers, reaffirming their status as top choices.\nSurprisingly, Vac Grade Explosive emerges as a standout, despite being categorized as common.\n\n\n\n\n\n\n\nNote\n\n\n\nFill your boots up with Vac Grade Explosive. Though think about taking out good life insurance, first.\n\n\nSorting the ratio column in ascending order reveals the poor choices of resources to collect. At least in terms of value per gram. Fiber, Water, Nutrient, all of these things sound so wholesome. Perhaps there are alternative reasons for hoarding such items, such as crafting or survival. It’s not all about becoming the richest spaceperson in the universe, right? \nBy plotting the density of value to mass ratio for each rarity class, an interesting picture emerges. For this chart, I have filtered out those 2 high-end unique outliers, otherwise the traces are a bit small and hard to see.\n\n\n\n\nSome observations\n\nExotic and Unique rarities show a bimodal distribution (2 peaks in value to mass ratio).\nThe other rarities exhibit trimodal distributions.\nCommon and Rare classes have a clear outlier (Vac Grade Explosive and Veryl Explosive). This game places a high value on blowing things up.\nRare resources display a wider distribution in value per gram, making it a good compromise in availability, mass and value."
  },
  {
    "objectID": "blogs/04-starfield-resources.html#thank-you-cosmic-voyagers",
    "href": "blogs/04-starfield-resources.html#thank-you-cosmic-voyagers",
    "title": "Maximizing Loot Gains in Starfield: A Data-Driven Approach",
    "section": "Thank You, Cosmic Voyagers",
    "text": "Thank You, Cosmic Voyagers\nBy deploying simple Python know-how, we’ve unraveled the secrets of the digital cosmos, empowering you to make informed choices. Your virtual pockets, now filled with strategic loot, pave the way to riches in your interstellar escapades.\nBefore we sign off, a massive thank you to https://inara.cz/ for graciously sharing their data, making this cosmic venture possible. And kudos to the Python libraries — requests, beautifulsoup4, plotly, and ridgeplot — for bringing this interstellar exploration to life.\nIn the vast cosmic expanse of Starfield, live long and prosper."
  },
  {
    "objectID": "blogs/03-quarto-github-actions.html",
    "href": "blogs/03-quarto-github-actions.html",
    "title": "How to Automate Quarto Builds with GitHub Actions",
    "section": "",
    "text": "You’re set up with a GitHub account.\nYou’re able to run git commands [1] from a command line interface (CLI).\nYou’ve installed quarto. [2]\nYou’ve a preferred text editor installed, eg Visual Studio Code, Atom or similar.\n\nThis guide is based on the useful quarto continuous integration (CI) documentation [3] and the examples provided within the Quarto CI GitHub repository [4]."
  },
  {
    "objectID": "blogs/03-quarto-github-actions.html#assumptions",
    "href": "blogs/03-quarto-github-actions.html#assumptions",
    "title": "How to Automate Quarto Builds with GitHub Actions",
    "section": "",
    "text": "You’re set up with a GitHub account.\nYou’re able to run git commands [1] from a command line interface (CLI).\nYou’ve installed quarto. [2]\nYou’ve a preferred text editor installed, eg Visual Studio Code, Atom or similar.\n\nThis guide is based on the useful quarto continuous integration (CI) documentation [3] and the examples provided within the Quarto CI GitHub repository [4]."
  },
  {
    "objectID": "blogs/03-quarto-github-actions.html#ci-for-quarto",
    "href": "blogs/03-quarto-github-actions.html#ci-for-quarto",
    "title": "How to Automate Quarto Builds with GitHub Actions",
    "section": "CI for Quarto",
    "text": "CI for Quarto\nThe repository used for setting up this example is available on GitHub.\nThe renderred site should look like this on GitHub Pages.\n\nIn the GitHub User Interface\n\nCreate a repository.\nCopy the clone url.\n\n\n\nIn the CLI\n\ncd to wherever you would like to keep your local clone.\ngit clone &lt;INSERT REPO URL&gt;\ncd &lt;INSERT REPO PATH&gt;\ntouch .github/workflows/publish-quarto.yml\ntouch index.qmd\ntouch .nojekyll\ntouch _quarto.yml\n\n\n\nIn the text editor\n\nCopy and paste the below into .github/workflows/publish-quarto.yml (you may need to enable viewing hidden files on your system - command + shift + . On macOS):\n\nname: Render and Publish\non:\n  push:\n    branches:\n      - main  # changes pushed to this branch will trigger a build.\n\njobs:\n  build-deploy:\n      runs-on: ubuntu-latest\n      permissions:\n        contents: write\n      steps:\n        - name: Check out repository\n          uses: actions/checkout@v3\n          \n        - name: Set up Quarto\n          uses: quarto-dev/quarto-actions/setup@v2\n          with:\n            version: 1.3.340\n\n        - name: Publish to GitHub Pages (and render)\n          uses: quarto-dev/quarto-actions/publish@v2\n          with:\n            target: gh-pages # renderred html files will be pushed here\n          env:\n            GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions\n\nCopy paste the below into the index.qmd, using your preferred text editor:\n\n---\ntitle: Hello Quarto CI\ndate: last-modified\nresources:\n  - .nojekyll\n---\nSetting up CI for quarto website build & publish.\n\nCopy paste the following into _quarto.yml:\n\nproject:\n  type: website\n  output-dir: docs\nexecute:\n  freeze: auto\nformat: html\n\n\nBack in the CLI\n\nAt the project root: quarto render. This will make a docs folder with your rendered website, a directory called index_files with more site dependencies and a .gitignore file. The only file needed to be committed is the .gitignore.\necho /docs/ &gt;&gt; .gitignore\necho /index_files/ &gt;&gt; .gitignore\ngit status should look like this:\n\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        .github/workflows/publish-quarto.yml\n        .gitignore\n        _quarto.yml\n        index.qmd\n\ngit add .\ngit commit -m \"Configure quarto\"\ngit push\n\n\n\nBack to the Web Browser\n\nIf the push was successful, navigate to your repository\nClick on the drop down arrow next to main branch\nClick on ‘view all branches’\nClick the ‘new branch’ button\nCreate the branch gh-pages\nClick on ‘settings’ in the top ribbon of the repo site\nClick on ‘Pages’ in the menu to the left\nCheck that your GitHub Pages is setup is Build and deployment &gt; Source &gt; Deploy from a branch\nCheck that the Branch setup is gh-pages /root\nAfter the CI has finished building, you can click on the url that appears at the top of this page under “GitHub Pages” to check that the site has been deployed properly. Copy the url of your GitHub Pages site.\n\n\n\nHead Back to your Local Repo\n\nInsert your url into your _quarto.yml, like below:\n\nproject:\n  type: website\n  output-dir: docs\nexecute:\n  freeze: auto\nformat: html\nwebsite:\n  site-url: \"&lt;YOUR_URL_HERE&gt;\" # makes site links work on your remote site"
  },
  {
    "objectID": "blogs/03-quarto-github-actions.html#creating-a-workflow-build-status-badge",
    "href": "blogs/03-quarto-github-actions.html#creating-a-workflow-build-status-badge",
    "title": "How to Automate Quarto Builds with GitHub Actions",
    "section": "Creating a Workflow Build Status Badge",
    "text": "Creating a Workflow Build Status Badge\n\nUse the following format to create a workflow build status badge in your readme: https://github.com/OWNER/REPOSITORY/actions/workflows/WORKFLOW-FILE/badge.svg\nFor example: https://github.com/r-leyshon/quarto-ci-example/actions/workflows/publish-quarto.yml/badge.svg\n\nFinally, embed the url in the src of a markdown image, like: ![example workflow](https://github.com/r-leyshon/quarto-ci-example/actions/workflows/publish-quarto.yml/badge.svg)\n\n\n\n\nexample workflow\n\n\n\nfin!"
  },
  {
    "objectID": "blogs/05-signed-commits.html",
    "href": "blogs/05-signed-commits.html",
    "title": "Set Up Signed Commits on GitHub",
    "section": "",
    "text": "GitHub verification badge."
  },
  {
    "objectID": "blogs/05-signed-commits.html#acknowledgement",
    "href": "blogs/05-signed-commits.html#acknowledgement",
    "title": "Set Up Signed Commits on GitHub",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThis article merely collates information from the following sources:\n\nAdding a GPG key to your GitHub account\nGenerating a new GPG key\nHow to understand the gpg failed to sign the data problem in git\n\nFor more information and troubleshooting, please visit these sources as they contain additional guidance which may be helpful for operating systems other than macos."
  },
  {
    "objectID": "blogs/05-signed-commits.html#the-scenario",
    "href": "blogs/05-signed-commits.html#the-scenario",
    "title": "Set Up Signed Commits on GitHub",
    "section": "The Scenario",
    "text": "The Scenario\nYou need to set up commit verification on your computer for the first time. Possibly you have changed computer and need to quickly set up once more. You are on macos  with access to the terminal."
  },
  {
    "objectID": "blogs/05-signed-commits.html#what-youll-need",
    "href": "blogs/05-signed-commits.html#what-youll-need",
    "title": "Set Up Signed Commits on GitHub",
    "section": "What you’ll need:",
    "text": "What you’ll need:\n\nmacos\nYour GitHub username\nThe Email address associated with your GitHub account\nAccess to the command line via Command Line Interface (CLI)\nA secure password wallet"
  },
  {
    "objectID": "blogs/05-signed-commits.html#instructions",
    "href": "blogs/05-signed-commits.html#instructions",
    "title": "Set Up Signed Commits on GitHub",
    "section": "Instructions",
    "text": "Instructions\n\nIn terminal, run:\n\n\n\nterminal\n\ngit config --global commit.gpgsign true\ngit config --global tag.gpgsign true\n\n\nVisit GPG suite and download the installer.\nFollow the installation steps and quit the screen that attempts to create a new key\nIn terminal, create a key with:\n\n\n\nterminal\n\ngpg --full-generate-key\n\n\nAt the prompt, accept the default values for key type, size and persistence\nEnsure you enter your real name, as it appears on GitHub, under your GitHub profile avatar. Use the primary Email associated with your GitHub account.\nEnter a passphrase, confirm it and store it in a secure password wallet. You will need it again in the final step of this process\nPrint out the long format of the key details with:\n\n\n\nterminal\n\ngpg --list-secret-keys --keyid-format=long\n\n\nCopy the long form of the key ID from the example output labelled as &lt;COPY THIS BIT ONLY&gt;, do not include the preceeding forward slash:\n\n$ gpg --list-secret-keys --keyid-format=long\n/Users/hubot/.gnupg/secring.gpg\n------------------------------------\nsec   XXXX/&lt;COPY THIS BIT ONLY&gt; 2023-10-23 \nuid                          your username\nssb   xxxXXXX/XXXXXXXXXXXXXXXX 2023-10-23\n\nAdjust this command with your copied key ID and run in terminal:\n\n\n\nterminal\n\ngit config --global user.signingkey &lt;INSERT YOUR KEY ID&gt;\n\n\nPaste your key ID into the command below and execute in terminal:\n\n\n\nterminal\n\ngpg --armor --export &lt;INSERT YOUR KEY ID&gt;\n\n\nCopy the output, including the -----BEGIN PGP PUBLIC KEY BLOCK----- and -----END PGP PUBLIC KEY BLOCK----- sections.\nGo to the GPG Keychain app, it should have detected the key in your clipboard and ask you to import the key to your keychain. Click OK\nOver to your web brower, go to GitHub  profile pic  settings  SSH and GPG keys\nAdd a new key to your account, give it an appropriate title and paste the key from your clipboard\nGitHub will ask you to authenticate in order to make this change\nNow ensure Git knows where to look for your GPG program:\n\n\n\nterminal\n\nwhere gpg\n\nCopy the path to the GPG program.\n\nUpdate the command below with the path in your clipboard:\n\n\n\nterminal\n\ngit config --global gpg.program \"&lt;INSERT/PATH/HERE&gt;\"\n\n\nCheck that your git config file looks as expected:\n\n\n\nterminal\n\ngit config --global --list \n\nExample output:\nuser.name=&lt;YOUR GITHUB USERNAME&gt;\nuser.email=&lt;YOUR PRIMARY GITHUB EMAIL&gt;\nuser.signingkey=&lt;YOUR GPG KEY ID&gt;\ncommit.gpgsign=true\ngpg.program=&lt;PATH TO YOUR GPG PROGRAM&gt;\ntag.gpgsign=true\n\n\nThe next time you need to commit, you will be asked to enter the passphrase you saved to your password wallet in order to add the key to your keychain"
  },
  {
    "objectID": "blogs/05-signed-commits.html#troubleshooting",
    "href": "blogs/05-signed-commits.html#troubleshooting",
    "title": "Set Up Signed Commits on GitHub",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\n\n\n\n\n\ngpg: signing failed: Inappropriate ioctl for device\n\n\n\n\n\nAdd the below to your initialisation file (eg ~/.zshrc or equivalent):\n\n\n~/.zshrc\n\nGPG_TTY=$(tty)\nexport GPG_TTY\n\nRestart your terminal. Try to commit once more. You’ll be asked for the GPG passphrase that you stored in your password wallet.\n\n\n\n\nfin!"
  },
  {
    "objectID": "blogs/17-quarto-comments.html",
    "href": "blogs/17-quarto-comments.html",
    "title": "Quarto Comments",
    "section": "",
    "text": "Speech bubbles with emojis."
  },
  {
    "objectID": "blogs/17-quarto-comments.html#introduction",
    "href": "blogs/17-quarto-comments.html#introduction",
    "title": "Quarto Comments",
    "section": "Introduction",
    "text": "Introduction\nFor people who use Quarto to build their websites, there are a few options for adding commenting functionality to their site. This allows your readers to engage with your site, leaving text or emoji feedback. Quarto currently offers built-in support for three commenting widgets. This article compares their functionality, linking to minimal implementations of each.\nFor full details on how to implement each solution, please consult the Quarto commenting documentation.\nThis article was written with Quarto 1.5.56. The solutions explored in this article are in development and may change in the future.\n\nIntended Audience\nProgrammers with a working knowledge of quarto websites, considering options for adding commenting features to their site.\n\n\nWhat You’ll Need\n\nQuarto CLI\nCommand line access"
  },
  {
    "objectID": "blogs/17-quarto-comments.html#hypothesis",
    "href": "blogs/17-quarto-comments.html#hypothesis",
    "title": "Quarto Comments",
    "section": "Hypothesis",
    "text": "Hypothesis\nHypothesis is a great new, feature-rich, social annotation solution. It has a strong commitment to open source. After exploring its main features, I would suggest it is aimed at a broad audience with strong features for academic audiences, particularly cohorts of students that will benefit from group analysis of documents.\nFor users to interact with the Hypothesis interface, they will need to create an account and login, though this is not a painful process and will prevent excess spam on your site. An example of a minimal quarto website with Hypothesis enabled is below - feel free to test the commenting features yourself. Click on the arrow in the top-right hand corner to expand the Hypothesis user interface (UI). Code for the site is available on GitHub.\n\n\n\n\n\n\n\nTable 1: Hypothesis Observations\n\n\n\n\n\n\n\n(a) Pros\n\n\n\n\n\n\n\n\nSimple setup, just include the Hypothesis portion in your site’s YAML & render.\n\n\nPrivate highlighting.\n\n\nPrivate notetaking if you create a private group. Other members can be invited to participate.\n\n\nToggle on/off highlights and comments separately.\n\n\nAnnotations - linked specifically to a region of text in the article.\n\n\nPage notes - applied to an entire page.\n\n\nAnnotations and page notes can be tagged with additional metadata.\n\n\nRevisions are easy and built into the UI.\n\n\nCollapsible UI is neat, reducing clutter.\n\n\nBrowser extension available.\n\n\nCompatible with sites deployed from other repo-hosting solutions, eg GitLab, BitBucket.\n\n\n\n\n\n\n\n\n\n\n\n(b) Cons\n\n\n\n\n\n\n\n\nI couldn’t get the embedding options to work (eg theme etc).\n\n\nNo emoji reactions."
  },
  {
    "objectID": "blogs/17-quarto-comments.html#utterances",
    "href": "blogs/17-quarto-comments.html#utterances",
    "title": "Quarto Comments",
    "section": "Utterances",
    "text": "Utterances\nUtterances uses GitHub Issues to store comment data. If you are deploying your site from GitHub and are not making good use of the repo issues, this could be a viable option. It’s important to note that your users will need a GitHub account and to authenticate in order to post comments on your site. Please consult the Utterances documentation for more information. In order to read and write issues on your repo, you do need to give the Utterances GitHub app permission to read and write repo metadata. Without doing this, the Utterances UI will appear on your site but will not function correctly. Code for A minimal Quarto site with Utterances is available on GitHub. The site can be viewed below.\n\n\n\n\n\n\n\nTable 2: Utterances Observations\n\n\n\n\n\n\n\n(a) Pros\n\n\n\n\n\n\n\n\nEither give it global access to all repos or selected repos.\n\n\nUser must sign into GitHub and authorise the Utterances app.\n\n\nMarkdown compatibility as per usual GitHub issues.\n\n\nFirst comment on a page creates an issue, subsequent comments are added to the same issue.\n\n\nReactions to comments with emojis.\n\n\n\n\n\n\n\n\n\n\n\n(b) Cons\n\n\n\n\n\n\n\n\nEvery comment creates a GitHub issue on the repo – 1 per page of your site. Maybe a bit noisy for some.\n\n\nMarking issues as closed does not remove them from the site.\n\n\nDeleting the issue from the repo will remove the comment but may also mess up the mapping of comments to pages. May cause issues moderating.\n\n\nCouldn’t get the labels feature to work, despite creating the issue label of the same name, as the documentation suggested.\n\n\nCannot respond to a comment with text.\n\n\nRevisions are possible though are not achievable through the website UI. By navigating to the repo issues, you can edit any comment that was authored by your account."
  },
  {
    "objectID": "blogs/17-quarto-comments.html#giscus",
    "href": "blogs/17-quarto-comments.html#giscus",
    "title": "Quarto Comments",
    "section": "Giscus",
    "text": "Giscus\nGiscus emulates the Utterances functionality, but by using the new(ish) GitHub Discussions feature as the comment database, instead of the repo issues. The Giscus documentation currently states the widget is in development, as well as the GitHub API that it relies on, so expect some changes with this solution. The Giscus documentation also provides a really useful tool that checks whether Giscus has been configured correctly on the target repo. This same tool was very useful in configuring the YAML metadata for my site correctly.\nIn the same way as Utterances, you will need to give the Giscus GitHub app permissions to read and write repo metadata. Users will also require a GitHub account in order to authenticate. Code for A minimal quarto site with Giscus is available on GitHub. The site can be viewed here (the Giscus interface will not render correctly within an iframe).\n\n\n\n\nTable 3: Giscus Observations\n\n\n\n\n\n\n\n(a) Pros\n\n\n\n\n\n\n\n\nActivate discussions on your repo or give it global access to all repos.\n\n\nUser must sign into GitHub and authorise the Giscus app.\n\n\nAllows emoji reactions to articles or comments on articles.\n\n\nAllows text responses to specific comments.\n\n\nMarkdown compatibility as per usual GitHub issues.\n\n\nFirst comment on a page creates a GitHub Discussion, subsequent comments are added to the same Discussion.\n\n\n\n\n\n\n\n\n\n\n\n(b) Cons\n\n\n\n\n\n\n\n\nLike Utterances, Giscus revisions are possible only through the GitHub UI. By navigating to the GitHub repo discussions tab, you can edit any post authored by your account.\n\n\nChanging configuration (e.g., mapping: pathname to mapping: URL) will cause old Giscus comments to be lost from your site. Though they are still available in the repo under the discussions tab."
  },
  {
    "objectID": "blogs/17-quarto-comments.html#summary",
    "href": "blogs/17-quarto-comments.html#summary",
    "title": "Quarto Comments",
    "section": "Summary",
    "text": "Summary\nOverall, I felt that Hypothesis offered the greatest functionality. However, it also presents a new service for your audience to subscribe to. If like me, your target audience consists mainly of programmers, then it is likely they will already have access to GitHub accounts and therefore one of the GitHub-specific solutions may present less of a barrier to your audience engaging with your content.\nComparing GitHub Utterances with Giscus, I considered the greater functionality and look of the Giscus UI to be just a little better than Utterances. Therefore I opted for this solution for this site, though I’ll keep it under review incase of breaking changes.\nIt’s great that the Quarto development team have implemented support for several commenting widgets. Although there are a great variety of alternative solutions available and implementing any of these solutions should be possible as quarto document metadata is fully customisable.\nIf you spot an error with this article, or have a suggested improvement then feel free to leave a comment (GitHub login required) or raise an issue on GitHub.\n\nfin!"
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#introduction",
    "href": "blogs/19-github-audit-trail.html#introduction",
    "title": "Commit with Clarity",
    "section": "Introduction",
    "text": "Introduction\nMost developers spend time reading other people’s code - for Pull Reviews (PRs) or to learn more about a software package, for example. Every so often, a developer may need to review an entire repository and possibly even its commit history. This can happen when publishing a mature codebase.\nMaking sense of other peoples’ commit histories can be challenging, especially if that work is exploratory. Understanding the myriad reasons for any single change after the fact is reliant upon whether the developer had time to document their reasons for their implementation. Even if you work alone, perhaps that other developer will be yourself at times. Needing to pick through your code’s commit history in order to find a bug-free version.\nThe good news is that there are a few tools that Git and GitHub can provide us, and one or two easy habits that will greatly assist your colleagues in comprehending your Git activity. In fact, the GitHub User Interface (UI) is designed in subtle ways, to nudge you towards some of these behaviours. The sort of things that are not required but are incredibly helpful to others - including your future self.\n\n\n Read on for more on how to be kind to yourself, and those poor souls who need to read your work - GitHub has your back.\n\n\n\n\n\n\nOpinions Ahead… (click to expand)\n\n\n\n\n\nEvery Git user has their own way of doing things. Many experts on the matter have diverging opinions on pretty much everything Git has to offer. In this article, I am offering a medley of advice from colleagues, trial, error and pain incurred. I’d bet that not all the advice here will chime with you.\nThis article will include a fair amount of opinion & appreciation for how GitHub helps promote considerate behaviours. You are most welcome to disagree and share your own opinions. There is a comments section at the bottom of the page to facilitate that.\n\n\n\n\nIntended Audience\nProgrammers who use GitHub to share code. The kind of Programmers who:\n\nmay not have used GitHub to collaborate in teams (previously me).\npride themselves on knowing ‘just enough Git to survive’ (me).\nhave been using GitHub for many years and wonder if their behaviours can be adjusted to be more helpful to others (future me)."
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#commit-messages",
    "href": "blogs/19-github-audit-trail.html#commit-messages",
    "title": "Commit with Clarity",
    "section": "Commit Messages",
    "text": "Commit Messages\nOne of the most ‘freeing’ style guide rules an organisation can institute are rules for what it considers to be good commit messages. Having enough rules to help take the pondering out of writing your message content will help get you back onto the development work quicker.\nHaving well-structured commit messages also helps others to quickly understand the types of changes that have been implemented in a pull request (PR). Some of my previous colleagues took the time to put together guidance on such matters.\n\n” &lt;type&gt;: &lt;subject&gt;\ntype\nMust be one of the following:\n\nfeat: A new feature\nfix: A bug fix\ndoc: Documentation only changes\nstyle: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc)\nrefactor: A code change that neither fixes a bug or adds a feature\nperf: A code change that improves performance\ntest: Adding missing tests\nchore: Changes to the build process or auxiliary tools and libraries such as documentation generation Do not capitalise the first letter.\n\nsubject\nThe subject contains succinct description of the change:\n\nuse the imperative, present tense: “Change” not “Changed” nor “Changes”\ndo capitalise first letter\nno dot (.) at the end”\n\n\nMany thanks to those Predeleagues (Predecessor Colleagues, my own portmanteau) who took the time to write that guidance.\nThis has been super useful for 99% of my commit messages that are one-liners. On the odd occasion I’ve felt a multi-line message was required, having the guidance for that written down has been a priceless time-saver. Using a commit type has also helped in moving backwards through the version history - helping my future self to target specific refactoring diffs or taking a rummage through a feature that introduced some newly discovered bug.\nConsidering the commit subject, I would subscribe to ONS Duck Book’s advice - aspire to short and informative messages."
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#link-prs-with-issues",
    "href": "blogs/19-github-audit-trail.html#link-prs-with-issues",
    "title": "Commit with Clarity",
    "section": "Link PRs with Issues",
    "text": "Link PRs with Issues\nTo those poor souls who have jobs that involve reading through commit logs - we salute you.\nOftentimes understanding the reason for a commit can become a mystery. Trying to understand the purpose of some contextless diff can become a real chore. By ensuring that each PR is linked with an issue (or issues), we can help provide the context needed to anyone who needs to pick through or pick apart our code.\nThe GitHub UI helps to nudge us in the right direction. Below I create a new issue in the repo for this blog:\n\n\n\nCreating an issue in GitHub\n\n\nNotice that there is an option on the right hand side, under Development to Create a branch for this issue. Click this and GitHub will create a branch with a naming convention that links the branch to the issue.\n\nOnce finished with the branch, we raise a PR. To link the PR with the issue, ensure to use one of GitHub’s keywords to automatically close the issue on merge. In this example, including the line Fixes #71 in a comment within the PR will link the issue. Several issues can be linked in this way, eg Fixes #71, Resolves #72 and so on. In this way, we have given an issue, branch and PR a clear identity."
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#consider-your-merge-strategy",
    "href": "blogs/19-github-audit-trail.html#consider-your-merge-strategy",
    "title": "Commit with Clarity",
    "section": "Consider Your Merge Strategy",
    "text": "Consider Your Merge Strategy\nWhen merging a PR in the GitHub UI, 3 options are presented:\n\nMerge commit (the default)\nSquash and merge\nRebase and merge\n\nThese options are a little involved and I would recommend reading GitHub’s merge docs on the matter for a more detailed breakdown.\nTo help visualise the differences in these approaches, consider the following diagram:\n\n\n\nSource: matt-rickard.com\n\n\nIn the following scenarios, I will walk through commit history following the three different merges. In all examples, I will refer to the target branch receiving the commits as main and the topic branch containing the additions as feature.\n\nRebase Merge\nWhen a rebase merge is used, new commits that mirror those in feature branch are created in main. You keep every commit and maintain a linear commit history. In the diagram below, I compare commits in a repo with an example rebase merge. Note that there are 2 commits from feature branch with commit messages like “FEATURE: …”. Merging the PR creates new commits to main, which have all the file edits from feature. However, note that these new commits have different hashes to those in feature.\n\n\n\nComparing main and feature following rebase merge. Click to enlarge.\n\n\n\n\nSquash and Merge\nOn selecting “Squash and merge” in the GitHub UI, A new “summary commit” is created in main. This condenses all of the file changes from feature into a single, new commit. You can see that even in the trivial example squash merge repository, the outcome is that main branch will be much more succinct than in the other merge strategies.\n\n\n\nComparing main and feature following a squash merge. Click to enlarge.\n\n\nInspecting the automated squash merge commit message demonstrates how GitHub summarises the activity from feature branch.\n\n\n\nSquash commit generated commit message.\n\n\nThe squash merge strategy is a good candidate for busy projects with many contributors. It’s also a neat way to avoid noise in your version history, such as experimental ‘cruft’ or benign changes that you’d rather summarise. It is important to note that once merged to main, you should go ahead and delete the feature branch. If you continue to work in feature, there is a likelihood of diverging with main, ending up in merge conflicts to resolve.\n\n\nMerge Commit\nFinally, we consider the default merge behaviour - the merge commit. This behaviour will create a new commit in main that introduces the changes in feature. Notice that in this scenario, the commits in main and feature share the same content and commit hashes, as opposed to a rebase merge which “pretends” those commits happened in main.\n\n\n\nComparing main and feature following a merge commit. Click to enlarge.\n\n\nThis is perhaps the noisiest merge strategy, as the commits of each feature branch are all merged to main, plus an additional commit that marks the merge. Use this scenario if you consider it really important to be able to revisit the commit history.\n\n\nOverview of Merge Strategies\n\n\n\n\n\n\n\n\n\n\nMerge Type\nWhat Happens\nHow It Looks\nBest For\nDownside\n\n\n\n\nMerge Commit\nA new commit is created to merge the PR, keeping all individual commits intact.\nA merge commit is added, and you can see all the individual commits from the PR.\nKeeping a detailed history with all commits preserved.\nCan clutter the commit history with many small or trivial commits.\n\n\nSquash and Merge\nAll commits in the PR are combined into one single commit before merging.\nOnly one commit appears in the history, representing all changes from the PR.\nKeeping the commit history clean and concise.\nLoses the individual commit details from the PR.\n\n\nRebase and Merge\nThe commits from the PR are applied directly on top of the main branch, maintaining their original structure but without a merge commit.\nThe history looks linear, with the PR commits applied after the latest main branch commit, with no merge commit in between.\nKeeping a linear, clean commit history without merge commits.\nCan be tricky with conflicts, especially for complex histories.\n\n\n\n\n\nSelecting a Merge Strategy\nUnderstanding which strategy is for the best depends on the context in which you’re working. Your 2 options for maintaining a full commit history are either merge commit or rebase and merge. If you would rather summarise the commit history, then squash commit is the right approach. If I’m working on a solo project, I tend to merge commit. If I’m working in a team, I tend to squash commit in order to keep the version history manageable.\nSome people bemoan the squash commit approach, with 2 main complaints that I’ve encountered:\n\nThe full commit history is not preserved.\nIt decreases contributors’ apparent GitHub activity.\n\nMy responses follow:\n\nDeleted branches can be restored.\nGitHub activity is a poor proxy for impact.\n\nAdmittedly, the squash merge approach works best for projects where there is a disciplined approach to PRs. If PRs represent a tangible unit of work, such as a bug is fixed or a new feature is implemented, then squash merge works really well in my experience. Individual branches are short-lived and the risk of merge conflicts are minimised.\nHowever, some projects are not like that. Particularly in exploratory work where some PRs become sprawling, long-lived with diffs numbering tens-of-thousands of lines. It may be advisable to merge commit in those scenarios. Personally, I never rebase when working with others."
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#organising-issues",
    "href": "blogs/19-github-audit-trail.html#organising-issues",
    "title": "Commit with Clarity",
    "section": "Organising Issues",
    "text": "Organising Issues\nIssues provide the context for PRs. Understanding why a PR is necessary is very helpful to collaborators and will be appreciated by anyone who needs to look back over your version history.\nA feature that I consider to be under-utilised in GitHub are milestones. The milestone feature allows you to group related work, such as grouping issues and PRs with an epic. These milestones can then be added to GitHub projects to coordinate burn-down effort. Find the milestones interface under the issues tab.\n\n\n\nGitHub Milestone interface. Click to expand.\n\n\nAdding this sort of structure can be great in helping collaborators understand where your work fits into more tangible delivery, and your product managers will thank you for it. Below I show how with a few clicks, the milestone can be used to create an informative delivery roadmap.\n\n\n\nMilestone on a GitHub roadmap. Click to expand.\n\n\nYou can see in the project that I have grouped the issues by milestone on the left hand-side. Also, by adding the milestone to the date fields, you get the blue date line appearing on the roadmap to the right of the screen.\nRecently, GitHub has unveiled some significant changes to its issues. The nested issues feature adds even more flexibility in grouping units of work together. This feature is in public beta at time of writing. Join the waitlist here."
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#tips-for-auditing",
    "href": "blogs/19-github-audit-trail.html#tips-for-auditing",
    "title": "Commit with Clarity",
    "section": "Tips for Auditing",
    "text": "Tips for Auditing\nIf you are tasked with making sense of someone else’s code for PR or commit history for a release, then there are a few tools & tricks that can help make your life a bit easier. I’ll cover some of them here.\n\nAssign BLAME\n\n“It is ill to praise, and worse to blame, the thing which you do not understand.” Leonardo da Vinci, “Life, art and science, the thoughts of Leonardo”, p.67, 2013, Lulu.com\n\nAt times, it may be useful to identify the person who wrote some code. It’s not completely obvious, but by viewing a file and toggling from Preview to Blame, you get a line-by-line view of who commited what and when.\n\n\n\nGitHub blame view. Click to expand.\n\n\nNote that there are also handy tools such as GitLens for VSCode that can bring the Git blame into your IDE.\n\n\nGrep FTW\nIf you need to check all occurrences of a specific pattern anywhere within a repository, there’s a great little tool called git grep that will help. In an interactive terminal, run git grep &lt;INSERT_PATTERN&gt; and all occurrences of that pattern within any file contents will be returned. If the pattern has spaces, just wrap the pattern in speech marks.\nIf there are loads of files and you want to search for a pattern in the filenames, then use:\ngit ls-files | grep &lt;INSERT_PATTERN&gt;\nIf you’d like to search for specific patterns in commit messages:\ngit log --grep=&lt;INSERT_PATTERN&gt;\nIf you need to scan an entire commit history for the presence of a pattern in the contents of the files, then this is achieved with\ngit log -G &lt;INSERT_PATTERN&gt;\nThat pattern takes regular expressions so it can be quite flexible in combination with wildcards. This is super useful if you need to check whether a specific secret was ever added to the commit history.\n\n\nGitHub & VSCode\nThe previous tip is a feature of Git rather than GitHub. In order to execute the commands, you’ll need a Command Line Interface and a local clone of the repository. That might not always be convenient. Did you know that since the low(ish) key Microsoft takeover of GitHub, you can now access VSCode directly from the GitHub UI?\nBy simply typing . (full stop or period, depending on what side of the Atlantic you learned English) you will open your repository within VSCode directly within your browser window. If you’d prefer to open VSCode in a new browser window, type &gt; instead. This interface is handy for adding in new files or adjusting the content of existing files.\nIf you’d like an interactive terminal, or to test out code, you’ll need to switch over to GitHub Codespaces. Again, this is a free service that GitHub provide that provisions some compute for you. To launch a ‘live’ version of VSCode in your browser, click on the burger icon in in the ribbon to the left, then Terminal -&gt; New Terminal. You will be presented with options in the terminal asking you to launch GitHub Codespaces or to continue in a local clone of the repo.\n\n\n\nLaunching Codespaces. Click to expand.\n\n\nOnce Codespaces is launched, you have an interactive terminal to carry out your favourite operations. Here I’m displaying the git grep command in my browser with Codespaces.\n\n\n\nRunning terminal operations with Codespaces. Click to expand."
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#summary",
    "href": "blogs/19-github-audit-trail.html#summary",
    "title": "Commit with Clarity",
    "section": "Summary",
    "text": "Summary\nIn this article we covered considerate Git practice and how GitHub helps to nudge us toward these behaviours. Specifically:\n\nCommit Messages: The value of having well-structured commit messages.\nLinking PRs with Issues: Providing necessary context for reviewers.\nMerge Strategies: Advantages and disadvantages of the options GitHub provides in their UI.\nOrganising Issues: Using milestones to group related work, enhancing coordination in projects.\nTips for Auditing: Tools and techniques for inspecting a commit history, including the use of Git blame and grep commands.\nGitHub & VSCode Integration: Describes how to access VSCode directly from GitHub for streamlined code management.\n\nPlease feel free to share your own thoughts and ideas in the comment section below (GitHub login required)! If you spot an error with this article, or have a suggested improvement then feel free to raise an issue on GitHub."
  },
  {
    "objectID": "blogs/19-github-audit-trail.html#acknowledgements",
    "href": "blogs/19-github-audit-trail.html#acknowledgements",
    "title": "Commit with Clarity",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo past and present colleagues who have helped to discuss pros and cons, establishing practice and firming-up some opinions. Particularly:\n\nIan\nRob\nAdrian\nDan Shiffman\n\n\nfin!"
  },
  {
    "objectID": "book-reviews/01-deep-work.html",
    "href": "book-reviews/01-deep-work.html",
    "title": "Deep Work",
    "section": "",
    "text": "Fanal Forest, Madeira. Wikimedia Creative Commons."
  },
  {
    "objectID": "book-reviews/01-deep-work.html#introduction",
    "href": "book-reviews/01-deep-work.html#introduction",
    "title": "Deep Work",
    "section": "Introduction",
    "text": "Introduction\nAt the date of writing this review, Deep Work scores an average of 4.19 / 5.00 across over 141k ratings on goodreads. Also nominated by the same website for Best Nonfiction, 2016. Awarded gongs for best book and best seller in business & leadership by Amazon & the Wall Street Journal.\nThis book was recommended to me by a close colleague and I read it on holidays during some much-needed downtime in the Summer of 2023. I should note that I reflect on the relevance of the advice in this book to my own personal circumstances. To that end, it is worth noting that I currently work as a senior data scientist and that I happen to face many competing priorities in my day-to-day job.\nCal Newport is a celebrated author within the field of personal productivity. According to his website, Newport is an MIT Grad in Computer Science and a professor at Georgetown University [1]."
  },
  {
    "objectID": "book-reviews/01-deep-work.html#an-overview-of-the-book",
    "href": "book-reviews/01-deep-work.html#an-overview-of-the-book",
    "title": "Deep Work",
    "section": "An Overview of the Book",
    "text": "An Overview of the Book\nDeep Work is structured in 2 parts:\n\nPart 1: The Idea\nHere the author sets out his stall, establishing definitions of fundamental concepts, such as deep and shallow work and their relative value to the author’s definition of what he refers to as the ‘knowledge worker’. The author sets out noteworthy examples of individuals who (have) had a proven ability to establish deep thought throughout their illustrious careers. The author then sets out the case for why deep work is a rewarding endeavor and how its antithesis of a connected and responsive workday offers little benefit to the individual, the organisation or society. Yet , many modern organisations have unwittingly promoted and even entrenched a shallow work culture among their employees.\n\n\nPart 2: The Rules\nIn this section, the author offers suggested interventions to make within your workplace. Exemplifying strategies with personal experience and from those around him, Newport assists the reader in visualising a professional future where they can rule their schedule, rather than the reverse.\n\n\n\n\n\n\nNote\n\n\n\n“… remain unresponsive to the pinprick onslaught of small obligations that seem harmless in isolation but aggregate to serious injury to his deep work habit.” [2, p. 142]\n\n\nThe author identifies potential sticking points and attempts to treat them, offering suggested strategies for securing the support of colleagues, stakeholders and managers in the reader’s pursuit of deep work. Moderating his message, Newport offers words of advice against the pursuit of deep work to the exclusion of everything else, yet establishing set constraints within a schedule where shallow tasks and administrative commitments are not permitted to undo your daily objectives."
  },
  {
    "objectID": "book-reviews/01-deep-work.html#analysis-and-evaluation",
    "href": "book-reviews/01-deep-work.html#analysis-and-evaluation",
    "title": "Deep Work",
    "section": "Analysis and Evaluation",
    "text": "Analysis and Evaluation\nMuch of the content in this book resonated with me. Newport takes a contrarian view of many modern professional practices, such as structuring your day around group ceremonies like stand ups or scrums, maintaining open channels of communication via Email and instant messaging applications, and as mentioned above, social media channels. Many I.T. professionals will find their progress hampered by a menagerie of ceremonies, administrative tasks and meetings of ambiguous impact. Understanding how to categorise such meetings and structure your day around your deep work goals is what Newport hopes to espouse. This has been a consistent feature of my data-related roles throughout my career. Striking that balance of engaging with stakeholders versus undertaking the work can all too often result in a fractured day with little developmental progress.\nThat’s not to say that Newport promotes a hermetic approach to work. It’s clear to most that the tool, statistic or analysis that is being developed can only be effective if it is useful. Newport states that these ‘shallow’ tasks should be kept in check. They should be minimised and must earn your attention. Placing a premium on your time and attention is at the core of the book’s message.\n\n\n\n\n\n\nNote\n\n\n\n“…for decisions that involve large amounts of information and multiple vague, and perhaps even conflicting restraints, your unconscious mind is well suited to tackle the issue.” [2, p. 145]\n\n\n\nAbove, Newport summarises a high level takeaway from unconscious thought theory (UTT), which may present a theoretical basis for sleeping on a particularly challenging problem.\n\nA lot of what Newport writes has rung true in my experience. While not all jobs have the same requirements, my roles in data have all required a deep focus disposition. In fact, some of the strategies that the author suggests for optimising your day, I had independently arrived at. Approaches such as starting your day before the rest of the office has woken up and keeping Email responses process-related have both served me well in my career progression so far. But, there are some suggested strategies that I have not quite been convinced of. At one point, Newport discusses cognitive strategies for extending your capacity for deep concentration. The suggested approach is to remember the order of a shuffled deck of cards. Newport outlines a method for doing so and cites some studies that are indicative of the positive relationship between such activities and the mental fortitude required for deep focus. Personally, I would sacrifice too much time in achieving such a feat, whereas I would gain more by implementing the task at hand, gradually incrementing my exposure to deep concentration sessions. Newport does state that this sort of thinking misses the point entirely, and that investing effort in such a mental feat pays dividends in the longer term, though I have yet to be convinced of this claim.\n\n\n\n\n\n\nNote\n\n\n\n“…attention restoration theory (ART), which claims that spending time in nature can improve your ability to concentrate. This theory… is based on the concept of attention fatigue. To concentrate requires what ART calls directed attention. This resource is finite: If you exhaust it, you’ll struggle to concentrate.” [2, p. 147]\n\n\n\nI found this concept to be very interesting, and a little concerning. Managing burnout is something that I value. It seems that my pasttimes also require directed attention, and that perhaps I should pursue recreational activities that contrast with my professional interests. I have decided to note within my journal when I notice that I am lacking energy and to resolve to take a bike ride, swim or just a walk in order to efefctively disconnect and recharge.\n\nAt times throughout the book, I did find myself reflecting that some of the claims or advice were not as generalisable as the author had perceived. At one point for example, the Newport suggests diagnosing whether your workplace can support a culture of deep concentration and finding alternative employment if the answer was a clear enough ‘no’. This did strike me as something that many colleagues could only dream of, with the reality of bills to pay, children to feed and job security in an uncertain sector. Advising people to leave rather than finding alternative strategies to influence managerial culture does seem a bit thoughtless.\n\n\n\n\n\n\nNote\n\n\n\n“Professional E-mail Sorting: Do not reply to an e-mail message if any of the following applies:\n\nIt’s ambiguous or otherwise makes it hard for you to generate a reasonable response.\nIt’s not a question or proposal that interests you.\nNothing really good would happen if you did respond and nothing really bad would happen if you didn’t.” [2, p. 255]\n\n\n\n\nI find this advice to be a bit myopic. This is likely great advice for an accomplished academic with a strong internal locus of control. Junior entrants to a profession typically need to prove their utility to those with greater power around them - the decision makers that could be on their next promotion panel. Ignoring Emails that are a bit ambiguous could result in passing up an oportunity to help a colleague, forge a new professional relationship or prove your worth in the workplace. Rather than approaching the needs of others with derision, I would instead advise time-boxing a response and communicating your needs clearly to the other party. Something like - ‘I’m a bit pushed for time right now and am not familiar with the context, but if you can point me to a briefing note I can get back to you on Monday, once I’ve cleared off my backlog’.\n\nAnother feature of this book which that requires some scepticism is in the outcomes of studies used to underpin the attitudes and strategies promoted as good practice. It’s likely no news to you that the behavioural sciences has attracted a fair amount of criticism about the reproducibility of published findings over the last decade. Coupled with the widespread publication bias encountered in academic journals [3] and confirmation bias abound in the field of psychology, I would suggest the author reveal some of the research that they have undertaken in validating the claims of the studies. It is unlikely that the average reader will have the necessary time to carry out their own investigation of the findings, and doubt in the ability to evidence some of the claims within the book is introduced. I do not wish to sound like I am criticising the author for choosing studies that help to evidence their claims, as I would have criticised them for not doing so had that been the case. I would ask that the author publishes their attempts to prove the hypotheses considered.\n\n“Don’t trust everything you read in the psychology literature. In fact, two thirds of it should probably be distrusted.” [4]"
  },
  {
    "objectID": "book-reviews/01-deep-work.html#comparisons",
    "href": "book-reviews/01-deep-work.html#comparisons",
    "title": "Deep Work",
    "section": "Comparisons",
    "text": "Comparisons\nThere are some obvious comparisons with other productivity self-help books. One of the most obvious is in Stephen Covey’s The 7 Habits of Highly Effective People [5]. Both books make an effort to discuss the management of competing priorities and how to go about organising your working day around prioritised, impactful goals. Covey’s book dedicates more energy towards effectively triaging tasks and charting progress made against longer-term priorities than what is explored within Deep Work. In fact, this may be another presumption made by Newport - that the direction of progress is obvious to the reader and it is simply a matter of finding the undisturbed time to do the work. As many of us will encounter uncertainty and a fair amount of strategic thrashing in our working lives, this could prove to be a limiting assumption.\nBelow is an example of what is commonly referred to as a “Covey Quadrant”, a rubric for efficiently categorising tasks along dimensions of urgency and importance."
  },
  {
    "objectID": "book-reviews/01-deep-work.html#recommendation",
    "href": "book-reviews/01-deep-work.html#recommendation",
    "title": "Deep Work",
    "section": "Recommendation",
    "text": "Recommendation\nThere is a lot of wisdom to be gleaned from this book. Sure, some of it may be anecdotal and won’t be true in all cases. But there is an undeniable pattern in the examples provided, that sustained effort yields desirable outcomes. This is something that I have always found to be true and connects with my wider values. It is this message and the useful reminders and strategies that would form the basis of my recommendation for this book. This book is an opportunity to gain insight into how the elite of the achievers in society get things done. You may be able to make some of this work for you but don’t expect it to be easy, or perhaps even achievable in your current situation.\nTo put it bluntly, if you have ever struggled to quiet the noise at work and get things done, then this book is for you. (It’s not lost on me that that may qualify pretty much everyone who has ever worked in an office)."
  },
  {
    "objectID": "book-reviews/03-amusing-ourselves-to-death.html",
    "href": "book-reviews/03-amusing-ourselves-to-death.html",
    "title": "Amusing Ourselves to Death",
    "section": "",
    "text": "Image credit: https://api.ndla.no/"
  },
  {
    "objectID": "book-reviews/03-amusing-ourselves-to-death.html#summary",
    "href": "book-reviews/03-amusing-ourselves-to-death.html#summary",
    "title": "Amusing Ourselves to Death",
    "section": "Summary",
    "text": "Summary\nAs of today’s date, Amusing Ourselves to Death (AOtD) scores an average of 4.15 / 5.00 over 29.5k ratings on goodreads.\nAOtD is a challenging read for a short book. It is heaped in cultural criticism and a pessimistic assessment of technological development. I would not recommend readily internalising the content without thoughtful evaluation. However, much of the critique is well-reasoned and although written in the 1980s, is possibly of greater relevance today than when first penned.\n\nOn the Author\nNeil Postman was a professor of communication at New York University. Well-known for his body of work in examining the study of knowledge-acquisition and pedagogy through the lens of societal decline. Postman endeavoured to influence public education curricula in the United States during his term as Chairman of the University’s Department for Culture and Communication."
  },
  {
    "objectID": "book-reviews/03-amusing-ourselves-to-death.html#an-overview-of-the-book",
    "href": "book-reviews/03-amusing-ourselves-to-death.html#an-overview-of-the-book",
    "title": "Amusing Ourselves to Death",
    "section": "An Overview of the Book",
    "text": "An Overview of the Book\nPostman’s critique is that the widespread adoption of television has subversively influenced culture, human behaviour and intellect in ways that could not be foreseen at the technology’s inception. Unaware of the broad repercussions of immersing ourselves in TV pop culture, the standards for entertainment in this medium of communication have permeated through society, from the boardroom to the classroom.\nPostman warns that American culture; seemingly unaware of how trivial and distracted it has become; is at risk of losing its moral compass. The main premise of his warning is that rather than an Orwellian dystopian future where society is controlled by a despotic surveillance state, a more realistic outcome would be characterised by Aldous Huxley’s Brave New World [1]. A future where a simpleton proletariat has been rendered ineffective by the pursuit of hedonism at the cost of all else.\nThe book is organised into 2 parts and 11 chapters. Part 1 establishes the scale of the apparent decline in literacy, logic and debate brought about by the decline of a largely print-based culture. Part 2 argues that aspects of TV as a medium impose limitations on the length of exposition and complexity of language that have widely influenced our lives. Postman exemplifies how this simplification of our public discourse has declined, with considerations from many domains.\n\nPart 1\nThe book begins with a treatment of Huxley’s warning in Brave New World. A future in which civilisation is threatened by an over-supply of information and a reduction of the peoples’ ability to identify that which has meaning. Postman suggests that Western culture had been en guarde for signs of Orwellian oppression but has not adopted a defence against the possibility that we may be oppressed by our own ignorance.\n\n1. The Medium Is the Metaphor\nPostman argues that the technological revolution brought about by mass adoption of television has unwittingly changed the fabric of our society. Using the analogy of the clock, Postman indicates that the mechanism is not merely a device used for measuring time, but that it “dissociates time from human events and thus nourishes the belief in an independent world of mathematically measurable sequences.” [2, p. 12].\nThis analogy does not help someone who is subject to the belief of quantifiable sequence in understanding his point. The thought of a world without clocks is an unimaginable dystopia. The positives that the clock has wrought greatly outweigh any possible drawbacks that I can conceive of. This may be the point entirely - just as the fish is likely unaware that it lives within water, the ability of the human mind to conceive of how it has been influenced by a technology that has been fully integrated through society may be similarly limited.\nPostman goes on to state that the clock has removed the concept of god from the meaning of time. Unable to place a god as the cause of time, I am lost as to how to meaningfully rationalise his analogy. I surmise that Postman’s point is that as a consequence of reducing the concept of time to the machinations of gears, removes any sense of reverence or magical thought. Although some would argue that the internals of an analogue clock are a thing of beauty and the trade of the watchmaker an art. Nonetheless, the reduction of time to a gadget now worn on the wrist may have effects beyond a greater ability to manage time, possibly influencing our perception of our place in the universe. The comparison with television’s replacement of print seems to mean that there are unintended consequences owing to the adoption of a novel technology that are perhaps poorly understood. In my opinion, this is a weak analogy, lacking in consequence. I don’t believe it helps the reader orient to Postman’s main point. The negative consequences of the clock; whatever they may be; must now be broadly accepted as part of human existence.\n\n\n2. Media as Epistemology\nIn this chapter, Postman considers the nature of truth, the acquisition of knowledge and how this has changed with the cultural trend toward visual media. The author posits the concept that all media are not equal in their ability to convey meaning and truth.\nAn interesting juxtaposition is explored - that in certain circumstances, the medium of spoken word is thought to be of higher merit than the written, such as in most modern courtrooms where verbal rather than written testimony is required. However, Postman is able to draw on his experience in academia to illustrate that the reverse is true in the assessment of a thesis, where a candidate had attempted to cite ephemeral evidence; a conversation or interview with an academic. In this example the result had been a witty retort from the review panel,\n“…we are sure you would prefer that this commission produce a written statement that you have passed your examination (should you do so) than for us merely to tell you that you have, and leave it at that. Our written statement would represent the”truth”. Our oral agreement would be only a rumour.” [2, p. 24].\nWho could argue with that? The contrast between written assessment and courtroom testimony’s truth value glazes over the context and purposes of these discourse formats. The courtroom favours verbal testimony as an unadulterated recount of the past and motive, yet quickly commits this testimony to the written word via courtroom stenographers. A raw, unfiltered account for a thesis would only serve as a draft and would require significant editing in order to test that the structure and content of the paper is robust.\nPostman goes on to examine truth as a cultural prejudice for certain media. From tribal counsel’s use of parables through Aristotle’s deductive reasoning about the physical world, Postman finally rounds to the modern world’s adherence to the quantifiable.\n“Many of our psychologists, sociologists, economists… will have numbers to tell them the truth or they will have nothing. Can you imagine, for example, a modern economist articulating truths about our standard of living by reciting a poem?” [2, p. 26]\nI wonder if numbers can be considered a medium. It occurs to me that numbers are a language that can be expressed in a variety of media. Postman could have explored instead the danger of an over-reliance on statistics as truth. The fact that statistics can be selectively deployed to make opposing arguments is of course, not a new one.\n\n\n\n\n\n\nNote\n\n\n\n“Lies, damned lies, and statistics.” attribution debated.\n\n\nThe use of numbers to oversimplify, diminish context and misdirect can also be a misuse of data visualisation. On the nature of bias in the chart,\n“…it makes the viewer believe that they can see everything, all at once, from an imaginary and impossible standpoint. But it’s also a trick because what appears to be everything, and what appears to be neutral, is always … a partial perspective.” [3, Ch. 3].\nAll of us must be guilty of accepting a viewpoint based on the convincing support of charts or numbers, without undertaking the necessary due diligence of reproducing the analysis and seriously examining the assumptions and potential underlying biases. The complexity of society and the volume of analysis we generate make it impossible not to do so. The presumption is that those people charged with the responsibility of evidence-based policy design are carrying out the due diligence on behalf of us all.\n\n\n3. Typographic America\nThe author uses this chapter to familiarise the reader with an abridged history of literacy from 17th century England and the United States through to modern day America. Thanks primarily to the efforts of the churches, literacy among the general populace was understood to have been significantly higher than in the modern day populace. But with a decline in the relevance of the printed word, literacy rates have steadily declined over the previous century.\n17th century people were conditioned to spend long hours of leisure time focussed upon reading a single book. This mental fortitude affected their ability and predilection for other feats of mental endurance. Debating halls were common across the country and accounts of debates extending long into the evenings were said to be common. The contrast between these discussions and the modern approach to televised debates must be striking. It is here that I have little to argue with Postman’s position. It is undoubtedly true that television does nothing to prepare viewers for bouts of prolonged concentration. If a topic cannot be reduced to chunks of ten second sound bites, it generally makes for poor television.\nWhile television is an enjoyable entertainment device, the demands of its format aim to keep the viewer perpetually stimulated and do not imbue its audience with mental fortitude. Postman’s position is that this lack of mental preparation against boredom leaves us struggling to achieve focus in many other contexts. These known limitations of television have given rise to the podcast in recent years, where a type of long format debate has returned to public fora.\n\n\n4. The Typographic Mind\nIn this chapter the author explores how a sustained media shift away from the printed word may have influenced our assessment of culture’s interpretation of truth. The author compares the image-obsessed standards of the televised news shows to a form of infantilism. Where assessment of truth is based upon the appearance of the newscaster rather than the content of the televised message. An industry-wide ad hominem has permeated through even those shows that are intended to be sober and informative. Postman suggests that the form of truth and intelligence valued by ‘the typographic’ mind (pre-television) would have been markedly different.\nAn interesting point is made about an unspoken contract between television and those appearing on it. The author argues that the dominant media in our society governs the behaviours of those wishing to exploit that as a tool. Politicians, scholars and religious figures are reduced to a fickle celebrity by the demands of a television presence - curate your image, reduce your campaign to sound bites, prioritise speed over reason. In considering the first 15 presidents of the United States, Postman states,\n“Public figures were known largely by their written words, for example, not by their looks or even their oratory… To think about those men was to think about what they had written, to judge them by their public positions, their arguments, their knowledge as codified in the printed word.” [2, p. 70].\nRecalling any of the notable icons of the twentieth century would entail instantly recalling their image rather than the content of their words or actions. Political campaigns have been won and lost at the hands of advertisement budgets, party political broadcasts and impactful slogans. It appears that we are in the midst of fast food politics, a generation of the slogan-oriented, averse to analysis of manifesto.\n\n\n5. The Peek-a-Boo World\nHere, the author establishes the “information-action ratio”, a concept that considers the relevance of a communication to the person receiving it.\n“…how often does it occur that information provided to you on morning radio or television, or in the morning newspaper, causes you to alter your plans for the day, or to take some action you would not otherwise have taken, or provides insight into some problem you are required to solve?” [2, p. 78]\nThe author goes on to qualify such exceptions to the low relevance information generally on offer by television, such as weather programming and stock movements. It is an interesting concept that I have pondered, finding exceptions here and there myself, such as programmes that help people to manage their finances, special interest programming such as gardening shows, and so on. I can only estimate how important shows such as Songs of Praise must be for those who are unable to participate in the communal observation of their religion in person. Undeniably, these shows would be exceptions that prove the rule - that the purpose of the television is primarily to entertain, even when it purports to inform.\nPostman’s criticism of what has become “The News of the Day”, which he states started with the invention of the telegraph and has been further transformed by a partnership between television and newspapers into the ‘human interest’ genre, is that the information is low in information-action ratio. With the telegraph, “news from nowhere, addressed to no one in particular, began to criss-cross the nation” [2, p. 78].\nThis commodification of contextless information, Postman argues, was bolstered by photography. Once papers adopted the photograph, “For countless Americans, seeing not reading, became the basis for believing” [2, p. 86]. A prescient point as we enter the age of the deep fake.\nThe author warns that our culture is bombarded with low-relevance information and a limited capacity for sorting it based on relevance. I have found the combination of a negative news loop and continual outrage on social media to have caused a shift in my personal behaviour away from those media. Yet I also note that at the time of writing this blog, the United Kingdom has experienced its largest sustained demonstration in history. Outbreak of war between Israel and Hamas has caused people across the country to consider their own position on the matter, arousing strong emotions that have led to these mass demonstrations. Similarly during the Covid-19 lockdowns, the greater part of the nation coalesced around the television to gain their news from the Covid press briefings. While the vast majority of television’s content may be almost irrelevant to those subject to it, its ability to influence on a mass scale may be magnified during crises.\nI will complete my review of Part 1 on the author’s warning that has troubled me the most. That televised media has become the dominant culture in a way that we can no longer separate the two.\n“Twenty years ago, the question, does television shape culture or merely reflect it? held considerable interest for many scholars and social critics. The question has largely disappeared as television has gradually become our culture.” [2, p. 91].\nAs fish may be largely unaware of the water around them, we are immersed in TV culture and are generally oblivious to how this has mediated our thoughts. One could argue that the relevance of television is in decline and that newer forms of media are to dominate the future. I would argue that the addictive properties of the mobile phone tend to be those that ape features of television, albeit a television that can follow you out of your living room, accompany you on your dog walk and keep you enthralled on your drive to work. It seems that the human predilection for entertainment can subjugate notions of personal safety and consideration for others.\n\n\n\nPart 2\n\n6. The Age of Show Business\nThis chapter best represents the core of Postman’s criticism. He elaborates on how entertainment has become ‘baked-in’ to television’s format, even in the more sober programming. As the author puts it, “…entertainment is the supra-ideology of all discourse on television” [2, p. 102]. Postman argues that this exaltation of entertainment has gone on to influence the wider culture.\n“Television is our culture’s principal mode of knowing about itself… how television stages the world becomes the model for how the world is properly to be staged…\nIn courtrooms, classrooms, operating rooms, boardrooms, churches and even airplanes, Americans no longer talk to each other, they entertain each other. They do not exchange ideas; they exchange images. They do not argue with propositions; they argue with good looks, celebrities and commercials.” [2, p. 108]\nIf I needed to reduce the book down to one quote, it would be the above. The values enshrined by television have been broadly adopted, influencing our societal norms. Postman rightly points to limitations in television’s format that limit reasoned conversation. In its pursuit of the stimulating, television generally does not permit hesitation. Uncertainty is not tolerated on modern TV. The act of thinking does not make for good viewing. Over time, our tolerance for thinking-time in real-life situations such as the boardroom or the job interview has been further eroded by standards propagated by TV. The iconic Dragon’s Den sixty second business pitch, replete with hype and corporate speak becoming the subconscious expectation for discourse in all situations.\nIn recent years, the division between television and the rest of the world has reduced further still, with the ‘reality TV’ genre aiming to commodify what may be represented as everyday life. Now there are TV shows where we can watch others watching TV shows. Instagram is the social media platform where people present an idealised impression of their lives on a dedicated catwalk, while on YouTube, people and families commodify their own lives, merging their leisure time with commercial opportunities in order to monetise every waking second. It is clear that television (and its close cousins) have become inextricably linked with human experience. It is likely that rather than causing the end of television culture, the internet has served television in such diverse formats that it is nearly inescapable.\n\n\n7. “Now… This”\n“For on television, nearly every half hour is a discrete event, separated in content, context and emotional texture from what precedes and follows it.” [2, p. 116]\nPostman applies this in what he refers to in its most embarrassing form to the news of the day shows. Updates may be broadly grouped as ‘politics’ or ‘sport’ but are scheduled to stimulate attention and emotion, in short - to entertain. Accompanied by attractive presenters, stirring music and interspersed with engaging commercials, Postman rightly points out that the viewer understands that even the most horrific article on the human impact of war should not upset the rest of their day. Quickly, the viewer’s palate will be cleansed in preparation for the next article in what has become a form of cultural voyeurism.\nPostman’s point about the fragmented context of a TV schedule may be applied at a finer scale in related visual formats. Many studies have investigated change in cinema and viewer attentiveness. Cornell University [4] have investigated decline in shot duration in a broad range of movies, finding a stable trend in decreasing shot duration. The interpretation of this finding is that cinema adapts to a society with less tolerance for boredom by ensuring that the executive function of cinema-goers is not taxed. Or in the words of Ridley Scott, on his latest movie Napoleon, he constantly watches for the “bum-ache factor” [5] in his movie-goers, which I find quite fascinating - Scott’s 40 year-old science fiction masterpiece Alien is well-known to revel in longer shot durations.\nThis trend in shot length can be anecdotally observed in television also, especially in children’s programming. Some shows that my children adore, I struggled to ‘keep up with’ - almost anything produced by Nickelodeon. The comparison to some of the older endearing shows of yesteryear such as ‘Watch With Mother’, ‘Thomas The Tank’ and ‘The Clangers’ is stark. As culture has adopted the norms of increased segmentation, a feedback loop whereby viewers no longer wish to endure longer format media may have driven a trend toward a reduced shot duration, greater emphasis on motion and greater stimulation brought about by frequent context switching.\nThe author’s warning to society is that the danger of a slew of information bereft of context, relevance and meaning has left people indifferent. How can a person internalise this glut of information without being seriously affected by the scenes of crime, war and human suffering? The answer would be in a societal intellectual compartmentalisation - cognitive dissonance at scale.\n“…it is far more likely that the Western democracies will dance and dream themselves into oblivion than march into it, single file and manacled… it is not necessary to conceal anything from a public insensible to contradiction and narcotized by technological diversions.” [2, pp. 128–129]\n\n\n8. Shuffle Off to Bethlehem\nIn this chapter, Postman explores how television has given a new platform to religion and how the norms of the television medium have influenced the content provided by religious programming. When AOtD was written in the 1980s, Postman observed that the most viewed religious content at the time had become focussed on dealing with the extremes of the human condition. Commercials showing people wracked with guilt or in desperate conditions and turning to the church for solace. Postman’s observation that extreme emotions translate to higher ratings was astute, predicting the trend for American TV evangelicals, of which the most viral have now become immortalised in memes rather than by the rapture that they tend to call for.\n\n&lt;a href=\"https://tenor.com/view/ken-copeland-kenneth-copeland-lil-kc-covid19-covid19preacher-gif-21109768\"&gt;Ken Copeland Kenneth Copeland GIF&lt;/a&gt;\nfrom\n&lt;a href=\"https://tenor.com/search/ken+copeland-gifs\"&gt;Ken Copeland GIFs&lt;/a&gt;\n\n\nWhich brings me to Postman’s next concern about religious show business - the unavoidable celebrity that the clerics attract. Coupled with the monetisation of modern religious viewing, a malaise of spiritual bankruptcy has been accepted in this most visible element of the modern church. Celebrity pastors become extremely wealthy while serving explosive rhetoric, using advertisement campaigns designed to prey upon misery, insecurity and vulnerability. Undoubtedly, at its worst, modern religious programming in the United States has become a caricature, a ridiculous spectacle of extremes. I note that the sort of viewing that I am selectively referring to here may not reflect all shows of this nature. In stark contrast, the BBC’s Songs of Praise could not be characterised as extreme in any way - largely due to the BBC’s public broadcasting purpose, it is not subject to the format pressures that monetisation (or arguably ratings) introduce.\nMuch of today’s religious viral content has great potential to misrepresent the defining features of its subject’s faith. To those passing viewers of no particular denomination, these shows often present a glimpse into a cast in the act of uncouth showmanship, rather than a community in the act of worship.\n\n\n9. Reach Out and Elect Someone\nA consistent thread in AotD is the change in political discourse between 1780s and 1980s America. Back in chapter 4, The Typographic Mind, Postman introduces the Lincoln-Douglas debates [6] in order to make two key points, the first being that the duration (7 hours in one sitting) and complexity of the discourse allowed a more nuanced evaluation of the positions of the candidates. The second point made was about the proposed capacity of the audience to sustain their comprehension of the complex subject matter for such an extended duration.\nIn chapter 9, Postman returns to this example in order to illustrate the decay in the public’s appetite for meaningful political discourse. Some of his points land well, with a stark contrast in recent years with the rise of populism and in particular the appalling and often provocative use of language during presidential debates appealing to the more base instincts of an audience. Yet something troubles me in the contrasting examples employed by Postman in order to make his point:\n\nHow can we say with any certainty that the attendees of the Lincoln-Douglas debates had comprehended the content?\nWhat evidence is there that the mental faculties of the Lincoln-Douglas debates’ audience were representative of the average American?\n\nThese two key questions cannot be answered by historical accounts alone. Without testing and surveying the audience immediately on exiting the debates, it would be incorrect to draw conclusions that could be generalised to a larger population. While it may be that societal and technological change may have reduced an average person’s attention span, I would not attempt to base my argument on anecdotal supposition.\nOn the subject of comparing political candidates,\n“…television makes impossible the determination of who is better than whom, if we mean by”better” such things as more capable in negotiation, more imaginative in executive skill, more knowledgeable about international affairs, more understanding of the interrelations of economic systems, and so on… For on television, the politician does not so much offer the audience an image of himself, as offer himself as an image of the audience.” [2, p. 155]\nI would agree that the limitations in television’s format constraints make for a poor vehicle for political awareness. We have seen how televised political debates become bouts of slogans and savagery. It means a great deal if a person is not allowed to take the necessary time to process and formulate a reasoned response. The rules of the game are then not in comprehension and logic. The most effective path to success would be in securing the audience’s appeal while simultaneously eroding public confidence in the competition.\nAnd on the point of how politics has; like many aspects of society; become obsessed with matters of image - where should we point the blame for this shallow obsession? The fact that Neil Kinnock falling over on Brighton Beach, Ed Miliband’s infamous bacon butty gurn or the media’s flare for capturing Theresa May’s most unflattering expressions likely sold more newspapers than any analysis of their respective parties’ manifestos ever did. In voting for a person instead of a party, are we not putting all of our political eggs in one basket?\n\n\n10. Teaching as an Amusing Activity\nOf all the different domains of society that Postman explores through his lens of discounted discourse, it was the topic of education that resonated the most with me. I should divulge that I have previously spent nearly ten years teaching high school science within the British education system.\nMy initial impression is that Postman is no fan of Sesame Street. As a child of the ‘80s, this is not a strong start. While not wholly critical of the Muppets-inspired preschool ’edutainment’ show in its potency as an entertaining pastime for preschoolers, Postman finds the precedent it sets for presenting television as a medium for education disagreeable.\nIn this chapter, the author sets out what I consider to be the most concerning element of his argument against television’s command of our culture - its ability to displace education with entertainment. This resonates with my experience in education during a period of technological advancement that must have supplanted television’s ability to interfere with intellectual advancement - the multimedia mobile phone. Postman’s technological scepticism in the 1980s may have been interpreted as antiquated at the time but to my mind this chapter is imbued with a prophetic quality.\n“…television has by its power to control the time, attention and cognitive habits of our youth gained the power to control their education. This is why I think it is accurate to call television a curriculum… whose purpose is to influence, teach, train or cultivate the mind and character of youth. Television, of course, does exactly that, and does it relentlessly. In so doing, it competes successfully with the school curriculum… it damn near obliterates it” [2, p. 169].\nThe crucial difference between the mobile phone and the traditional television that Postman opined in the ’80s is that the phone has now become a mobile television, among many other things. The need for traditional education to compete with this alternative curriculum has introduced a great deal of friction in the modern classroom, as if there were not enough already. But for a proportion of the population, the persistent availability of entertainment over education has devastating consequences. I know this because I have seen it. For many young people, education is rarely an enjoyable undertaking and preparing themselves requires discipline and endurance. Adding a constant opportunity for distraction to this situation will render a smaller proportion of our youth unable to learn anything other than the most shallow of content. One may argue that this has always been the case, which I would not refute. My position is that the proportion of people who are unable to access the National Curriculum has grown as a result of improper technological interference.\nPostman’s next point about television’s societal influence is yet more troubling. As he sets out in previous chapters, television not only presents certain standards for our intercourse, it establishes those norms for our use in society. In this context, television not only displaces education, it remodels it. On the topic of ‘dumbing down’ in educational curricula,\n“Mainly, they will have learned that learning is a form of entertainment or, more precisely, that anything worth learning can take the form of entertainment, and ought to. And they will not rebel if their English teacher asks them to learn the eight parts of speech through the medium of rock music. Or if their social studies teacher sings to them the facts about the War of 1812. Or if their physics comes to them on cookies and T-shirts. Indeed, they will expect it and thus will be well-prepared to receive their politics, their religion, their news and their commerce in the same delightful way” [2, p. 179].\nCurriculum-reform has faced a crisis in recent years - what should we teach children who now have the world’s information in their pocket? Education’s response to this development in the early part of the 20th century has been to strip the curriculum of content, to focus on the development of skills over knowledge. This has been coupled with prioritisation of skills in assessment frameworks. Our newfound ability to outsource accurate recall to devices has resulted in doctors that Google your symptoms, mechanics that Google engine components and data scientists that Google model parameters - I am compelled to disclose this last example, having successfully transitioned away from teaching to analysis in more recent years.\nHow problematic is all this change? Human recollection was never our species’ strong suit - just ask a legal professional about the fallibility of human memory. Better to outsource that to the machine, right? It is certainly convenient, and as someone who considers themselves a bit of a professional Googler, it’s undeniable that it is at times a tool for good. But is it a good idea to hand over responsibility for knowledge retrieval to the machine, or more accurately big corporations? What do we lose when we do this? What are the unseen biases and agendas in the content that is shown or censored? How are these intrinsic patterns affecting outcomes for people?\nThe shift from recall to a skills-based educational framework has assumed that the value of a human being is in synthesis - the ability to evaluate sources of information and to put it to work, composing novel content. As Large Language Models begin to reveal their potential in executing these higher-order intellectual functions, where do we go next? Technology’s advancement has the potential to disrupt our estimation of human value and priority. Will lack of practice in the creative endeavour reduce our species to manipulators of tools produced by the machine, or increase our capacity for creation - freeing us from time consuming, lower operations? I don’t know, but I can say that we will be discovering the answer to these questions in retrospect - realising the consequences; both desirable and otherwise; as we proceed through uncertainty.\n\n\n11. The Huxleyan Warning\nIn the final chapter, Postman reflects upon his argument against technology, examining the readiness of American people to adopt novel technology in spite of the potential disadvantages they may incur.\n“…a population that devoutly believes in the inevitability of progress… all Americans are Marxists, for we believe nothing if not that history is moving us toward some preordained paradise and that technology is the force behind that movement” [2, p. 183].\nThe reference to Marxism does not capture a meaningful assessment underlying the ideology. After all, Marx called for the people to intervene in the direction of their future based upon his assessment of the flaws in prevalent capitalist societies. This would not presume progress as the default position, although Marx did suggest that a system of rules limiting personal gain at the expense of others could result in a form of utopia if properly administered. I presume Postman’s comment to be a provocation of the intended audience, potentially born out of frustration at a society willing to roll the dice on progress through technology.\n“Americans will not shut down any part of their technological apparatus, and to suggest that they do so is to make no suggestion at all… Many civilized nations limit by law the amount of hours television may operate and thereby mitigate the role television plays in public life. But I believe that this is not a possibility in America” [2, p. 184].\nPostman makes an interesting point about directionality in technological innovation. When a novel product has non-trivial, immediate and tangible benefits you may expect it to be readily adopted. Once the economies of scale have been applied to said product and the reduction in financial cost has removed the significant barrier to accessing those benefits, I agree that our ability to reverse such widespread adoption is limited. Demand and profiteering form an economic valve that maintains the product evolution and consequent sales. The fact that the consequences of all this activity may be measured over a lifetime while the benefits may be observed within an instant is a dichotomy that the human mind appears poorly equipped to deal with. Technology may be our modern-day pandora’s box.\nFinally, Postman turns his attention to the computer, where he was both right and wrong,\n“Although I believe the computer to be a vastly overrated technology, I mention it here because, clearly, Americans have accorded it their customary mindless inattention; which means they will use it as they are told, without a whimper” [2, p. 187].\nHere, Postman proves that a person’s biases limit their understanding of potential. In the ’80s the position of computers in our society may have been debatable, although not to the likes of Bill Gates. It’s obvious from today’s perspective that the utility of the computer has been proven. People form interests around ideas and things that align with their values, developing foresight into potential applications as they encounter problems throughout their everyday life. Postman was wrong in his assessment of the utility of the computer, but in his subsequent statement,\n“…years from now, …it will be noticed that the massive collection and speed-of-light retrieval of data have been of great value to large-scale organizations but have solved very little of importance to most people and have created at least as many problems for them as they may have solved” [2, p. 187].\nIt is fascinating to observe this foresight from forty years ago. In the age of the multinational technology corporation, fortunes have been built upon meeting human needs. The consequent power this has produced has recently been accused of interfering; or being exploited to interfere; with democratic elections around the world. This has evolved into a power struggle for public influence between big corporations and authorities of various territories. Some twenty years after social media’s inception, governments have begun a campaign of control over social media platforms, opting to censor and police where they deem it necessary. Whether this represents infringement or protection of our rights is hotly contested. Could it be that Postman was again, partially right and wrong about the relative threats of Orwellian and Huxleyan dystopia? What if they are not mutually exclusive and what if technology enables the worst of both worlds?"
  },
  {
    "objectID": "book-reviews/03-amusing-ourselves-to-death.html#analysis-and-evaluation",
    "href": "book-reviews/03-amusing-ourselves-to-death.html#analysis-and-evaluation",
    "title": "Amusing Ourselves to Death",
    "section": "Analysis and Evaluation",
    "text": "Analysis and Evaluation\nIt would be tempting to dismiss Postman’s criticisms of television culture as an antiquated resistance to progress - this would be an ignorant treatment of his argument. Technological advancement has demonstrated its ability to transform our culture. As a species we are locked into a continual compromise of how to implement immediate benefits while avoiding the longer-term costs. When a technology’s consequences are transformational; as was the case with the printing press, the lightbulb, the nuclear bomb and the multimedia device; might it be best to proceed with caution, allowing time for a more meaningful cost-benefit analysis?\nIn the Imperative of Responsibility [7], Hans Jonas considers an alternative ethical framework, designed to hold those responsible of profiting from technological enterprise responsible for any remote and unforeseen consequences of its implementation. This principle is known as the Precautionary Principle and has garnered equal support and derision in academic literature. Authorities around the world have enacted the Precautionary Principle, establishing policy, regulation and; where identification of the causes of environmental degradation can be evidenced; to pursue justice.\nCritics of the Precautionary Principle would argue that it significantly raises the bar to human progress and that this presents an ethical quandary. Could you imagine an alternative reality where legislation prevented mass adoption of the light bulb pending a full review of the environmental and societal consequences? How would our world have been limited by the lack of access to this invention? And then again, how would our world have changed if we had paused for more information prior to rolling out thalidomide to expecting mothers?\nTo undertake an assessment of the full impact of Edison’s filament lamp on society would have been impossible at that time. It would have required an evaluation of innovations that had yet to exist and processes that were yet to be understood. This would include a multitude of missing jigsaw pieces, such as a national-scale power grid (that would only come to be some half a century after Edison perfected his initial design), an awareness of the greenhouse effect and how electricity generated by fossil fuels contribute to this (legitimacy still argued in some circles), the study of human circadian rhythm and how this would be disrupted by the invention, an evaluation of the impact of light pollution and so on. At the same time, the case for the technology would need to be evidenced in greater measure. Evidencing the benefits to productivity, safety, leisure and wellbeing that mass adoption of the light bulb would induce would have been a monumental undertaking. This is to say nothing of the consequential innovations that either required or were inspired by the filament lamp, or that in time we would improve it, producing brighter, more efficient devices that would mitigate much of that initial risk yet cause new environmental consequences related to the use of plastics and production and safe disposal of semiconductors.\nThe effort described above may have delayed the mass rollout of the lightbulb by half a century or more. Time therein where the world literally sits in the dark, awaiting the bureaucracy to arrive at a decision. Preparing the world for a transformational technology may be considered an intractable problem. The Collingridge dilemma states that until a technology has been embedded in a society, there is not enough information to provide an informed assessment of its risk, and then as a consequence of the widespread adoption, an inability to effectively regulate that technology. That doesn’t mean we get to wash our hands of the responsibility of doing this - not at all. A full and unbiased evaluation of the consequences of innovation that is proportionate to the current evidence of risk would be a vast improvement over a system accelerated by profit and disregard for all else. Political lobbying, the reproducibility crisis in many fields of research and our chronic inability to identify and prosecute fraudulent behaviour have resulted in an economy where the cost of hindering technological progress outweighs the consequences to its proliferation. To put it bluntly, we have a prenatal societal capacity to defer gratification.\nWith the scales tipped in favour of progress above all else, the ramifications for a society at the inception of generative artificial intelligence are clear. As artificial general intelligence now appears more feasible than ever, many people of influence are involved in a rich ethical debate.\n\n\n\nIn AI, the ratio of attention on hypothetical, future, forms of harm to actual, current, realized forms of harm seems out of whack. Many of the hypothetical forms of harm, like AI \"taking over\", are based on highly questionable hypotheses about what technology that does not…\n\n— Andrew NgDecember 18, 2023\n\n\n\n\nEarlier this week, POTUS Biden issued an executive order on artificial intelligence – a breakthrough technology that has the power to change the world in ways we’re only beginning to understand.I wanted to share some of the books, articles, and podcasts that have helped shape…\n\n— Barack ObamaNovember 3, 2023\n\n\n\nWhether or not the future risks of generative AI will be well-managed will be based upon the conversations that we have today. At this juncture in our history, the role of the sceptic may be more vital than ever. It is not enough to sway opinion by preaching calamity or pigeonholing criticism as antiquated techno-scepticism. Finding effective modes of discourse to help promulgate AI awareness is the route to ethically achieve the integration of this latest transformative technology. The only means to navigate this milestone must be to deepen our understanding of the technology and each other. To this end I would encourage the use of open source AI tools, to discuss the implications, benefits, limitations, biases and drawbacks. Educate yourself on the direction of the research and to attempt to stay abreast of the news in the sector, while avoiding tabloid sensationalism."
  },
  {
    "objectID": "book-reviews/06-second-brain.html#book-summary",
    "href": "book-reviews/06-second-brain.html#book-summary",
    "title": "Building a Second Brain",
    "section": "Book Summary",
    "text": "Book Summary\nBuilding a Second Brain by Tiago Forte is a productivity book that teaches how to take and organise effective notes in a digital format. Collating these records with your own synthesis within a cohesive software ecosystem in order to improve productivity and support creative work.\n\n“Those who learn how to leverage technology and master the flow of information through their lives will be empowered to accomplish anything they set their minds to.” [1, p. 7]"
  },
  {
    "objectID": "book-reviews/06-second-brain.html#on-the-author",
    "href": "book-reviews/06-second-brain.html#on-the-author",
    "title": "Building a Second Brain",
    "section": "On the Author",
    "text": "On the Author\nTiago Forte is a productivity expert known for his work on personal knowledge management. He studied international business and worked in various roles, including the Peace Corps in Ukraine, where he taught productivity techniques. His career in innovation consulting introduced him to the world of Personal Knowledge Management (PKM), leading to the creation of his training venture, Forte Labs. This has since grown into a successful online education company, with Forte emphasising the integration of personal and professional growth. His work focuses on helping individuals manage information overload to enhance creativity and productivity."
  },
  {
    "objectID": "book-reviews/06-second-brain.html#three-takeaway-ideas",
    "href": "book-reviews/06-second-brain.html#three-takeaway-ideas",
    "title": "Building a Second Brain",
    "section": "Three Takeaway Ideas",
    "text": "Three Takeaway Ideas\n\n1. Consolidation.\nWhat I liked best about this book was that it didn’t feel completely new to me. It discussed concepts that I had intuited and practised in less formal ways prior to reading. Therefore, adaptation to a centralised digital notekeeping solution would present a minor attitude adjustment, rather than a complete transformation.\nBack in 2015 I had attended a training course on how to get the most out of Microsoft OneNote, with low expectations and even less interest. Previously, OneNote had been the perplexing default option for printing documents - a minor annoyance while I swiftly found the printer I needed. The training session did a lot to demystify the software and highlighted some great features which at the time felt quite revolutionary, notably audio transcription, apply and search notes by tag and video embedding. I proceeded to use OneNote to record meeting outcomes, transcribe user-testing sessions, scribble ideas over papers and policy documents and so on. Some of my colleagues started to notice and asked me about it. I remember saying these words:\n\nIf I need to find something, I can ‘CTRL + F’ the software, whereas I can’t do that with a notebook or stack of post-it notes.\n\nOver time, my digital ecosystem has diversified a bit. Sometimes because of me and software compatibility with the devices that I use, and at other times because of the preferences of my team. This book made a great case for favouring interoperable software to achieve a unified note taking system. Software that cannot work together is not serving your ability to retrieve information when you need it most.\n\n“Research from Microsoft shows that the average US employee spends 76 hours per year looking for misplaced notes, items, or files. And a report from the International Data Corporation found that 26 percent of a typical knowledge worker’s day is spent looking for and consolidating information spread across a variety of systems.” [1, p. 16]\n\nThis must be achingly familiar to most modern workers, especially programmers. Those times when you find yourself Googling for solutions that you once knew, following purple links that you’ve already visited. Or trying to find that salient programming meme or inspirational quote in a newly refreshed social media feed. Surely, everyone has experienced this? Tiago Forte’s book suggests that if we ‘get our digital act together’, we don’t have to rely on our biological brain for recall. We can farm that job out to a digital note taking system which will perform better, recall faster and with greater accuracy. Instead, we can shift our efforts to synthesis - spotting connections between notes, adding our interpretation to them and extracting relevance in the process.\n\n\n2. C.O.D.E.\nTo anyone who has found themselves mindlessly highlighting reams of a text with no specific reason in mind, other than in a futile attempt to try to remember everything (guilty as charged), Forte’s C.O.D.E. recipe can offer clarity:\n\nMy interpretation of the recipe is as follows:\nCapture: Your note taking app should be ready to go at all times. With the capability to sync across all of your devices and backed up in the cloud, you should never miss an opportunity to make a record of an important piece of information, whenever and wherever it presents itself to you. More on the type of information to capture in a note in section 3.\nOrganise: Consider where the note should live within your digital brain. Don’t put pressure on yourself to do this straight away, as it may dissuade you from recording notes in the first place. But use your default section of a notebook (the area where documents would print to by default in OneNote for example) as a holding area. You can then triage these notes later in the day.\nAlso, don’t agonise over where to locate these notes. Remember that you can search for them across your entire notebook. In fact, revisiting important notes and realigning them to new project folders or bringing old notes out of cold storage can play an important part in the creative process - never start from scratch again! Every time you initiate a new project, a great starting point would be to consult existing notes for relevant content. Most modern note taking applications also allow you to create internal links, allowing you to build connections across topics in your digital notes, or to group notes together under an index page.\nDistill: The author suggests a specific summarising mechanism to allow at-a-glance knowledge retrieval when revisiting notes. One crucial element in acquiring knowledge is that you should always endeavour to do something with the information you wish to learn. Over time, when the details fade in your mind, it is the impact or relevance of that information that remains. Forte encourages the reader to develop the habit of reflecting upon the studied content, leaving helpful summaries that will aid your future self in retrieving what was important.\nExpress: Evaluate. Share the products of your note taking efforts and seek feedback from others. Find opportunities to help those around you in professional communities and consider how to refine your notes or your note-taking practice. Forte introduces the concept of “intermediate packets” - over time, projects may call for common notes or portions of notes to be put to work. In iteratively refining these packets of information, they can be adapted or generalised, greatly helping to facilitate future work.\n\n\n3. What to Capture?\nThe author emphasises the importance of allowing your intuition to guide you when deciding on what information holds more value within any piece of text. The more you practise this skill, the better you will become in extracting the salient points of a text. If that sounds too much like hard work, the author suggests aligning your priorities to a set of ongoing projects that will help to guide your attention in capturing, organising and reflecting upon information.\n\n“You have to keep a dozen of your favourite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps.” (Nobel prize-winning physicist Richard Feynman reflects on his strategy for success) [1, p. 44]\n\nI don’t consider the number twelve to be particularly important in all honesty. But you may have a few longer term targets in a professional development plan that you would like to progress - why not start with these? Having sections of your digital brain dedicated to these topics allows you to orient your efforts and order your thoughts.\nForte also provides direction to those who need more direction in deciding what information has the greatest utility.\n\n“Capture Criteria #1: Does It Inspire Me? …\n”Capture Criteria #2: Is It Useful? …\n“Capture Criteria #3: Is It Personal? …\n”Capture Criteria #4: Is It Inspiring?” [1, pp. 48–49]\n\nThese criteria can be used to help filter the information that you capture, allowing you to focus on that which is most important. The author offers a brief explanation for each of the criteria, supported by examples. I am currently trying these criteria on for size and have included a highlighting key within my note taking app to help me remember to use them."
  },
  {
    "objectID": "book-reviews/06-second-brain.html#in-summary",
    "href": "book-reviews/06-second-brain.html#in-summary",
    "title": "Building a Second Brain",
    "section": "In Summary",
    "text": "In Summary\nOverall, I would recommend this book to anyone interested in the personal efficacy space. It is full of practical advice and encouragement to get started or to refine your digital note taking system. The book contains plenty of examples that illustrate exactly how to put the ideas into action, catering for a range of preferred learning styles. Additionally, the author’s system is extremely well-supported and debated online. Check out the Forte Labs website and the Tiago Forte YouTube channel for more information.\nIf this book inspired you to start your own digital note taking system, you may find my review of Cal Newport’s Deep Work book useful."
  },
  {
    "objectID": "book-reviews/06-second-brain.html#acknowledgements",
    "href": "book-reviews/06-second-brain.html#acknowledgements",
    "title": "Building a Second Brain",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI would like to thank Beth for a fantastic book recommendation - this was a great read."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to The Data Savvy Corner!",
    "section": "",
    "text": "A site to store blogs about programming concepts, software development and data science. Generally things that future me will be thankful that I’ve recorded."
  },
  {
    "objectID": "index.html#intro",
    "href": "index.html#intro",
    "title": "Welcome to The Data Savvy Corner!",
    "section": "",
    "text": "A site to store blogs about programming concepts, software development and data science. Generally things that future me will be thankful that I’ve recorded."
  },
  {
    "objectID": "index.html#site-overview",
    "href": "index.html#site-overview",
    "title": "Welcome to The Data Savvy Corner!",
    "section": "Site Overview",
    "text": "Site Overview\n\nTechnical Blogs : Technical blogs, Explanations, tutorials, how-to guides. All articles are categorised according to the excellent diataxis framework.\nMusic Reviews : Mostly album reviews. I listen to instrumental music when programming. This was a habit that I developed while working within a busy office environment. This has helped me efficiently establish a state of mental flow required for deep concentration. I’ll include reviews of some of my favourite albums here.\nBook Reviews : Much of my casual reading is non-fiction and tangential to programming. I’ll review material here that I have found to be supportive of my work in various aspects."
  },
  {
    "objectID": "index.html#recent-articles",
    "href": "index.html#recent-articles",
    "title": "Welcome to The Data Savvy Corner!",
    "section": "Recent Articles",
    "text": "Recent Articles\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nLazy Mocking\n\n\n\n\n\n\nHow-to\n\n\npytest\n\n\nUnit tests\n\n\nmocking\n\n\npytest-in-plain-english\n\n\npatching\n\n\nlazy\n\n\nlazy evaluation\n\n\n\nUsing Fixtures to Mock With Deferred Evaluation\n\n\n\n\n\nNov 4, 2024\n\n\nRich Leyshon\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nCommit with Clarity\n\n\n\n\n\n\nExplanation\n\n\nGitHub\n\n\nGit\n\n\nVersion Control\n\n\nSoftware Development\n\n\nBlame\n\n\nVSCode\n\n\nGit Grep\n\n\n\nBuilding a Better Audit Trail with GitHub\n\n\n\n\n\nOct 13, 2024\n\n\nRich Leyshon\n\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\n\nChoose Your Own Adventure with ChatGPT\n\n\n\n\n\n\nTutorial\n\n\nPython Shiny\n\n\nLLMs\n\n\nLarge Language Models\n\n\nGenAI\n\n\nGenerative AI\n\n\nFront End Dev\n\n\nOpenAI\n\n\n\nIteratively Building an LLM-Powered Shiny Application.\n\n\n\n\n\nSep 21, 2024\n\n\nRich Leyshon\n\n\n83 min\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Second Brain\n\n\nA Proven Method to Organise Your Digital Life and Unlock Your Creative Potential.\n\n\n\nNon-fiction\n\n\nSelf-Help\n\n\nProductivity\n\n\nPersonal Knowledge Management\n\n\nPersonal Development\n\n\nBusiness\n\n\nPsychology\n\n\nTechnology\n\n\nNote Taking\n\n\n\nSystematise what you’re already probably doing.\n\n\n\n\n\nSep 6, 2024\n\n\nRich Leyshon\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto Comments\n\n\n\n\n\n\nExplanation\n\n\nQuarto\n\n\nComments\n\n\nHypothesis\n\n\nGitHub\n\n\nUtterances\n\n\nGiscus\n\n\n\nComparing Hypothesis, Utterances & Giscus.\n\n\n\n\n\nAug 18, 2024\n\n\nRich Leyshon\n\n\n16 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Welcome to The Data Savvy Corner!",
    "section": "About Me",
    "text": "About Me\n\nI am a Senior Developer at the the Ministry of Justice, UK. I enjoy programming & automation and an advocate for the standards outlined in Quality Assurance of Code for Analysis & Research. For more detail regarding my professional experience, please follow this link to my resumé. To collaborate, reach out at my GitHub profile."
  },
  {
    "objectID": "music-reviews/index.html",
    "href": "music-reviews/index.html",
    "title": "Music",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nWhen Worlds Collide\n\n\n3 min\n\n\nThomas Barrandon’s understated scifi masterpiece\n\n\n\nRich Leyshon\n\n\nMay 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTriads\n\n\n5 min\n\n\nCode Elektro’s exploration of future Japan’s criminal underworld\n\n\n\nRich Leyshon\n\n\nApr 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDonkey Kong Country Relaxing Piano (Instrumental)\n\n\n5 min\n\n\nBeautiful zen with a nostalgic twist.\n\n\n\nRich Leyshon\n\n\nJan 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZelda & Chill\n\n\n9 min\n\n\nA Lofi Homage to Nintendo’s Zelda Series, Composed by Mikel & GameChops\n\n\n\nRich Leyshon\n\n\nOct 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGhostrunner\n\n\n9 min\n\n\nA review of the soundtrack to the 2020 hit video game Ghostrunner, composed by Daniel Deluxe.\n\n\n\nRich Leyshon\n\n\nSep 5, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html",
    "href": "blogs/11-fiddly-bits-of-pytest.html",
    "title": "Pytest Fixtures in Plain English",
    "section": "",
    "text": "Creative commons license by Ralph"
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html#introduction",
    "href": "blogs/11-fiddly-bits-of-pytest.html#introduction",
    "title": "Pytest Fixtures in Plain English",
    "section": "Introduction",
    "text": "Introduction\npytest is a testing package for the python framework. It is broadly used to quality assure code logic. This article discusses using test data as fixtures with pytest and is the first in a series of blogs called pytest in plain English, favouring accessible language and simple examples to explain the more intricate features of the pytest package.\nFor a wealth of documentation, guides and how-tos, please consult the pytest documentation.\n\n\n\n\n\n\nA Note on the Purpose (Click to expand)\n\n\n\n\n\nThis article intends to discuss clearly. It doesn’t aim to be clever or impressive. Its aim is to extend the audience’s understanding of the more intricate features of pytest by describing their utility with simple code examples.\n\n\n\n\nIntended Audience\nProgrammers with a working knowledge of python and some familiarity with pytest and packaging. The type of programmer who has wondered about how to optimise their test code.\n\n\nWhat You’ll Need:\n\nPreferred python environment manager (eg conda)\npip install pytest==8.1.1\nGit\nGitHub account\nCommand line access\n\n\n\nPreparation\nThis blog is accompanied by code in this repository. The main branch provides a template with the minimum structure and requirements expected to run a pytest suite. The repo branches contain the code used in the examples of the following sections.\nFeel free to fork or clone the repo and checkout to the example branches as needed.\nThe example code that accompanies this article is available in the fixtures branch of the example code repo."
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html#what-are-fixtures",
    "href": "blogs/11-fiddly-bits-of-pytest.html#what-are-fixtures",
    "title": "Pytest Fixtures in Plain English",
    "section": "What are fixtures?",
    "text": "What are fixtures?\nData. Well, data provided specifically for testing purposes. This is the essential definition for a fixture. One could argue the case that fixtures are more than this. Fixtures could be environment variables, class instances, connection to a server or whatever dependencies your code needs to run.\nI would agree that fixtures are not just data. But that all fixtures return data of some sort, regardless of the system under test."
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html#when-would-you-use-fixtures",
    "href": "blogs/11-fiddly-bits-of-pytest.html#when-would-you-use-fixtures",
    "title": "Pytest Fixtures in Plain English",
    "section": "When would you use fixtures?",
    "text": "When would you use fixtures?\nIt’s a bad idea to commit data to a git repository, right? Agreed. Though fixtures are rarely ‘real’ data. The data used for testing purposes should be minimal and are usually synthetic.\nMinimal fixtures conform to the schema of the actual data that the system requires. These fixtures will be as small as possible while capturing all known important cases. Keeping the data small maintains a performant test suite and avoids problems associated with large files and git version control.\nIf you have ever encountered a problem in a system that was caused by a problematic record in the data, the aspect of that record that broke your system should absolutely make it into the next version of your minimal test fixture. Writing a test that checks that the codebase can handle such problem records is known as ‘regression testing’ - safeguarding against old bugs resurfacing when code is refactored or new features are implemented. This scenario commonly occurs when a developer unwittingly violates Chesterton’s Principle.\n\n\nMany thanks to my colleague Mat for pointing me towards this useful analogy. A considerate developer would probably include a comment in their code about a specific problem that they’ve handled (like erecting a sign next to Chesterton’s fence). An experienced developer would do the same, and also write a regression test to ensure the problem doesn’t re-emerge in the future (monitoring the fence with CCTV…). Discovering these problem cases and employing defensive strategies avoids future pain for yourself and colleagues.\nAs you can imagine, covering all the important cases while keeping the fixture minimal is a compromise. At the outset of the work, it may not be obvious what problematic cases may arise. Packages such as hypothesis allow you to generate awkward cases. Non-utf-8 strings anyone? Hypothesis can generate these test cases for you, along with many more interesting edge-cases - ăѣ𝔠ծềſģȟᎥ𝒋ǩľḿꞑȯ𝘱𝑞𝗋𝘴ȶ𝞄𝜈ψ𝒙𝘆𝚣 (Non-utf8 strings often cause problems for web apps).\nNon-disclosive fixtures are those that do not expose personally identifiable or commercially-sensitive information. If you are working with this sort of data, it is necessary to produce toy test fixtures that mimic the schema of the real data. Names and addresses can be de-identified to random alphanumeric strings. Location data can be adjusted with noise. The use of dummy variables or categories can mitigate the risk of disclosure by differencing.\nBy adequately anonymising data and testing problem cases, the programmer exhibits upholds duties under the General Data Protection Regulation:\n\naccurately store, process, retain and erase personally-identifiable information.\n\nIn cases where the system integrates with data available in the public domain, it is may be permissible to include a small sample of the data as a test fixture. Ensure the license that the data is distributed under is compatible with your code’s license. If the license is compatible, I recommend including a reference to the fixture, its source and license within a LICENSE.note file. This practice is enforced by Comprehensive R Archive Network. You can read more about this in the R Packages documentation."
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html#scoping-fixtures",
    "href": "blogs/11-fiddly-bits-of-pytest.html#scoping-fixtures",
    "title": "Pytest Fixtures in Plain English",
    "section": "Scoping fixtures",
    "text": "Scoping fixtures\npytest fixtures have different scopes, meaning that they will be prepared differently dependent on the scope you specify. The available scopes are as follows:\n\n\n\nScope Name\nTeardown after each\n\n\n\n\nfunction\ntest function\n\n\nclass\ntest class\n\n\nmodule\ntest module\n\n\npackage\npackage under test\n\n\nsession\npytest session\n\n\n\nNote that the default scope for any fixtures that you define will be ‘function’. A function-scoped fixture will be set up for every test function that requires it. Once the function has executed, the fixture will then be torn down and all changes to this fixture will be lost. This default behaviour encourages isolation in your test suite. Meaning that the tests have no dependencies upon each other. The test functions could be run in any order without affecting the results of the test. Function-scoped fixtures are the shortest-lived fixtures. Moving down the table above, the persistence of the fixtures increases. Changes to a session-scoped fixture persist for the entire test execution duration, only being torn down once pytest has executed all tests.\n\nScoping for performance\n\n\nperformance vs isolation\n\nBy definition, a unit test is completely isolated, meaning that it will have no dependencies other than the code it needs to test. However, there may be a few cases where this would be less desirable. Slow test suites may introduce excessive friction to the software development process. Persistent fixtures can be used to improve the performance of a test suite.\nFor example, here we define some expensive class:\n\n\nexpensive.py\n\n\"\"\"A module containing an expensive class definition.\"\"\"\nimport time\nfrom typing import Union\n\n\nclass ExpensiveDoodah:\n    \"\"\"A toy class that represents some costly operation.\n\n    This class will sleep for the specified number of seconds on instantiation.\n\n    Parameters\n    ----------\n    sleep_time : Union[int, float]\n        Number of seconds to wait on init.\n\n    \"\"\"\n    def __init__(self, sleep_time: Union[int, float] = 2):\n        print(f\"Sleeping for {sleep_time} seconds\")\n        time.sleep(sleep_time)\n        return None\n\nThis class will be used to demonstrate the effect of scoping with some costly operation. This example could represent reading in a bulky xlsx file or querying a large database.\nTo serve ExpensiveDoodah to our tests, I will define a function-scoped fixture. To do this, we use a pytest fixture decorator to return the class instance with a specified sleep time of 2 seconds.\n\n\ntest_expensive.py\n\nimport pytest\n\nfrom example_pkg.expensive import ExpensiveDoodah\n\n\n@pytest.fixture(scope=\"function\")\ndef module_doodah():\n    \"\"\"Function-scoped ExpensiveDoodah.\"\"\"\n    return ExpensiveDoodah(2)\n\nNow to test ExpensiveDoodah we extend our test module to include a test class with 3 separate test functions. The assertions will all be the same for this simple example - that ExpensiveDoodah executes without raising any error conditions. Notice we must pass the name of the fixture in each test function’s signature.\n\n\ntest_expensive.py\n\n\"\"\"Tests for expensive.py using function-scoped fixture.\"\"\"\nfrom contextlib import nullcontext as does_not_raise\nimport pytest\n\nfrom example_pkg.expensive import ExpensiveDoodah\n\n\n@pytest.fixture(scope=\"function\")\ndef doodah_fixture():\n    \"\"\"Function-scoped ExpensiveDoodah.\"\"\"\n    return ExpensiveDoodah(2)\n\n\nclass TestA:\n    \"\"\"A test class.\"\"\"\n\n    def test_1(self, doodah_fixture):\n        \"\"\"Test 1.\"\"\"\n        with does_not_raise():\n            doodah_fixture\n\n    def test_2(self, doodah_fixture):\n        \"\"\"Test 2.\"\"\"\n        with does_not_raise():\n            doodah_fixture\n\n    def test_3(self, doodah_fixture):\n        \"\"\"Test 3.\"\"\"\n        with does_not_raise():\n            doodah_fixture\n\nThe result of running this test module can be seen below:\ncollected 3 items\n\n./tests/test_expensive_function_scoped.py ...    [100%]\n\n============================ 3 passed in 6.04s ================================\n\nNotice that the test module took just over 6 seconds to execute because the function-scoped fixture was set up once for each test function.\nIf instead we had defined doodah_fixture with a different scope, it would reduce the time for the test suite to complete by approximately two thirds. This is the sort of benefit that can be gained from considerate use of pytest fixtures.\n\n\ntest_expensive.py\n\n@pytest.fixture(scope=\"module\")\ndef doodah_fixture():\n    \"\"\"Module-scoped ExpensiveDoodah.\"\"\"\n    return ExpensiveDoodah(2)\n\ncollected 3 items\n\n./tests/test_expensive_function_scoped.py ...    [100%]\n\n============================ 3 passed in 2.02s ================================\n\nThe scoping feature of pytest fixtures can be used to optimise a test-suite and avoid lengthy delays while waiting for your test suites to execute. However, any changes to the fixture contents will persist until the fixture is next torn down. Keeping track of the states of differently-scoped fixtures in a complex test suite can be tricky and reduces segmentation overall. Bear this in mind when considering which scope best suits your needs.\n\n\nScope persistence\n\n\nfunction &lt; class &lt; module &lt; package &lt; session\n\nUsing scopes other than ‘function’ can be useful for end-to-end testing. Perhaps you have a complex analytical pipeline and need to check that the various components work well together, rather than in isolation as with a unit test. This sort of test can be extremely useful for developers in a rush. You can test that the so called ‘promise’ of the codebase is as expected, even though the implementation may change.\nThe analogy here would be that the success criteria of a SatNav is that it gets you to your desired destination whatever the suggested route you selected. Checking that you used the fastest or most fuel efficient option is probably a good idea. But if you don’t have time, you’ll just have to take the hit if you encounter a toll road. Though it’s still worth checking that the postcode you hastily input to the satnav is the correct one.\n\n\n Perhaps your success criteria is that you need to write a DataFrame to file. A great end-to-end test would check that the DataFrame produced has the expected number of rows, or even has rows! Of course it’s also a good idea to check the DataFrame conforms to the expected table schema, too: number of columns, names of columns, order and data types. This sort of check is often overlooked in favour of pressing on with development. If you’ve ever encountered a situation where you’ve updated a codebase and later realised you now have empty tables (I certainly have), this sort of test would be really handy, immediately alerting you to this fact and helping you efficiently locate the source of the bug.\n\nDefine Data\nIn this part, I will explore the scoping of fixtures with DataFrames. Again, I’ll use a toy example to demonstrate scope behaviour. Being a child of the ’90s (mostly), I’ll use a scenario from my childhood. Scooby Doo is still a thing, right?\nEnter: The Mystery Machine\n \nThe scenario: The passengers of the Mystery Machine van all have the munchies. They stop at a ‘drive thru’ to get some takeaway. We have a table with a record for each character. We have columns with data about the characters’ names, their favourite food, whether they have ‘the munchies’, and the contents of their stomach.\n\nimport pandas as pd\nmystery_machine = pd.DataFrame(\n        {\n            \"name\": [\"Daphne\", \"Fred\", \"Scooby Doo\", \"Shaggy\", \"Velma\"],\n            \"fave_food\": [\n                \"carrots\",\n                \"beans\",\n                \"scooby snacks\",\n                \"burgers\",\n                \"hot dogs\",\n            ],\n            \"has_munchies\": [True] * 5, # everyone's hungry\n            \"stomach_contents\": [\"empty\"] * 5, # all have empty stomachs\n        }\n    )\nmystery_machine\n\n\n\n\n\n\n\n\nname\nfave_food\nhas_munchies\nstomach_contents\n\n\n\n\n0\nDaphne\ncarrots\nTrue\nempty\n\n\n1\nFred\nbeans\nTrue\nempty\n\n\n2\nScooby Doo\nscooby snacks\nTrue\nempty\n\n\n3\nShaggy\nburgers\nTrue\nempty\n\n\n4\nVelma\nhot dogs\nTrue\nempty\n\n\n\n\n\n\n\nTo use this simple DataFrame as a fixture, I could go ahead and define it with @pytest.fixture() directly within a test file. But if I would like to share it across several test modules (as implemented later), then there are 2 options:\n\nWrite the DataFrame to disk as csv (or whatever format you prefer) and save in a ./tests/data/ folder. At the start of your test modules you can read the data from disk and use it for testing. In this approach you’ll likely define the data as a test fixture in each of the test modules that need to work with it.\nDefine the fixtures within a special python file called conftest.py, which must be located at the root of your project. This file is used to configure your tests. pytest will look in this file for any required fixture definitions when executing your test suite. If it finds a fixture with the same name as that required by a test, the fixture code may be run.\n\n\n\n\n\n\n\nCaution\n\n\n\nWait! Did you just say ‘may be run’?\n\n\nDepending on the scope of your fixture, pytest may not need to execute the code for each test. For example, let’s say we’re working with a session-scoped fixture. This type of fixture will persist for the duration of the entire test suite execution. Imagine test number 1 and 10 both require this test fixture. The fixture definition only gets executed the first time a test requires it. This test fixture will be set up as test 1 executes and will persist until tear down occurs at the end of the pytest session. Test 10 will therefore use the same instance of this fixture as test 1 used, meaning any changes to the fixture may be carried forward.\n\n\nDefine fixtures\nFor our example, we will create a conftest.py file and define some fixtures with differing scopes.\n\n\nconftest.py\n\n\"\"\"Demonstrate scoping fixtures.\"\"\"\nimport pandas as pd\nimport pytest\n\n\n@pytest.fixture(scope=\"session\")\ndef _mystery_machine():\n    \"\"\"Session-scoped fixture returning pandas DataFrame.\"\"\"\n    return pd.DataFrame(\n        {\n            \"name\": [\"Daphne\", \"Fred\", \"Scooby Doo\", \"Shaggy\", \"Velma\"],\n            \"fave_food\": [\n                \"carrots\",\n                \"beans\",\n                \"scooby snacks\",\n                \"burgers\",\n                \"hot dogs\",\n            ],\n            \"has_munchies\": [True] * 5,\n            \"stomach_contents\": [\"empty\"] * 5,\n        }\n    )\n\n\n@pytest.fixture(scope=\"session\")\ndef _mm_session_scoped(_mystery_machine):\n    \"\"\"Session-scoped fixture returning the _mystery_machine DataFrame.\"\"\"\n    return _mystery_machine.copy(deep=True)\n\n\n@pytest.fixture(scope=\"module\")\ndef _mm_module_scoped(_mystery_machine):\n    \"\"\"Module-scoped _mystery_machine DataFrame.\"\"\"\n    return _mystery_machine.copy(deep=True)\n\n\n@pytest.fixture(scope=\"class\")\ndef _mm_class_scoped(_mystery_machine):\n    \"\"\"Class-scoped _mystery_machine DataFrame.\"\"\"\n    return _mystery_machine.copy(deep=True)\n\n\n@pytest.fixture(scope=\"function\")\ndef _mm_function_scoped(_mystery_machine):\n    \"\"\"Function-scoped _mystery_machine DataFrame.\"\"\"\n    return _mystery_machine.copy(deep=True)\n\nFixtures can reference each other, if they’re scoped correctly. More on this in the next section. This is useful for my toy example as I intend the source functions to update the DataFrames directly, if I wasn’t careful about deep copying the fixtures, my functions would update the original _mystery_machine fixture’s table. Those changes would then be subsequently passed to the other fixtures, meaning I couldn’t clearly demonstrate how the different scopes persist.\n\n\nDefine the source functions\nNow, let’s create a function that will feed characters their favourite food if they have the munchies.\n\n\nfeed_characters.py\n\n\"\"\"Helping learners understand how to work with pytest fixtures.\"\"\"\nimport pandas as pd\n\n\ndef serve_food(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Serve characters their desired food.\n\n    Iterates over a df, feeding characters if they have 'the munchies' with\n    their fave_food. If the character is not Scooby Doo or Shaggy, then update\n    their has_munchies status to False. The input df is modified inplace.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        A DataFrame with the following columns: \"name\": str, \"fave_food\": str,\n        \"has_munchies\": bool, \"stomach_contents\": str.\n\n    Returns\n    -------\n    pd.DataFrame\n        Updated DataFrame with new statuses for stomach_contents and\n        has_munchies.\n\n    \"\"\"\n    for ind, row in df.iterrows():\n        if row[\"has_munchies\"]:\n            # if character is hungry then feed them\n            food = row[\"fave_food\"]\n            character = row[\"name\"]\n            print(f\"Feeding {food} to {character}.\")\n            df.loc[ind, [\"stomach_contents\"]] = food\n            if character not in [\"Scooby Doo\", \"Shaggy\"]:\n                # Scooby & Shaggy are always hungry\n                df.loc[ind, \"has_munchies\"] = False\n        else:\n            # if not hungry then do not adjust\n            pass\n    return df\n\nNote that it is commonplace to copy a pandas DataFrame so that any operations carried out by the function are confined to the function’s scope. To demonstrate changes to the fixtures I will instead choose to edit the DataFrame inplace.\n\n\nFixtures Within a Single Test Module\nNow to write some tests. To use the fixtures we defined earlier, we simply declare that a test function requires the fixture. pytest will notice this dependency on collection, check the fixture scope and execute the fixture code if appropriate. The following test test_scopes_before_action checks that the mystery_machine fixtures all have the expected has_munchies column values at the outset of the test module, i.e. everybody is hungry before our source function takes some action. This type of test doesn’t check behaviour of any source code and therefore would be unnecessary for quality assurance purposes. But I include it here to demonstrate the simple use of fixtures and prove to the reader the state of the DataFrame fixtures prior to any source code intervention.\n\n\n\n\n\n\nTesting pandas DataFrames\n\n\n\n\n\nYou may notice that the assert statements in the tests below requires pulling column values out and casting to lists. The pandas package has its own testing module that is super useful for testing all aspects of DataFrames. Check out the pandas testing documentation for more on how to write robust tests for pandas DataFrames and Series.\n\n\n\n\n\ntest_feed_characters.py\n\n\"\"\"Testing pandas operations with test fixtures.\"\"\"\nfrom example_pkg.feed_characters import serve_food\n\n\ndef test_scopes_before_action(\n    _mm_session_scoped,\n    _mm_module_scoped,\n    _mm_class_scoped,\n    _mm_function_scoped,\n):\n    \"\"\"Assert that all characters have the munchies at the outset.\"\"\"\n    assert list(_mm_session_scoped[\"has_munchies\"].values) == [True] * 5, (\n        \"The session-scoped DataFrame 'has_munchies' column was not as \",\n        \"expected before any action was taken.\",\n    )\n    assert list(_mm_module_scoped[\"has_munchies\"].values) == [True] * 5, (\n        \"The module-scoped DataFrame 'has_munchies' column was not as \",\n        \"expected before any action was taken.\",\n    )\n    assert list(_mm_class_scoped[\"has_munchies\"].values) == [True] * 5, (\n        \"The class-scoped DataFrame 'has_munchies' column was not as \",\n        \"expected before any action was taken.\",\n    )\n    assert list(_mm_function_scoped[\"has_munchies\"].values) == [True] * 5, (\n        \"The function-scoped DataFrame 'has_munchies' column was not as \",\n        \"expected before any action was taken.\",\n    )\n\nNow to test the serve_food() function operates as expected. We can define a test class that will house all tests for serve_food(). Within that class let’s define our first test that simply checks that the value of the has_munchies column has been updated as we would expect after using the serve_food() function.\n\n\ntest_feed_characters.py\n\nclass TestServeFood:\n    \"\"\"Tests that serve_food() updates the 'has_munchies' column.\"\"\"\n\n    def test_serve_food_updates_df(\n        self,\n        _mm_session_scoped,\n        _mm_module_scoped,\n        _mm_class_scoped,\n        _mm_function_scoped,\n    ):\n        \"\"\"Test serve_food updates the has_munchies columns as expected.\n\n        This function will update each fixture in the same way, providing each\n        character with their favourite_food and updating the contents of their\n        stomach. The column we will assert against will be has_munchies, which\n        should be updated to False after feeding in all cases except for Scooby\n        Doo and Shaggy, who always have the munchies.\n        \"\"\"\n        # first lets check that the session-scoped dataframe gets updates\n        assert list(serve_food(_mm_session_scoped)[\"has_munchies\"].values) == [\n            False,\n            False,\n            True,\n            True,\n            False,\n        ], (\n            \"The `serve_food()` has not updated the session-scoped df\",\n            \" 'has_munchies' column as expected.\",\n        )\n        # next check the same for the module-scoped fixture\n        assert list(serve_food(_mm_module_scoped)[\"has_munchies\"].values) == [\n            False,\n            False,\n            True,\n            True,\n            False,\n        ], (\n            \"The `serve_food()` has not updated the module-scoped df\",\n            \" 'has_munchies' column as expected.\",\n        )\n        # Next check class-scoped fixture updates\n        assert list(serve_food(_mm_class_scoped)[\"has_munchies\"].values) == [\n            False,\n            False,\n            True,\n            True,\n            False,\n        ], (\n            \"The `serve_food()` has not updated the class-scoped df\",\n            \" 'has_munchies' column as expected.\",\n        )\n        # Finally check the function-scoped df does the same...\n        assert list(\n            serve_food(_mm_function_scoped)[\"has_munchies\"].values\n        ) == [\n            False,\n            False,\n            True,\n            True,\n            False,\n        ], (\n            \"The `serve_food()` has not updated the function-scoped df\",\n            \" 'has_munchies' column as expected.\",\n        )\n\nNotice that the test makes exactly the same assertion for every differently scoped fixture? In every instance, we have fed the characters in the mystery machine DataFrame and therefore everyone’s has_munchies status (apart from Scooby Doo and Shaggy’s) gets updated to False.\n\n\n\n\n\n\nParametrized Tests\n\n\n\n\n\nWriting the test out this way makes things explicit and easy to follow. However, you could make this test smaller by using a neat feature of the pytest package called parametrized tests. This is basically like applying conditions to your tests in a for loop. Perhaps you have a bunch of conditions to check, multiple DataFrames or whatever. These can be programmatically served with parametrized tests. While outside of the scope of this article, I intend to write a blog on this in the future.\n\n\n\nNext, we can add to the test class, including a new test that checks the state of the fixtures. At this point, we will start to see some differences due to scoping. The new test_expected_states_within_same_class() will assert that the changes to the fixtures brought about in the previous test test_serve_food_updates_df() will persist, except for the the case of _mm_function_scoped which will go through teardown at the end of every test function.\n\n\ntest_feed_characters.py\n\nclass TestServeFood:\n    \"\"\"Tests that serve_food() updates the 'has_munchies' column.\"\"\"\n    # ... (test_serve_food_updates_df)\n\n    def test_expected_states_within_same_class(\n        self,\n        _mm_session_scoped,\n        _mm_module_scoped,\n        _mm_class_scoped,\n        _mm_function_scoped,\n    ):\n        \"\"\"Test to ensure fixture states are as expected.\"\"\"\n        # Firstly, session-scoped changes should persist, only Scooby Doo &\n        # Shaggy should still have the munchies...\n        assert list(_mm_session_scoped[\"has_munchies\"].values) == [\n            False,\n            False,\n            True,\n            True,\n            False,\n        ], (\n            \"The changes to the session-scoped df 'has_munchies' column have\",\n            \" not persisted as expected.\",\n        )\n        # Secondly, module-scoped changes should persist, as was the case for\n        # the session-scope test above\n        assert list(_mm_module_scoped[\"has_munchies\"].values) == [\n            False,\n            False,\n            True,\n            True,\n            False,\n        ], (\n            \"The changes to the module-scoped df 'has_munchies' column have\",\n            \" not persisted as expected.\",\n        )\n        # Next, class-scoped changes should persist just the same\n        assert list(_mm_class_scoped[\"has_munchies\"].values) == [\n            False,\n            False,\n            True,\n            True,\n            False,\n        ], (\n            \"The changes to the class-scoped df 'has_munchies' column have\",\n            \" not persisted as expected.\",\n        )\n        # Finally, demonstrate that function-scoped fixture starts from scratch\n        # Therefore all characters should have the munchies all over again.\n        assert (\n            list(_mm_function_scoped[\"has_munchies\"].values) == [True] * 5\n        ), (\n            \"The function_scoped df 'has_munchies' column is not as expected.\",\n        )\n\nIn the above test, we assert that the function-scoped fixture values have the original fixture’s values. The function-scoped fixture goes through set-up again as test_expected_states_within_same_class is executed, ensuring a ‘fresh’, unchanged version of the fixture DataFrame is provided.\nWithin the same test module, we can add some other test class and make assertions about the fixtures. This new test will check whether the stomach_contents column of the module and class-scoped fixtures have been updated. Recall that the characters start out with \"empty\" stomach contents.\n\n\ntest_feed_characters.py\n\n\n# ... (TestServeFood)\n    # (test_serve_food_updates_df)\n    # (test_expected_states_within_same_class) ...\n\nclass TestSomeOtherTestClass:\n    \"\"\"Demonstrate persistence of changes to class-scoped fixture.\"\"\"\n\n    def test_whether_changes_to_stomach_contents_persist(\n        self, _mm_class_scoped, _mm_module_scoped\n    ):\n        \"\"\"Check the stomach_contents column.\"\"\"\n        assert list(_mm_module_scoped[\"stomach_contents\"].values) == [\n            \"carrots\",\n            \"beans\",\n            \"scooby snacks\",\n            \"burgers\",\n            \"hot dogs\",\n        ], \"Changes to module-scoped fixture have not propagated as expected.\"\n        assert (\n            list(_mm_class_scoped[\"stomach_contents\"].values) == [\"empty\"] * 5\n        ), \"Values in class-scoped fixture are not as expected\"\n\nIn this example, it is demonstrated that changes to the class-scoped fixture have been discarded. As test_whether_changes_to_stomach_contents_persist() exists within a new class called TestSomeOtherTestClass, the code for _mm_class_scoped has been executed again, providing the original DataFrame values.\n\nBalancing Isolation & Persistence\n\nWhile the persistence of fixtures may be useful for end to end tests, this approach reduces isolation in the test suite. Be aware that this may introduce a bit of friction to your pytest development process. For example, it can be commonplace to develop a new test and to check that it passes by invoking pytest with the keyword -k flag to run that single test (or subset of tests) only. This approach is useful if you have a costly test suite and you just want to examine changes in a single unit.\nAt the current state of the test module, executing the entire test module by running pytest ./tests/test_feed_characters.py will pass. However, running pytest -k \"TestSomeOtherTestClass\" will fail. This is because the assertions in TestSomeOtherTestClass rely on code being executed within the preceding test class. Tests in TestSomeOtherTestClass rely on changes elsewhere in your test suite and by definition are no longer unit tests. For those developers who work with pytest-randomly to help sniff out poorly-isolated tests, this approach could cause a bit of a headache.\nA good compromise would be to ensure that the use of fixture scopes other than function are isolated and clearly documented within a test suite. Thoughtful grouping of integration tests within test modules or classes can limit grief for collaborating developers. Even better would be to mark tests according to their scoped dependencies. This approach allows tests to be grouped and executed separately, though the implementation of this is beyond the scope of this article.\n\n\n\nFixtures Across Multiple Test Modules\nFinally in this section, we will explore fixture behaviour across more than one test module. Below I define a new source module with a function used to update the mystery_machine DataFrame. This function will update the fave_food column for a character if it has already eaten. This is meant to represent a character’s preference for a dessert following a main course. Once more, this function will not deep copy the input DataFrame but will allow inplace adjustment.\n\n\n\nupdate_food.py\n\n\"\"\"Helping learners understand how to work with pytest fixtures.\"\"\"\nimport pandas as pd\n\n\ndef fancy_dessert(\n    df: pd.DataFrame,\n    fave_desserts: dict = {\n        \"Daphne\": \"brownie\",\n        \"Fred\": \"ice cream\",\n        \"Scooby Doo\": \"apple crumble\",\n        \"Shaggy\": \"pudding\",\n        \"Velma\": \"banana bread\",\n    },\n) -&gt; pd.DataFrame:\n    \"\"\"Update a characters favourite_food to a dessert if they have eaten.\n\n    Iterates over a df, updating the fave_food value for a character if the\n    stomach_contents are not 'empty'.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        A dataframe with the following columns: \"name\": str, \"fave_food\": str,\n        \"has_munchies\": bool, \"stomach_contents\": str.\n    fave_desserts : dict, optional\n        A mapping of \"name\" to a replacement favourite_food, by default\n        { \"Daphne\": \"brownie\", \"Fred\": \"ice cream\",\n        \"Scooby Doo\": \"apple crumble\", \"Shaggy\": \"pudding\",\n        \"Velma\": \"banana bread\", }\n\n    Returns\n    -------\n    pd.DataFrame\n        Dataframe with updated fave_food values.\n\n    \"\"\"\n    for ind, row in df.iterrows():\n        if row[\"stomach_contents\"] != \"empty\":\n            # character has eaten, now they should prefer a dessert\n            character = row[\"name\"]\n            dessert = fave_desserts[character]\n            print(f\"{character} now wants {dessert}.\")\n            df.loc[ind, \"fave_food\"] = dessert\n        else:\n            # if not eaten, do not adjust\n            pass\n    return df\n\nNote that the condition required for fancy_dessert() to take action is that the contents of the character’s stomach_contents should be not equal to “empty”. Now to test this new src module, we create a new test module. We will run assertions of the fave_food columns against the differently-scoped fixtures.\n\n\ntest_update_food.py\n\n\"\"\"Testing pandas operations with test fixtures.\"\"\"\nfrom example_pkg.update_food import fancy_dessert\n\n\nclass TestFancyDessert:\n    \"\"\"Tests for fancy_dessert().\"\"\"\n\n    def test_fancy_dessert_updates_fixtures_as_expected(\n        self,\n        _mm_session_scoped,\n        _mm_module_scoped,\n        _mm_class_scoped,\n        _mm_function_scoped,\n    ):\n        \"\"\"Test fancy_dessert() changes favourite_food values to dessert.\n\n        These assertions depend on the current state of the scoped fixtures. If\n        changes performed in\n        test_feed_characters::TestServeFood::test_serve_food_updates_df()\n        persist, then characters will not have empty stomach_contents,\n        resulting in a switch of their favourite_food to dessert.\n        \"\"\"\n        # first, check update_food() with the session-scoped fixture.\n        assert list(fancy_dessert(_mm_session_scoped)[\"fave_food\"].values) == [\n            \"brownie\",\n            \"ice cream\",\n            \"apple crumble\",\n            \"pudding\",\n            \"banana bread\",\n        ], (\n            \"The changes to the session-scoped df 'stomach_contents' column\",\n            \" have not persisted as expected.\",\n        )\n        # next, check update_food() with the module-scoped fixture.\n        assert list(fancy_dessert(_mm_module_scoped)[\"fave_food\"].values) == [\n            \"carrots\",\n            \"beans\",\n            \"scooby snacks\",\n            \"burgers\",\n            \"hot dogs\",\n        ], (\n            \"The module-scoped df 'stomach_contents' column was not as\",\n            \" expected\",\n        )\n        # now, check update_food() with the class-scoped fixture. Note that we\n        # are now making assertions about changes from a different class.\n        assert list(fancy_dessert(_mm_class_scoped)[\"fave_food\"].values) == [\n            \"carrots\",\n            \"beans\",\n            \"scooby snacks\",\n            \"burgers\",\n            \"hot dogs\",\n        ], (\n            \"The class-scoped df 'stomach_contents' column was not as\",\n            \" expected\",\n        )\n        # Finally, check update_food() with the function-scoped fixture. As\n        # in TestServeFood::test_expected_states_within_same_class(), the\n        # function-scoped fixture starts from scratch.\n        assert list(\n            fancy_dessert(_mm_function_scoped)[\"fave_food\"].values\n        ) == [\"carrots\", \"beans\", \"scooby snacks\", \"burgers\", \"hot dogs\"], (\n            \"The function-scoped df 'stomach_contents' column was not as\",\n            \" expected\",\n        )\n\nNote that the only fixture expected to have been adjusted by update_food() is _mm_session_scoped. When running the pytest command, changes from executing the first test module test_feed_characters.py propagate for this fixture only. All other fixture scopes used will go through teardown and then setup once more on execution of the second test module.\nThis arrangement is highly dependent on the order of which the test modules are collected. pytest collects tests in alphabetical ordering by default, and as such test_update_food.py can be expected to be executed after test_feed_characters.py. This test module is highly dependent upon the order of the pytest execution. This makes the tests less portable and means that running the test module with pytest tests/test_update_food.py in isolation would fail. I would once more suggest using pytest marks to group these types of tests and execute them separately to the rest of the test suite."
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html#scopemismatch-error",
    "href": "blogs/11-fiddly-bits-of-pytest.html#scopemismatch-error",
    "title": "Pytest Fixtures in Plain English",
    "section": "ScopeMismatch Error",
    "text": "ScopeMismatch Error\nWhen working with pytest fixtures, occasionally you will encounter a ScopeMismatch exception. This may happen when attempting to use certain pytest plug-ins or perhaps if trying to use temporary directory fixtures like tmp_path with fixtures that are scoped differently to function-scope. Occasionally, you may encounter this exception when attempting to reference your own fixture in other fixtures, as was done with the mystery_machine fixture above.\nThe reason for ScopeMismatch is straightforward. Fixture scopes have a hierarchy, based on their persistence:\n\nfunction &lt; class &lt; module &lt; package &lt; session\n\nFixtures with a greater scope in the hierarchy are not permitted to reference those lower in the hierarchy. The way I remember this rule is that:\n\nFixtures must only reference equal or greater scopes.\n\nIt is unclear why this rule has been implemented other than to reduce complexity (which is reason enough in my book). There was talk about implementing scope=\"any\" some time ago, but it looks like this idea was abandoned. To reproduce the error:\n\n\ntest_bad_scoping.py\n\n\"\"\"Demomstrate ScopeMismatch error.\"\"\"\n\nimport pytest\n\n@pytest.fixture(scope=\"function\")\ndef _fix_a():\n    return 1\n\n@pytest.fixture(scope=\"class\")\ndef _fix_b(_fix_a):\n    return _fix_a + _fix_a\n\n\ndef test__fix_b_return_val(_fix_b):\n    assert _fix_b == 2\n\nExecuting this test module results in:\n================================= ERRORS ======================================\n________________ ERROR at setup of test__fix_b_return_val _____________________\nScopeMismatch: You tried to access the function scoped fixture _fix_a with a\nclass scoped request object, involved factories:\ntests/test_bad_scoping.py:9:  def _fix_b(_fix_a)\ntests/test_bad_scoping.py:5:  def _fix_a()\n========================== short test summary info ============================\nERROR tests/test_bad_scoping.py::test__fix_b_return_val - Failed:\nScopeMismatch: You tried to access the function scoped fixture _fix_a with a\nclass scoped request object, involved factories:\n=========================== 1 error in 0.01s ==================================\nThis error can be avoided by adjusting the fixture scopes to adhere to the hierarchy rule, so updating _fix_a to use a class scope or greater would result in a passing test."
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html#summary",
    "href": "blogs/11-fiddly-bits-of-pytest.html#summary",
    "title": "Pytest Fixtures in Plain English",
    "section": "Summary",
    "text": "Summary\nHopefully by now you feel comfortable in when and how to use fixtures for pytest. We’ve covered quite a bit, including:\n\nWhat fixtures are\nUse-cases\nWhere to store them\nHow to reference them\nHow to scope them\nHow changes to fixtures persist or not\nHandling scope errors\n\nIf you spot an error with this article, or have suggested improvement then feel free to raise an issue on GitHub.\nHappy testing!"
  },
  {
    "objectID": "blogs/11-fiddly-bits-of-pytest.html#acknowledgements",
    "href": "blogs/11-fiddly-bits-of-pytest.html#acknowledgements",
    "title": "Pytest Fixtures in Plain English",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo past and present colleagues who have helped to discuss pros and cons, establishing practice and firming-up some opinions. Particularly:\n\nClara\nDan C\nDan S\nEdward\nEthan\nHenry\nIan\nIva\nJay\nMark\nMartin R\nMartin W\nMat\nSergio\n\n\nfin!"
  },
  {
    "objectID": "blogs/01-state-of-pyshiny.html",
    "href": "blogs/01-state-of-pyshiny.html",
    "title": "The State of Python Shiny",
    "section": "",
    "text": "DALL.E prompt: python logo golden Sparkling glittery bokeh bright.\n\n\nPython Shiny celebrates its first year anniversary on PyPi in July 2023. In case that needs further qualification, this is the Python-native implementation of the beloved RShiny dashboarding package that has been available in the R programming framework for over a decade now. Python Shiny has benefited from the experience that the developers at Posit have gained in building its more mature, R-flavoured sibling.\nPython Shiny has experienced what I would describe as an accelerated evolution and has the potential to become a front runner in production-grade applications. Mainly because it adheres to an evaluation strategy which is a bit ‘un-pythonic’. Shiny introduces dashboarding with lazy evaluation, meaning that elements of your code will only be evaluated when there is a need to do so. This is not always a great idea, particularly for standard scripting purposes. But it does make event-driven applications more efficient and scalable. More on Posit’s take on the USP of Python Shiny here.\nLet’s consider the following example in Python:\n\n# In Python\ntry:\n  def failing_print(param_a=\"Am I lazy?\", param_b=absolutely_not):\n    print(param_a)\nexcept NameError:\n  print(\"Python would not allow me to define this function.\")\n\nPython would not allow me to define this function.\n\n\nStrict (also known as eager) evaluation in Python has triggered an error. I’ve had to catch the error above with the try/except clause in order to render this website. Even though failing_print() never calls on param_b, Python checks that the default value of that parameter exists on definition of the function.\nLet us now compare the situation in R.\n\n# In R\npassing_print &lt;- function(param_a = \"Am I lazy?\", param_b = yes_you_are){\n  print(param_a)\n}\nprint(paste(\"Does `yes_you_are` exist? : \", exists(\"yes_you_are\")))\n\n[1] \"Does `yes_you_are` exist? :  FALSE\"\n\npassing_print()\n\n[1] \"Am I lazy?\"\n\n\nNo exception was raised although the value yes_you_are has not been defined.\nLazy evaluation in Python Shiny minimises the work the application needs to undertake. Values in the app backend will only be re-evaluated as they are needed and contrasts with more pythonic approaches to dashboarding, such as the case with the streamlit package."
  },
  {
    "objectID": "blogs/01-state-of-pyshiny.html#python-for-shiny-is-now-a-thing",
    "href": "blogs/01-state-of-pyshiny.html#python-for-shiny-is-now-a-thing",
    "title": "The State of Python Shiny",
    "section": "",
    "text": "DALL.E prompt: python logo golden Sparkling glittery bokeh bright.\n\n\nPython Shiny celebrates its first year anniversary on PyPi in July 2023. In case that needs further qualification, this is the Python-native implementation of the beloved RShiny dashboarding package that has been available in the R programming framework for over a decade now. Python Shiny has benefited from the experience that the developers at Posit have gained in building its more mature, R-flavoured sibling.\nPython Shiny has experienced what I would describe as an accelerated evolution and has the potential to become a front runner in production-grade applications. Mainly because it adheres to an evaluation strategy which is a bit ‘un-pythonic’. Shiny introduces dashboarding with lazy evaluation, meaning that elements of your code will only be evaluated when there is a need to do so. This is not always a great idea, particularly for standard scripting purposes. But it does make event-driven applications more efficient and scalable. More on Posit’s take on the USP of Python Shiny here.\nLet’s consider the following example in Python:\n\n# In Python\ntry:\n  def failing_print(param_a=\"Am I lazy?\", param_b=absolutely_not):\n    print(param_a)\nexcept NameError:\n  print(\"Python would not allow me to define this function.\")\n\nPython would not allow me to define this function.\n\n\nStrict (also known as eager) evaluation in Python has triggered an error. I’ve had to catch the error above with the try/except clause in order to render this website. Even though failing_print() never calls on param_b, Python checks that the default value of that parameter exists on definition of the function.\nLet us now compare the situation in R.\n\n# In R\npassing_print &lt;- function(param_a = \"Am I lazy?\", param_b = yes_you_are){\n  print(param_a)\n}\nprint(paste(\"Does `yes_you_are` exist? : \", exists(\"yes_you_are\")))\n\n[1] \"Does `yes_you_are` exist? :  FALSE\"\n\npassing_print()\n\n[1] \"Am I lazy?\"\n\n\nNo exception was raised although the value yes_you_are has not been defined.\nLazy evaluation in Python Shiny minimises the work the application needs to undertake. Values in the app backend will only be re-evaluated as they are needed and contrasts with more pythonic approaches to dashboarding, such as the case with the streamlit package."
  },
  {
    "objectID": "blogs/01-state-of-pyshiny.html#an-example-python-shiny-app.",
    "href": "blogs/01-state-of-pyshiny.html#an-example-python-shiny-app.",
    "title": "The State of Python Shiny",
    "section": "An Example Python Shiny App.",
    "text": "An Example Python Shiny App.\nThis application is written in Python and served with a free shinyapps.io account. I made the app to explore the quality of the spatial data available within OpenStreetMap (OSM) data for certain urban areas. OSM is an open-source, community-maintained source of transport network data. The files also contain other spatial features, such as land use polygons. The quality of this data varies by location, as you may find in the app.\nThe application is pretty straightforward. It uses pandas to read in some pre-prepared data tables from a data folder. These files were prepared with a python package called pyrosm. Pyrosm is a useful application for ingesting, assessing & visualising OSM data. Selecting a city from the dropdowns then clicking the “Go” button will read the correct table from this little database, then using matplotlib, it visualises the selected spatial features. The app also presents some simple summary statistics in tables at the bottom of the page.\nThe preparation of the data files is not strictly necessary. You can serve an app and have it make external connections to data services to ingest data. In this instance, I chose to pre-process the data as it helped to improve the performance of the app. Even so, selecting London or Leeds can result in some wait times, so please be aware of this. Options for improving the performance further could include parallel processing, though that is not implemented here and is beyond the scope of this little example.\nIf you’d like to take a look at the application code and have a GitHub account, you can access it here."
  },
  {
    "objectID": "blogs/01-state-of-pyshiny.html#so-what-does-a-shiny-project-look-like",
    "href": "blogs/01-state-of-pyshiny.html#so-what-does-a-shiny-project-look-like",
    "title": "The State of Python Shiny",
    "section": "So What Does a Shiny Project Look Like?",
    "text": "So What Does a Shiny Project Look Like?\n\nOrganising a Shiny Project.\nBelow is a directory tree diagram of the example Shiny application presented above. It shows the file structure in the various folders.\n.\n├── 01-update-db.py\n├── app.py\n├── config\n│   └── 01-update-db.toml\n├── data\n│   ├── leeds-landuse-2023-06-19.arrow\n│   ├── leeds-natural-2023-06-19.arrow\n│   ├── leeds-net-driving-2023-06-19.arrow\n│   ├── london-landuse-2023-06-19.arrow\n│   ├── london-natural-2023-06-19.arrow\n│   ├── london-net-driving-2023-06-19.arrow\n│   ├── marseille-landuse-2023-06-19.arrow\n│   ├── marseille-natural-2023-06-19.arrow\n│   ├── marseille-net-driving-2023-06-19.arrow\n│   ├── newport-landuse-2023-06-19.arrow\n│   ├── newport-natural-2023-06-19.arrow\n│   └── newport-net-driving-2023-06-19.arrow\n├── requirements.txt\n└── rsconnect-python\n    └── pyrosm-cities-app.json\nThe Shiny code that generates the application is in app.py. The data folder is where you put any data files you’d like to work with. Here I’m working with the .arrow format (More on that here). However, this folder could be used to store csvs, images, a GeoJSON database, whatever your application needs.\nThe file 01-update-db.py and the contents of the config folder are related. The python script is used to update the database in the data folder. This part of the workflow can be quite time consuming, particularly extracting the transport network from dense areas such as Greater London. In order to improve the performance of the app, I chose to pre-prepare this data and limit the number of areas to my specific use-case. A previous iteration of this dashboard simply sent requests using the python pyrosm package to get data for any valid area name. The TOML file in the config folder simply stores some parameters used to configure 01-update-db.py, such as named areas of interest, bounding box coordinates in order to crop the maps, that sort of thing. The requirements.txt file is super important. Not only will it help others to re-run your dashboard with the required package dependencies made explicit, this is also a file that hosting services such as shinyapps.io will use to recreate your development environment. More on that later.\n\n\n\n\n\n\nTip\n\n\n\nEnsuring that you have ‘pinned’ each package version in your requirements file will make publishing to a hosting service such as shinyapps.io a lot easier. It can be frustrating to push your locally working application up to a remote service, waiting for a potentially lengthy deployment routine to complete only to see that your app breaks as you’re working on a different version of numpy than the one available by default in the remote server.\n\n\nFinally, the rsconnect-python directory is not something that would appear in your Shiny project until you deploy it to a remote-hosting service like shinyapps.io. It contains some metadata about your application which the remote service will use to set up your app properly.\n\n\nA Closer Look at app.py.\nAs stated earlier, this is where your app code goes. But before diving straight into some code, let’s try to get a feel for how the reactivity works.\n\n\n\n\n\n\nflowchart TD\n  user[\"User\"]\n  subgraph Application\n  server[\"Server\n  - Executes python code.\n  - Processes data.\n  - Translates outputs into HTML.\n  \"]\n  ui[\"User Interface\n  - Displays input widgets.\n  - Displays rendered server outputs.\n  - Can be adjusted with HTML & CSS.\"]\n  db[(\"Data\")]\n  end\n  user --&gt;|Input Values| ui &lt;--&gt;|Dynamic Values| server\n  db --&gt;|Read| server\n\nlinkStyle default stroke-width:1px,color:blue;\n\n\n\n\n\n\n\n\n\nEach Shiny application comes in two distinct sections. The user interface is the frontend of the application, where a person engages with elements of a web page in order to control visuals, filter tables and so on. The web page translates Python code into HyperText Markup Language (HTML). HTML can be interpreted by a web browser in order to present the user with a structured web page. But in order to present an attractive web page, this HTML foundation needs to be styled. So Cascading Style Sheets (CSS) are used to add decoration to the foundation established by HTML.\n\n\nServer-Side Shenanigans.\nHaving an attractive web page that does not do something when you click around on it, enter your credit card details or click ‘decline’ on cookie consent notices would be rather pointless. This is where a web developer would use the language of the browser to work with data behind that pretty frontend. That language is JavaScript and it’s remarkably versatile and intimidating to many data-types.\nSo to make a functioning app, you need to learn 3 distinct languages. For this reason, packages such as Shiny, Dash and Streamlit have become very popular with analysts working within open-source programming frameworks such as Python and R. They allow the creation of applications while adhering to the syntax that an analyst would be more familiar with. Abstracting all that front-end know-how behind some very straightforward Python code allows the analyst to focus their efforts on the parts of their job that they excel in - gaining insight from data.\nThere would be little value in emulating the excellent Posit documentation on getting started with Python Shiny. To do that, I suggest using their docs. In combination with the examples provided, a comprehensive introduction to Shiny is readily available. In the next section, I will focus on introducing a minimal application and then expanding on some of the more subtle considerations in the reactive flow of the backend. I’ll choose to focus on things where I’ve needed to learn by trial and error, or by searching the Stack Overflow boards through some of the inevitable roadblocks a person encounters when programming dashboards. I’ll throw in some common ‘gotchas’ for good measure.\nThe fastest way to get up and running with Python Shiny would be to play with the interactive code snippets that Posit makes available on their overview documentation. They host live Shiny sessions with the interactive app and backend code side-by-side. This is a great place to try things out and feel free to copy code from the examples I provide here."
  },
  {
    "objectID": "blogs/01-state-of-pyshiny.html#python-shiny-ecosystem.",
    "href": "blogs/01-state-of-pyshiny.html#python-shiny-ecosystem.",
    "title": "The State of Python Shiny",
    "section": "Python Shiny Ecosystem.",
    "text": "Python Shiny Ecosystem.\nThe success of Python Shiny will be down to the adoption & support of the open-source community. This was easier to achieve 10 years ago in the R framework as Shiny had no real competitors at that time. This is not the case in the modern-day Python framework. Even with its particular USP in comparison to Streamlit & Dash, programmers and analysts are creatures of habit. Considering the new player on the block as an alternative to what you already know requires a considerable argument. There will always be overhead in developing familiarity with a new solution’s particular quirks. That said, some of the community-developed packages in the more mature RShiny make building apps at scale very manageable. This final section of this blog takes a look at what Python Shiny bolt-ons we can already play with and a more wistful look over the programming divide at RShiny, considering some of the amazing packages that make me hopeful for the potential future of Python Shiny.\n\nWhat We Already Have.\n\nCompatibility With Jupyter Widgets.\nJupyter Widgets is a well-known add-in for Jupyter Notebooks, allowing for interactive widgets to be displayed and used in Notebooks. This allows for some interesting mini-dashboard opportunities to be served directly within the notebook itself, alongside the code. Having this compatibility from the start is great. While it does introduce a little duplication (Python Shiny has many of its own equivalent ui input widgets), the particular look and range of these widgets will be appealing to many seasoned Python devs. Many of the Jupyter Widget aficionados would have previously developed the capability in specifying callback logic, to be able to capture the user’s interactions with elements of the widget. For example, select a category in a table and use that active selection to filter a chart, the sort of thing that tends to be more prevalent in Business Insight software. Achieving this sort of interaction in Shiny definitely falls under ‘advanced use’. In R, the package crosstalk has significantly lowered the bar in achieving this. Hopefully a dedicated Python Shiny module or package makes its way to PyPi soon.\n\n\nDeploying An App With rsconnect-python.\nThis package is a useful command line interface (CLI) tool that allows you to build application manifests from your Shiny project and deploy them to services such as shinyapps.io. Once you’re ready to share an app with the wider community, check out the docs.\n\n\nModular Dashboards (Shiny Modules).\nThis aspect of Shiny dashboarding is a bit meta. Essentially, when you (or your organisation) gets to a point that they have enough dashboards to be concerned with thinking about consistency and efficiency, take a read through the Python Shiny Modules docs. This is a way of reusing elements of your dashboard, much in the same way in which you reuse code by writing a function. Maybe your organisation has really committed to Shiny and has developed a beautifully-styled interface with house branding, or some interface component such as an Email field with some complex regular expression checking the validity of the Email address. There really is no need to copy-paste that code when you want to use it again. Package the element up as a Shiny Module and you can roll out this feature across multiple dashboards, secure in the knowledge that the quality of this module has already been agreed. Responsibility successfully deferred!\n\n\n\n\n\n\nCode reuse is the Holy Grail of Software Engineering — Douglas Crockford\n\n\n\nThe fact that Python Shiny devs have prioritised modular dashboarding so early is great. It illustrates a commitment to reproducibility that is rightly lauded within the open source community. Just to note that the ability to do this in RShiny took approximately 3 years. Python users are quite spoiled to be able to make use of this feature from the outset.\n\n\n\nWhat I Really Want.\nWhile I feel generally positive about the future of Python Shiny, I do look across the gulf that exists between the Python and R frameworks with hungry eyes. Particularly at the rich, community-driven plethora of RShiny add-ins that make Shiny the undeniable dashboarding front-runner in that framework. Here is my wish-list of Python Shiny helper tools, ranked order (opinionated warning).\n\n1. Reactlog.\n\n\n\nThere’s no 2 ways about it, debugging apps is a royal pain. One of my go to helpers in times of need is Posit’s own reactlog package. Reactlog is such an understated tool, yet it has been crucial to me in understanding what’s going on under the hood of my apps. So much so, that I now feel hopelessly exposed when writing apps in Python without it to lean on.\n\n\n\nThis package allows you to launch an app, showing you useful insights about the performance and reactive flow of your app. It’s an app inception. It can be used in a variety of modes, you can record yourself clicking away on your app and then pause the interface to inspect variable statuses. Reactlog visualises the dependency graph of variables in your server and really is an indispensable debugging tool.\n\n\n2. Shinytest.\nUnit tests for your RShiny app anyone? Authored by the ubiquitous Hadley Wickham, shinytest allows you to make assertions about the behaviour of your application. In combination with the ability to design Shiny modules, this is a key piece of the RShiny toolkit allowing for the design of stable, production-ready Shiny components.\n\n\n3. DT Data Tables.\nAnother one of Posit’s own packages, DT helps to create beautiful, customisable and interactive data tables for the presentation of tables. Not just for RShiny applications, DT is also widely used in Rmarkdown reports. A dedicated Python Shiny solution would be most welcome.\n\n\n4. Shinyhelper.\nThe shinyhelper package developed by Chris Mason-Thom is an excellent solution for those involved applications that need a little more guidance for the user.\n\n\n\nShinyhelper allows the developer to include markdown files with extensive instructions, images and gif animations of how to use your application. These documents will be hidden from the screen until the user chooses to click on the help icons that shinyhelper provides. These help icons can be easily styled and positioned around any element within your ui. Once clicked, they will launch modal windows with your beautifully formatted instructions, allowing a wealth of guidance to be included within your app without causing excessive clutter.\nTry clicking through the different helper symbols in the demo RShiny application below."
  },
  {
    "objectID": "blogs/01-state-of-pyshiny.html#in-review.",
    "href": "blogs/01-state-of-pyshiny.html#in-review.",
    "title": "The State of Python Shiny",
    "section": "In Review.",
    "text": "In Review.\nPython Shiny is a promising addition to the Python programming framework. It has a USP, and Posit have the know-how to apply the learning from their past development of RShiny to help ensure it has a bright future. It is also worth noting that Posit have recently put a lot of effort into developing Quarto, which you may think of as like Rmarkdown but with native Python, R and Julia support. The reason why this is important is that often, interactive widgets and solutions designed for use in notebooks or markdown documents take little refactoring to get them running in Shiny apps. Or conversely, there are ways to convert rmarkdown docs into Shiny or Shiny-like applications. Understanding the synergies between these tools and how they have influenced the evolution of RShiny may give some insight into how we may expect Python Shiny & Quarto to develop in the years ahead.\nThe Python community is well-served by dashboarding solutions which will affect its wider adoption. If you are newer to dashboarding, or if you are looking for a solution that perhaps scales better than some of the other options available in the Python framework, then consider Python Shiny. It’s already pretty great and will only get better as the community warms to this new tool in the Python toolkit."
  },
  {
    "objectID": "music-reviews/02-zelda-and-chill.html",
    "href": "music-reviews/02-zelda-and-chill.html",
    "title": "Zelda & Chill",
    "section": "",
    "text": "Nintendo’s Zelda series likely needs no introduction. In its fourth decade and one of the most successful adventure series in video games, Zelda is beloved for its sense of innovation.\nThe music of the games has often been at the core of establishing its identity and; at times; has played a key construct in the games’ development. The N64 batch of games adopted a core game mechanic where the ability to accurately play songs on an instrument called an ocarina triggered key plot events such as travelling through time. Perhaps due to this, many of the tracks here are from this period of Zelda’s history."
  },
  {
    "objectID": "music-reviews/02-zelda-and-chill.html#introduction",
    "href": "music-reviews/02-zelda-and-chill.html#introduction",
    "title": "Zelda & Chill",
    "section": "",
    "text": "Nintendo’s Zelda series likely needs no introduction. In its fourth decade and one of the most successful adventure series in video games, Zelda is beloved for its sense of innovation.\nThe music of the games has often been at the core of establishing its identity and; at times; has played a key construct in the games’ development. The N64 batch of games adopted a core game mechanic where the ability to accurately play songs on an instrument called an ocarina triggered key plot events such as travelling through time. Perhaps due to this, many of the tracks here are from this period of Zelda’s history."
  },
  {
    "objectID": "music-reviews/02-zelda-and-chill.html#songs-for-the-recovering-adventurers",
    "href": "music-reviews/02-zelda-and-chill.html#songs-for-the-recovering-adventurers",
    "title": "Zelda & Chill",
    "section": "Songs for the Recovering Adventurers",
    "text": "Songs for the Recovering Adventurers\nZelda & Chill is a love note to the iconic music produced by the Zelda developers. As a casual fan, I have enjoyed many of the games in the series and the album manages to prod the nostalgia sensor in my brain even after multiple playthroughs. But for those disinterested in video games, this album is great for drowning out the outside world and establishing the focus needed for deep work.\n\n\n Let’s take a look at the audio feature analysis for this album. For a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature.\n\n\n\nI find it surprising that there is such a wide distribution in the valence of the songs. I expected the album to be distributed centrally as the pace and tone of the music is generally understated. But there are a couple of tracks that strike a more melancholy tone, such as Dark World and Gerudo Valley. At the other end of the scale, the Legend of Zelda theme is likely the most positive on offer, helping to explain why a broad distribution of valence is observed. The album’s speechiness and instrumentalness score as you’d expect. Danceability is notably high, potentially as a result of the crunchy drum & bass lines present in all the songs. Acousticness is generally low throughout the tracks though with a broad distribution that is potentially influenced by recurring use of piano and string sections. Perhaps the most interesting feature for this album is energy, which describes the album as distinctly middle-of-the-road in terms of intensity. As a chill album you’d likely expect a lower energy but the strong rhythm section likely lifts the distribution of this feature."
  },
  {
    "objectID": "music-reviews/02-zelda-and-chill.html#the-tracks",
    "href": "music-reviews/02-zelda-and-chill.html#the-tracks",
    "title": "Zelda & Chill",
    "section": "The Tracks",
    "text": "The Tracks\nBelow are the mean audio feature values for each track. The last row (green) presents a mean summary of the album.\n\n\n\n\n\ntrack_name\ndanceability\nenergy\nspeechiness\nacousticness\ninstrumentalness\nvalence\n\n\n\n\nFairy Fountain\n0.6710000\n0.5250000\n0.0506000\n0.4040000\n0.924\n0.2830000\n\n\nDark World\n0.6700000\n0.3380000\n0.0569000\n0.4400000\n0.864\n0.5620000\n\n\nLost Woods\n0.7150000\n0.5440000\n0.0513000\n0.0895000\n0.935\n0.9080000\n\n\nSong of Storms\n0.6750000\n0.4580000\n0.0305000\n0.0181000\n0.889\n0.4790000\n\n\nMinuet of Forest\n0.7910000\n0.4820000\n0.0434000\n0.1750000\n0.857\n0.6980000\n\n\nGerudo Valley\n0.8430000\n0.4340000\n0.0844000\n0.4400000\n0.832\n0.1670000\n\n\nOath to Order\n0.7830000\n0.4640000\n0.1500000\n0.7480000\n0.805\n0.2200000\n\n\nDragon Roost Island\n0.7730000\n0.2450000\n0.0582000\n0.2530000\n0.932\n0.5530000\n\n\nKakariko Village\n0.7110000\n0.4330000\n0.1990000\n0.4520000\n0.905\n0.6260000\n\n\nBallad of the Goddess\n0.7590000\n0.4100000\n0.0595000\n0.0061500\n0.821\n0.3540000\n\n\nBreath of the Wild\n0.5410000\n0.4050000\n0.0418000\n0.0471000\n0.840\n0.0387000\n\n\nHateno Village\n0.7600000\n0.3470000\n0.0337000\n0.3430000\n0.689\n0.3940000\n\n\nLegend of Zelda\n0.5210000\n0.6270000\n0.0265000\n0.2510000\n0.847\n0.7260000\n\n\nOcarina of Time\n0.6440000\n0.4870000\n0.0419000\n0.1540000\n0.858\n0.2450000\n\n\nAlbum Mean\n0.7040714\n0.4427857\n0.0662643\n0.2729179\n0.857\n0.4466929\n\n\n\n\n\n\n\nFairy Fountain\n64-bit nostalgia ahead. While the Fairy Fountain has offered sanctuary to any daring adventurer donning the guise of Link throughout the entire Zelda series, this theme is synonymous with the N64’s Ocarina of Time. This rendition is a wonderful, crunchy production over a stripped-back ragtime tempo. Warm feelings of safe havens are immediately conjured from the outset, with that iconic dreamy harp intro. A strong start to the album that sets the mood for what’s to come.\nDark world\nFor those Zelda fans who can identify with A Link to the Past, this track may hold more significance. I have not played that game and checking out the original track, I’d say this version seems like a marked improvement. There’s a fascinating contrast in this song - the meaty bass forms the perfect foil to the high pitch tubular bell-effect hook.\nLost Woods\nAnother one for the Ocarina of Time fans. A slower tempo than theoriginal, hence the “Relax” in the album title. There’s a curious reverb effect at play that sounds a bit like a harpsichord fed through a tin can. After listening to quite a bit of lofi I am on board with this, but I could see that it may be an acquired taste for some. Against the light and airy melody, the low-tech production works really well.\nSong of Storms\nFamiliar to those wishing to summon rain in Ocarina of Time, this laid back rendition is mixed with a loop of the cooking theme from Breath of the Wild, replete with periodic pot whistles & cutlery clanking against china. The creative flair on show as the looped Song of Storms theme builds to a modest crescendo (it’s chill after all) makes this one of my album highlights.\nMinuet of Forest\nThis song was originally used in Ocarina of Time to warp characters back to the start of the lost woods play area - one of the more challenging areas in the early game. The artists have expertly built on what was a very brief movement in the original material, adding a bouncy low-end bass while keeping the track structured with a snappy drum section.\nGerudo Valley\nAnother Ocarina of Time offering here. The original Gerudo Valley theme was played on Spanish guitar in a flamenco-style with a high tempo. This rendition is nearly unrecognisable and undoubtedly brilliant. How the artist has isolated the key movements and set them against the slow, chuffing rhythm is quite amazing. The song is one of the more melancholy tunes and while lower in mood is undoubtedly beautiful.\nOath to Order\nThis song originally appeared in Majora’s Mask and was used as a plot construct in that game - apparently to summon giants. I have little association with Majora’s Mask and having listened to it, I fail to identify the musical connection with the source material. Someone with a greater familiarity would potentially find more to identify with. As a standalone piece, Oath to Order is a very warm-sounding, fuzzy sensation with a warbly theremin effect permeating throughout for a unique twist.\nDragon Roost Island\nIt’s great to have a theme from the Windwaker on the album, which in my opinion is one of the best Zelda games and is often overlooked for its cute exterior. The original track was distinctly latin with Spanish guitar, maracas and a forlorn panpipe high in the mix. As in Gerudo Valley, the artists have slowed the pace while emphasising the main movement in the original source material. The guitars have been replaced with warm, fuzzy piano for a more relaxed atmosphere.\nKakariko Village\nKakariko Village has made recurring appearances throughout the Zelda series of games and I have struggled to identify which version of the series soundtracks this song takes its inspiration from. Though the melody is very distinct and the track is another of my album highlights. I presume it must be from one of the games I am less familiar with. A light and plucky lick against a bright and bouncy bassline, there’s plenty to appreciate here.\nBallad of the Goddess\nAnother recurring song in the later games within the Zelda series, I find it a very enjoyable rendition despite my lack of familiarity with the source material. The song seems to originate from Skyward Sword, building upon the melody using sweet harp strings and later a dramatic orchestral accompaniment. In this version, the artist has retained the harp but has worked with piano for the main melody.\nBreath of the Wild\nTaking its inspiration from the main theme of Breath of the Wild which perhaps lacks a distinctive identity in my opinion, this song starts with a promising loop of one of its more recognisable movements. However, mid-way through the song it introduces some distinctly discordant keys that introduce a sort of dilapidated fairground motif to the song. This is one that I tend to skip for those reasons - I find it hard to concentrate on my work with discordant sound in my ears. I view the track as an experiment and not in keeping with the rest of the album.\nHateno Village\nAnother Breath of the Wild arrangement, Hateno Village is notably home to the Ancient Tech Lab - an important site for acquiring gear upgrades as the game progresses. In this rendition of the theme, the artists have retained some deep bass strings although the main melody is now expertly played on piano. Again, I feel that the original material is not the strongest explored in this album, while the reimagining on offer here is perhaps more interesting than the source material.\nLegend of Zelda\nMaybe the most iconic video theme of all time. This mix pays homage to the series’ 8-bit roots by experimenting with a chiptune style that does a great job of not getting skipped while I work - chiptune can be fun but not generally for concentration. One of the more moving songs on offer, this track builds to a crescendo replete with choral and piano arrangements, leaving the listener with a distinct sense of grandeur capturing the scale of the video games.\nOcarina of Time\nThe theme from the original N64 Zelda title is a fitting end to this fantastic homage to perhaps one of the greatest video game adventure series. Kids of my generation will recall this iconic track as it accompanied the Ocarina of Time intro. The intro that blew the minds of a generation of Zelda fans who got to see Link in 3D and on horseback in an amazing open world like never before. Great times."
  },
  {
    "objectID": "music-reviews/02-zelda-and-chill.html#highs-and-lows",
    "href": "music-reviews/02-zelda-and-chill.html#highs-and-lows",
    "title": "Zelda & Chill",
    "section": "Highs and Lows",
    "text": "Highs and Lows\nThe Breath of the Wild track is not to my taste and on writing this review, I’ve realised that I consider the soundtrack for this game to be somewhat inferior to the older games. No hate to Breath of the Wild, which is a masterpiece in modern gaming, but perhaps the soundtrack is less of a focal point and potentially appealing to a broader and more mature audience than the older games in the series.\nStandout tracks to my mind are Song of Storms, Kakariko Village and Legend of Zelda."
  },
  {
    "objectID": "music-reviews/02-zelda-and-chill.html#overall",
    "href": "music-reviews/02-zelda-and-chill.html#overall",
    "title": "Zelda & Chill",
    "section": "Overall",
    "text": "Overall\nThis album is a great choice for steadying the ship following a busy schedule. It establishes a quiet focus, allowing your brain’s operating system to reboot following a demanding presentation. I’d suggest this album as the first in a playlist dedicated to carving out an afternoon of focus time. Set your status to ‘do not disturb’ and eliminate your to-do list with the help of Link and his friends.\nFor more music to encourage your work efforts, check out Productivity Pulse."
  },
  {
    "objectID": "music-reviews/04-triads.html",
    "href": "music-reviews/04-triads.html",
    "title": "Triads",
    "section": "",
    "text": "Welcome to neon-lit streets, where the glint of laser-edged katana underlie the bustling cityscape. Where proud tradition is falling foul of organised exploitation. A realm where cybernetic dreams and dystopian nightmares converge in a symphony of pulsating synths and electrifying beats. Code Elektro’s masterpiece third album invites listeners on an immersive journey through a world where tradition meets technology, and the line between reality and virtuality blurs. With each track, the album paints a vivid portrait of a futuristic Tokyo, where shadowy figures roam the alleys and threat stalks the unwary.\n\n\n\nFor a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\nTriads is perfect for those moments when you crave an escape into a futuristic realm of imagination. Whether you’re embarking on a late-night drive through the city, diving into a cyberpunk novel, or simply seeking to enhance your creative flow, this album serves as the ideal soundtrack to accompany your journey into the unknown. Its pulsating rhythms and evocative melodies evoke a sense of adventure and intrigue, making it the perfect companion for any escapade into the realm of dystopian dreams.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature."
  },
  {
    "objectID": "music-reviews/04-triads.html#dysto-tokyo",
    "href": "music-reviews/04-triads.html#dysto-tokyo",
    "title": "Triads",
    "section": "",
    "text": "Welcome to neon-lit streets, where the glint of laser-edged katana underlie the bustling cityscape. Where proud tradition is falling foul of organised exploitation. A realm where cybernetic dreams and dystopian nightmares converge in a symphony of pulsating synths and electrifying beats. Code Elektro’s masterpiece third album invites listeners on an immersive journey through a world where tradition meets technology, and the line between reality and virtuality blurs. With each track, the album paints a vivid portrait of a futuristic Tokyo, where shadowy figures roam the alleys and threat stalks the unwary.\n\n\n\nFor a formal description of the audio feature categories presented here, please consult the Spotify Developer API Documentation.\nTriads is perfect for those moments when you crave an escape into a futuristic realm of imagination. Whether you’re embarking on a late-night drive through the city, diving into a cyberpunk novel, or simply seeking to enhance your creative flow, this album serves as the ideal soundtrack to accompany your journey into the unknown. Its pulsating rhythms and evocative melodies evoke a sense of adventure and intrigue, making it the perfect companion for any escapade into the realm of dystopian dreams.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting the Ridge Plot (Click to expand)\n\n\n\n\n\nThese ridge plots show a histogram of the mean audio feature values across each track in the album. Look across the horizontal axis at where the peaks for each feature occur. For example, if the album contains lots of tracks with busy vocals, the speechiness feature will show a peak to the right of the horizontal axis. Conversely, an instrumental album would have a speechiness peak to the left of the horizontal axis but you would also expect it to have a peak to the right of the axis in the instrumentalness feature."
  },
  {
    "objectID": "music-reviews/04-triads.html#the-tracks",
    "href": "music-reviews/04-triads.html#the-tracks",
    "title": "Triads",
    "section": "The Tracks",
    "text": "The Tracks\nBelow are the mean audio feature values for each track. The last row (green) presents a mean summary of the album.\n\n\n\n\n\ntrack_name\ndanceability\nenergy\nspeechiness\nacousticness\ninstrumentalness\nvalence\n\n\n\n\nRise of the Triads (Intro)\n0.31600\n0.4540000\n0.0471000\n0.6570000\n0.9000000\n0.1350\n\n\nShinobi\n0.46100\n0.7640000\n0.0344000\n0.0045100\n0.8940000\n0.1190\n\n\nNight Train\n0.51300\n0.5920000\n0.0378000\n0.2420000\n0.8990000\n0.1110\n\n\nChinese Dreams\n0.41100\n0.4140000\n0.0262000\n0.6480000\n0.9740000\n0.0732\n\n\nThe Monk\n0.47300\n0.9780000\n0.0427000\n0.0195000\n0.7320000\n0.4280\n\n\nIn the Shadows\n0.56600\n0.5280000\n0.0297000\n0.7830000\n0.8750000\n0.1900\n\n\nThe Wilderness\n0.48400\n0.7480000\n0.0344000\n0.0004190\n0.3020000\n0.3430\n\n\nInternational Karate\n0.57200\n0.7820000\n0.0357000\n0.0080500\n0.9510000\n0.2830\n\n\nTriads\n0.44000\n0.7550000\n0.0362000\n0.0101000\n0.8320000\n0.1610\n\n\nMission Control\n0.65500\n0.7330000\n0.0549000\n0.4410000\n0.8910000\n0.2560\n\n\nSilent Runner\n0.37300\n0.2570000\n0.0314000\n0.3730000\n0.8940000\n0.1780\n\n\nTokyo Dawn\n0.29500\n0.3680000\n0.0289000\n0.8160000\n0.9040000\n0.1840\n\n\nAlbum Mean\n0.46325\n0.6144167\n0.0366167\n0.3335482\n0.8373333\n0.2051\n\n\n\n\n\n\n\nThe ridge plot profile is remarkably similar to the ghostrunner ost, reviewed back in September 2023. Like ghostrunner, this albunm is low in speechiness and high in instrumentalness. In contrast, ghostrunner reported a broader distribution in valence than triads, which I find surprising. Triads is certainly a less menacing listen with some really beautiful melodies influenced by Japanese culture."
  },
  {
    "objectID": "music-reviews/04-triads.html#rise-of-the-triads-intro",
    "href": "music-reviews/04-triads.html#rise-of-the-triads-intro",
    "title": "Triads",
    "section": "Rise of the Triads (Intro)",
    "text": "Rise of the Triads (Intro)\nThis introductory track sets the stage for adventure. With pulsating synths and an aura of anticipation, it serves as the perfect prelude to the sonic journey ahead."
  },
  {
    "objectID": "music-reviews/04-triads.html#shinobi",
    "href": "music-reviews/04-triads.html#shinobi",
    "title": "Triads",
    "section": "Shinobi",
    "text": "Shinobi\n“Shinobi” channels the spirit of classic ninja films with its driving rhythms and mysterious melodies. Its electrifying energy evokes intrigue and images of stealthy warriors navigating through moonlit landscapes, ready to face any challenge."
  },
  {
    "objectID": "music-reviews/04-triads.html#night-train",
    "href": "music-reviews/04-triads.html#night-train",
    "title": "Triads",
    "section": "Night Train",
    "text": "Night Train\nMy favourite track. “Night Train” is an inspired prelude to action. An inspiring ride through the skies of a neon-lit cyberpunk city. A steady tempo and glittering percussive synth arrangement introduce the city’s grand scale accompanied by an alluring mix of danger and opportunity."
  },
  {
    "objectID": "music-reviews/04-triads.html#chinese-dreams",
    "href": "music-reviews/04-triads.html#chinese-dreams",
    "title": "Triads",
    "section": "Chinese Dreams",
    "text": "Chinese Dreams\nWith “Chinese Dreams,” Code Elektro delivers a mesmerizing blend of Eastern-inspired melodies and retro-futuristic synths. Its hypnotic rhythms and evocative instrumentation transport listeners to a realm where ancient traditions meet cutting-edge technology."
  },
  {
    "objectID": "music-reviews/04-triads.html#the-monk",
    "href": "music-reviews/04-triads.html#the-monk",
    "title": "Triads",
    "section": "The Monk",
    "text": "The Monk\n“The Monk” immerses listeners in a meditative soundscape, the onset of a surly tempest and a gong that could have been sampled straight from a ’70s martial arts flick. Contemplative melodies set to swelling rhythms create a sense of growing urgency."
  },
  {
    "objectID": "music-reviews/04-triads.html#in-the-shadows",
    "href": "music-reviews/04-triads.html#in-the-shadows",
    "title": "Triads",
    "section": "In the Shadows",
    "text": "In the Shadows\n“In the Shadows” conjures images of clandestine meetings and covert operations with its brooding atmosphere and enigmatic melodies. Its pulsating rhythms and suspenseful build-ups create a sense of tension and intrigue, keeping listeners on the edge of their seats. Something dark is afoot, and only a select few will ever know of what happened this day."
  },
  {
    "objectID": "music-reviews/04-triads.html#the-wilderness",
    "href": "music-reviews/04-triads.html#the-wilderness",
    "title": "Triads",
    "section": "The Wilderness",
    "text": "The Wilderness\n“The Wilderness” transports listeners to a landscapes where nature has been thoroughly hybridised with technology. Its expansive soundscapes and ethereal melodies evoke feelings of awe and wonder, then interspersed with an abundance of chiptune glitch and reverb, challenging assumptions and provoking wonder."
  },
  {
    "objectID": "music-reviews/04-triads.html#international-karate",
    "href": "music-reviews/04-triads.html#international-karate",
    "title": "Triads",
    "section": "International Karate",
    "text": "International Karate\nThis track is a steady movement with inspired homages to the sweet melodies of the East. Its minimalist approach provides a moment of introspection amidst the album’s high-energy tracks."
  },
  {
    "objectID": "music-reviews/04-triads.html#triads",
    "href": "music-reviews/04-triads.html#triads",
    "title": "Triads",
    "section": "Triads",
    "text": "Triads\nThe title track of the album is a tour de force of synth-driven bliss. “Triads” starts with a subtle ascent evoking impending action or imminent discovery. Then somewhere a door is kicked through and violence spills out onto the street, with a bassy reverb drawing the attention of all passers-by to the apparent chaos. Its pulsating rhythms and euphoric melodies leave a lasting impression."
  },
  {
    "objectID": "music-reviews/04-triads.html#mission-control",
    "href": "music-reviews/04-triads.html#mission-control",
    "title": "Triads",
    "section": "Mission Control",
    "text": "Mission Control\n“Mission Control” takes listeners on a cosmic voyage through space and time. Its propulsive rhythms evoke the spirit of space exploration and the promise of discovery, inviting listeners to join in on an epic adventure to the far reaches of the universe."
  },
  {
    "objectID": "music-reviews/04-triads.html#silent-runner",
    "href": "music-reviews/04-triads.html#silent-runner",
    "title": "Triads",
    "section": "Silent Runner",
    "text": "Silent Runner\n“Silent Runner” captivates listeners with its hauntingly beautiful melodies and hypnotic rhythms. A sweet soprano accompaniment counters a mysteriously brooding rhythm section. Its ethereal atmosphere and dreamlike quality create a sense of weightlessness, like drifting through the cosmos on a silent journey."
  },
  {
    "objectID": "music-reviews/04-triads.html#tokyo-dawn",
    "href": "music-reviews/04-triads.html#tokyo-dawn",
    "title": "Triads",
    "section": "Tokyo Dawn",
    "text": "Tokyo Dawn\nClosing out the album is “Tokyo Dawn,” a mesmerizing journey through to the dawn, bringing a sense of security and achievement. A sweet and contemplative outtro accompanying the hero through their jounrey home."
  },
  {
    "objectID": "music-reviews/04-triads.html#overall",
    "href": "music-reviews/04-triads.html#overall",
    "title": "Triads",
    "section": "Overall",
    "text": "Overall\nIn conclusion, “Triads” is a captivating odyssey through a cybernetic dreamscape, where each track offers a unique sonic experience that transports listeners to distant realms of imagination. Whether you’re a fan of synthwave or simply appreciate immersive music that takes you on a journey, “Triads” is an album that is sure to leave a lasting impression.\nFor more music to encourage your work efforts, check out Productivity Pulse."
  },
  {
    "objectID": "blogs/07-schedule-deploy-shinyapps.html",
    "href": "blogs/07-schedule-deploy-shinyapps.html",
    "title": "Scheduled Deployment to Shinyapps.io",
    "section": "",
    "text": "Wikimedia commons: Creative Commons"
  },
  {
    "objectID": "blogs/07-schedule-deploy-shinyapps.html#introduction",
    "href": "blogs/07-schedule-deploy-shinyapps.html#introduction",
    "title": "Scheduled Deployment to Shinyapps.io",
    "section": "Introduction",
    "text": "Introduction\nThis guide walks the reader through automated application update and deployment, a process known as scheduled deployment. GitHub Actions will be used to update application data and publish to shinyapps.io [1] for cloud hosting. This guide intends to help the casual developer keep their application data up-to-date.\n\n\n\n\n\n\nA Note on the Tools\n\n\n\n\n\nThe tooling used in this article may not suit all requirements. GitHub Actions and Shinyapps.io all provide free tier services, allowing for equitable access. These services are ideal for prototyping but come with limitations that may render them unsuitable for your purposes. For more information on these services and their various paid plans, please consult the Shinyapps.io features [2] and the GitHub Actions documentation [3]. This is not a product endorsement. Note that other cloud compute services provide alternative solutions to those presented in this article.\n\n\n\n\nIntended Audience\nAn experienced python and git practitioner, able to create and manage a virtual environment but less familiar with the shinyapps.io service or GitHub Actions.\n\n\nThe Scenario\nYou are considering building a dynamic application, presenting the latest view of some data to your users. You would like to automate the data retrieval and application publication processes.\n\n\nWhat You’ll Need:\n\nA GitHub account\nA shinyapps.io account\nA permissive firewall\nPython package manager (eg pip)\nPython environment manager (eg venv, poetry etc)\nAccess to a command line interface (CLI) such as terminal / Bash.\nPython requirements:\n\n\n\nrequirements.txt\n\nshiny\nrsconnect-python"
  },
  {
    "objectID": "blogs/07-schedule-deploy-shinyapps.html#develop-the-application",
    "href": "blogs/07-schedule-deploy-shinyapps.html#develop-the-application",
    "title": "Scheduled Deployment to Shinyapps.io",
    "section": "Develop the Application",
    "text": "Develop the Application\nThe steps in this guide result in a minimal application that reports the time that it was deployed to shinyapps.io.\n\nConfigure the Development Environment\n\n\n\n\n\nflowchart LR\n    B(Job: Install dependencies)\n \n\n\n\n\n\n\n\nCreate a new repository or; if you would rather skip the application development; clone this repository and proceed to the deployment stage.\nClone the repository into your local development environment.\nCreate a clean virtual environment with python 3.11. At the time of writing, this is the most current version of python available to shinyapps.io servers.\nActivate the environment.\nInstall the python dependencies in requirements.txt.\n\n\n\nPrepare the Data\n\n\n\n\n\nflowchart LR\n    B(Job: Install dependencies)\n    B ==&gt; C(Job: Run save_time.py)\n    C --&gt; D[saved_time.txt]\n \n\n\n\n\n\n\nThis job prepares the database on which the application will depend. In this trivial example, we simply save the current time as a formatted string to a text file. This simple artifact will later be read into a shiny app to present as the time of deployment.\n\nCreate a python file called save_time.py.\nPaste the following content into save_time.py and hit save:\n\n\n\nsave_time.py\n\nfrom datetime import datetime\nnw = datetime.now()\nnw = datetime.strftime(nw, \"%Y-%m-%d %H:%M:%S\")\nwith open(\"saved_time.txt\", \"w\") as f:\n    f.write(nw)\n    f.close()\nprint(f\"Saved time is {nw}\")\n\n\nRun the script from the terminal. A saved_time.txt file should appear in the project root:\n\n\n\nCLI\n\npython3 save_time.py\n\n\n\nPresent the Data\n\n\n\n\n\nflowchart LR\n    B(Job: Install dependencies)\n    B ==&gt; C(Job: Run save_time.py)\n    C --&gt; D[saved_time.txt]\n\n    G{{app.py}}\n    D -.-&gt; G  \n\n\n\n\n\n\nAn application is needed to present the data to your user. In this example, the app will simply read the date string created in the previous step, format the date string in a sentence and present it within the user interface.\n\nCreate a python file called app.py.\nPaste the following into app.py:\n\n\n\nsave_time.py\n\nfrom shiny import App, render, ui\n# get the saved time\nwith open(\"saved_time.txt\", \"r\") as f:\n    nw = f.readlines()[0]\n    f.close()\n\napp_ui = ui.page_fluid(\n    ui.h2(\"Testing Deploy Schedule.\"),\n    ui.output_text(\"txt\"),\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def txt():\n        return f\"Deployed at {nw}.\"\n\napp = App(app_ui, server)\n\n\nTest the application locally by running it. This can be done from the CLI with the command:\n\n\n\nCLI\n\npython -m shiny run ./app.py\n\n\nIf the application successfully launches, you should see a localhost URL printed. Command and click on this or paste it into your browser to confirm that the application successfully launches. The app should present the sentence Deployed at &lt;SOME_DATETIME_INSERTED_HERE&gt;."
  },
  {
    "objectID": "blogs/07-schedule-deploy-shinyapps.html#deploy-the-application",
    "href": "blogs/07-schedule-deploy-shinyapps.html#deploy-the-application",
    "title": "Scheduled Deployment to Shinyapps.io",
    "section": "Deploy the Application",
    "text": "Deploy the Application\n\nLocal Deploy\n\n\n\n\n\nflowchart LR\n    B(Job: Install dependencies)\n    B ==&gt; C(Job: Run save_time.py)\n    C --&gt; D[saved_time.txt]\n    C ==&gt; E(Job: Configure rsconnect)\n    H([SHINYAPPS_USERNAME\\nSHINYAPPS_TOKEN\\nSHINYAPPS_SECRET]) -.-&gt; E\n    E ==&gt; F(Job: Deploy to rsconnect)\n    F ==&gt; G{{shinyapps.io: serve app.py}}\n    D -.-&gt; G  \n\n\n\n\n\n\n\nThe first stage of deployment should be to manually upload the application to your shinyapps.io account. It is required to do this manually in the first instance, as it will allow you to retrieve an app ID for the deployment. This will ensure that when you use GitHub Actions to do the same, complications overwriting the application data are avoided. For more information on deploying to shinyapps.io, consult the python shiny cloud hosting documentation [4], the shinyapps.io documentation [5] and the Rsconnect-python documentation [6].\n\nFollow the shinyapps.io deployment documentation [5] to retrieve your username, token and secret. Store these somewhere secure.\n\n\n\n\n\n\n\nCaution\n\n\n\nTake precautions not to accidentally commit these credentials to your repository. I recommend both gitignoring the file that you stored them and using detect-secrets [7] if you are familiar with pre-commit hooks.\n\n\n\nConfigure an rsconnect server with the following command in your CLI, replacing the account, token and secret with your credentials:\n\n\n\nCLI\n\nrsconnect add --account &lt;YOUR_USERNAME&gt; --name rsconnect-server --token &lt;YOUR_TOKEN&gt; --secret &lt;YOUR_SECRET&gt;\n\nNote that you can give the server any name you wish, here I have used the imaginative name rsconnect-server. You must refer to this server name in &lt;YOUR_SERVER_NAME&gt; in the next step. If successful, you should see output in the CLI like below:\nChecking shinyapps.io credential...              [OK]\nUpdated shinyapps.io credential \"&lt;YOUR_SERVER_NAME&gt;\".\n\nNow use the configured rsconnect server to deploy your local app to the cloud, run the below command in the CLI, inserting the name of the server you configured in the previous step and an appropriate application title. Avoid using spaces in the application title as I have found this causes issues when deploying with certain versions of rsconnect-python:\n\n\n\nCLI\n\nrsconnect deploy shiny ./ --name &lt;YOUR_SERVER_NAME&gt;  --title &lt;ENTER_AN_APP_TITLE&gt;\n\nA successful deployment will confirm in the CLI like below:\nApplication successfully deployed to &lt;YOUR_APP_URL&gt;\n        [OK]\nSaving deployed information...  [OK]\nVerifying deployed content...   [OK]\n\nThe previous step creates a metadata directory called rsconnect-python. Add this to your .gitignore file.\nThe hosted application should launch in your default browser on successful deployment. If not, then visit the URL printed in the terminal output and check everything is working as expected.\n\n\n\nRemote Deploy\n\n\n\n\n\nflowchart LR\n    A[update.yml] ==&gt; B(Job: Install dependencies)\n    B ==&gt; C(Job: Run save_time.py)\n    C --&gt; D[saved_time.txt]\n    C ==&gt; E(Job: Configure rsconnect)\n    H([SHINYAPPS_USERNAME\\nSHINYAPPS_TOKEN\\nSHINYAPPS_SECRET]) -.-&gt; E\n    E ==&gt; F(Job: Deploy to rsconnect)\n    K([APP_ID]) -.-&gt; F\n    F ==&gt; G{{shinyapps.io: serve app.py}}\n    D -.-&gt; G    \n\n\n\n\n\n\nNow that the app has been successfully deployed, the app ID can be retrieved and used in a GitHub Action workflow to schedule this deployment. This stage will involve configuring environment variables and secrets in our GitHub repository. The guidance for configuring this is correct at the time of writing but be advised that GitHub frequently update their user interface and CI/CD functionality.\n\nConfigure the Repository Environment\n\nRetrieve the application ID. You can find this either in your shinyapps.io dashboard or by copying the value from the json file saved in the rsconnect-python directory, following a successful local deployment.\nNavigate to the GitHub repository in your browser.\nAccess the environment variables menu under Settings  Secrets and variables  Actions  Variables.\nSave an environment variable called SHINYAPPS_USERNAME with your shinyapps.io username. Ensure that the values are correct and authenticate when prompted by GitHub to save the variable. 2 factor authentication may be required so have your phone to hand.\nNow click on the Secrets tab and repeat this process for the three required secrets:\n\nAPP_ID\nSHINYAPPS_TOKEN\nSHINYAPPS_SECRET\n\nThese values will be encrypted and masked if you try to print them in workflow logs. Consult the GitHub Actions Security Documentation [8] for more on features and best practice.\n\n\n\nSet Up the Workflow\nIn this section, a script is created that will execute the job of updating the app and deploying to shinyapps.io. It will grab the secrets and variables created in the previous stage.\n\nCreate the following directory to store the workflow script:\n\n\n\nCLI\n\nmkdir -p .github/workflows\n\n\nIn that folder, create a YAML file that will contain the necessary logic to update and deploy the app.\n\n\n\nCLI\n\ntouch .github/workflows/update.yml\n\n\nUpdate the YAML file with the content below, note that I have included notes in the file to help understand the purpose of each step, but feel free to remove them if preferred:\n\n\n\nupdate.yml\n\nname: Update Application\non:\n  schedule:\n    - cron: '0 0 * * 6' # at midnight every Saturday, see https://crontab.guru/\njobs:\n  build:\n    runs-on: ubuntu-latest # this os tends to be quick & flexible\n    steps:\n      - uses: actions/checkout@v3 # premade action that allows your action to access your code\n      - uses: actions/setup-python@v3 # premade action that will install & configure python\n        with:\n          python-version: 3.11 # this needs to be a version compatible with shinyapps.io servers\n      - name: Install dependencies \n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n      - name: Update saved time # create the little saved_time.txt artifact\n        run: |\n          python3 save_time.py\n      - name: Configure rsconnect # set up an rsconnect server. Relies on repo vars & secrets\n        run: |\n          rsconnect add --account ${{ vars.SHINYAPPS_USERNAME }} --name rsconnect-server --token ${{ secrets.SHINYAPPS_TOKEN }} --secret ${{ secrets.SHINYAPPS_SECRET }}\n      - name: Deploy to rsconnect # app-id parameter allows reliable overwriting of app content without creating duplicates.\n        run: |\n          rsconnect deploy shiny --app-id ${{ secrets.APP_ID }} ./ --name rsconnect-server  --title scheduled-deployment\n\n\nOnce everything has been done, add and commit all the changes and push them to the remote. The next time the cron job triggers, navigate to the repository in a browser and inspect the workflow logs under Actions  All workflows.\nIf the Action executed successfully, you will see the topmost build log will present a blue checkmark. Click on the link to see the details.\nClick on the build label to expose the steps in the workflow. By clicking on the steps the logs can be expanded. Check the time of deployment under the Update saved time step.\nClick on the Deploy to rsconnect step. The final line should state that the application was successfully deployed to a URL. Click on the link to launch the app and confirm that the time of deployment matches that reported in the Update saved time log."
  },
  {
    "objectID": "blogs/07-schedule-deploy-shinyapps.html#tips-troubleshooting",
    "href": "blogs/07-schedule-deploy-shinyapps.html#tips-troubleshooting",
    "title": "Scheduled Deployment to Shinyapps.io",
    "section": "Tips & Troubleshooting",
    "text": "Tips & Troubleshooting\n\nTo see a list of your configured rsconnect servers, use the rsconnect list command in the CLI.\nTo remove a server, use rsconnect remove --name &lt;SERVER_NAME&gt; in the CLI.\nIf you encounter an error when deploying your app that states “not found”, try deleting the folder called rsconnect-python if it exists and run the deploy command once more.\nOnce you have used GitHub Actions to schedule the deployment, you may notice that the time of execution does not precisely match the time specified in the workflow file. GitHub will initiate the job at the time specified, but will queue the job until a runner is available to execute it. At periods of heavy traffic, you may experience delays of half an hour or more."
  },
  {
    "objectID": "blogs/07-schedule-deploy-shinyapps.html#conclusion",
    "href": "blogs/07-schedule-deploy-shinyapps.html#conclusion",
    "title": "Scheduled Deployment to Shinyapps.io",
    "section": "Conclusion",
    "text": "Conclusion\nIn this guide, we have produced a python shiny application and used GitHub Actions to schedule its deployment to the shinyapps hosting service.\nThis workflow can be adapted to serve a real business need. For example, a similar workflow can be used to produce a basic ‘bounty board’ app to help colleagues in an organisation extract GitHub issues and PRs (Code available here).\nThe workflow can also be improved to take advantage of the new GitHub Actions caching feature [9]. This will make subsequent runs faster as dependencies and configuration can be stored between runs.\nGet some action!\n\nAction Man GIFfrom Action GIFs\n\n\n\nfin!"
  },
  {
    "objectID": "blogs/20-lazy-mocking.html#introduction",
    "href": "blogs/20-lazy-mocking.html#introduction",
    "title": "Lazy Mocking",
    "section": "Introduction",
    "text": "Introduction\nA simple approach to sharing a fixture across multiple tests where mocking is a requirement. After comparing implementations with pytest’s monkeypatch and mockito, unittest.patch was selected because it is straightforward and succinct. The code in this article is available in this gist for those pushed for time.\n\nIntended Audience\nExperienced python Developers, test engineers & any intersection of the two. This tutorial is not for those new to mocking. Please refer to Mocking With Pytest in Plain English for a more comprehensive introduction to that. This blog is part of a series called pytest in plain English.\n\n\nRequirements\npip install pytest"
  },
  {
    "objectID": "blogs/20-lazy-mocking.html#some-source-code",
    "href": "blogs/20-lazy-mocking.html#some-source-code",
    "title": "Lazy Mocking",
    "section": "Some Source Code",
    "text": "Some Source Code\nThis little function would cause a problem when writing your test suite:\n\nfrom datetime import datetime\n\ndef get_poem_line_for_day():\n    \"\"\"Returns the line of the poem based on the current day of the week.\"\"\"\n    day_of_week = datetime.today().strftime('%A')\n    POEM = {\n        \"Monday\": \"Monday's child is fair of face\",\n        \"Tuesday\": \"Tuesday's child is full of grace\",\n        \"Wednesday\": \"Wednesday's child is full of woe\",\n        \"Thursday\": \"Thursday's child has far to go\",\n        \"Friday\": \"Friday's child is loving and giving\",\n        \"Saturday\": \"Saturday's child works hard for his living\",\n        \"Sunday\": \"And the child that is born on the Sabbath day is bonny and blithe, and good and gay\",\n    }\n    return POEM.get(day_of_week, \"Unknown day\")\n\nget_poem_line_for_day()\n\n\"Monday's child is fair of face\"\n\n\n\n\n\n\n\n\nWhy would this be hard to test without mocking? (Click to reveal)\n\n\n\n\n\n\nThe function will return different strings depending on the day the test is run.\nWithout mocking get_poem_line_for_day, you would have to update hard-coded test predicates to match the current day of the week. Nope.\nIn CI, avoiding mocking would likely result in setting a variable equal to the current day of the week and basing your test predicates off of that. Nope.\nLet’s instead patch the values…"
  },
  {
    "objectID": "blogs/20-lazy-mocking.html#lets-test",
    "href": "blogs/20-lazy-mocking.html#lets-test",
    "title": "Lazy Mocking",
    "section": "Let’s Test…",
    "text": "Let’s Test…\n\nLocal-Scoped Mock\nThis is very easy to mock using local-scoped utility functions.\n\nfrom unittest import mock\n\nimport pytest\n\nimport poem\n\nPOEM = {\n        \"Monday\": \"Monday's child is fair of face\",\n        \"Tuesday\": \"Tuesday's child is full of grace\",\n        \"Wednesday\": \"Wednesday's child is full of woe\",\n        \"Thursday\": \"Thursday's child has far to go\",\n        \"Friday\": \"Friday's child is loving and giving\",\n        \"Saturday\": \"Saturday's child works hard for his living\",\n        \"Sunday\": \"And the child that is born on the Sabbath day is bonny and blithe, and good and gay\",\n    }\n\n\n1@mock.patch(\"poem.get_poem_line_for_day\")\n2def test_poem_line_forever_thursday(patched_poem):\n    \"\"\"Uses immediate instantiation\"\"\"\n\n3    def mock_poem(day, poem=POEM):\n        return poem[day]\n\n4    patched_poem.return_value = mock_poem(day=\"Thursday\")\n5    result = poem.get_poem_line_for_day()\n6    assert result == \"Thursday's child has far to go\"\n\n\n1\n\nSpecify the target that we wish to patch.\n\n2\n\nDefine a name for the patch as patched_poem. We’ll need to refer to this when implementing the patch in the test.\n\n3\n\nDefine a locally-scoped function that will serve the line of the poem depending on the day that you ask for.\n\n4\n\nSet the return value of the patch we specified to be equal to the line for a hard-coded day of the week. Note that we could go ahead and make multiple assertions re-using the mock_poem utility.\n\n5\n\nUse the System Under Test (SUT). Note that in a real test suite, we would likely target the component of the SUT that we need to control, rather than the entire source code. Eg - target datetime.today rather than get_poem_line_for_day.\n\n6\n\nWhatever day the test is executed on, the resulting value will be patched in the way we specified.\n\n\n\n\n\n\nMock with Fixture - Broken\nIt is common to start with a locally-scoped mock and then later need to share that across multiple tests. You may naively try to use the same mock_poem as a pytest fixture.\n\nfrom unittest import mock\n\nimport pytest\n\nimport poem\n\n\n1@pytest.fixture(scope=\"function\")\n2def mock_poem(day, poem=POEM):\n    return poem[day]\n\n\n3@mock.patch(\"poem.get_poem_line_for_day\")\ndef test_IS_BROKEN_(patched_poem, mock_poem):\n    \"\"\"Uses deferred instantiation.\"\"\"\n    patched_poem.return_value = mock_poem(day_name=\"Wednesday\")\n    result = poem.get_poem_line_for_day()                                       \n    assert result == \"Wednesday's child is full of woe\"\n\n    patched_poem.return_value = mock_poem(day_name=\"Friday\")\n    result = poem.get_poem_line_for_day()\n    assert result == \"Friday's child is loving and giving\"\n\n\n1\n\nWe attempt to shift the utility to a fixture in order to use it across mutliple tests.\n\n2\n\npytest fixtures will eagerly evaluate the arguments to the fixture and raise an exception, as a value for day has not been set.\n\n3\n\nThe test is not run due to the above exception.\n\n\n\n\n\n\nMock with Fixture - Fixed\nWe need to implement some minor tweaks to the broken fixture in order to delay evaluation of the parameters. In this way, we make the fixture “lazy” by using a factory function to instantiate the poem line within the test, rather than before it.\n\nfrom unittest import mock\n\nimport pytest\n\nimport poem\n\n\n@pytest.fixture(scope=\"function\")\n1def mock_poem_line_factory():\n    \"\"\"Factory function that mocks expected return values.\"\"\"\n2    def _get_poem_line(day_name: str, poem: dict = POEM) -&gt; str:\n        return poem[day_name]\n    \n3    return _get_poem_line\n\n@mock.patch(\"poem.get_poem_line_for_day\")\n4def test_poem_line_any_day_we_like(patched_poem, mock_poem_line_factory):\n    \"\"\"Uses deferred instantiation.\"\"\"\n    patched_poem.return_value = mock_poem_line_factory(day_name=\"Wednesday\")\n5    result = poem.get_poem_line_for_day()\n    assert result == \"Wednesday's child is full of woe\"\n\n    patched_poem.return_value = mock_poem_line_factory(day_name=\"Friday\")\n    result = poem.get_poem_line_for_day()\n    assert result == \"Friday's child is loving and giving\"\n\n\n1\n\nThe fixture will now act as a factory function, encapsulating the instantiation of the values we wish to return. This gives us more control over when the day_name parameter is evaluated. Note that the fixture signature takes no arguments, though you could pass it other pytest fixtures if you needed to.\n\n2\n\nThe internal _get_poem_line signature defines the arguments needed to control which poem lines you wish to return.\n\n3\n\nNote the factory function should return the internal itself, rather than its value - we need to delay evaluation.\n\n4\n\nDon’t forget to pass in the fixture to the test signature. It must come after the alias we used for mock.patch, due to the decorator.\n\n5\n\nThe mock fixture gets evaluated when we attempt to patch the SUT."
  },
  {
    "objectID": "blogs/20-lazy-mocking.html#summary",
    "href": "blogs/20-lazy-mocking.html#summary",
    "title": "Lazy Mocking",
    "section": "Summary",
    "text": "Summary\nWe’ve summarised a basic implementation of how to defer evaluation of a pytest fixture by using a factory function, by:\n\nDemonstrating how to achieve a straightforward mock:patch combo with a local utility.\nDemonstrating that the same approach does not work for a pytest fixture.\nUpdating the fixture to use lazy evaluation.\n\nPlease feel free to share your own thoughts and ideas in the comment section below (GitHub login required)! If you spot an error with this article, or have a suggested improvement then feel free to raise an issue on GitHub.\n\nfin!"
  },
  {
    "objectID": "blogs/12-pytest-tmp-path.html",
    "href": "blogs/12-pytest-tmp-path.html",
    "title": "Pytest With tmp_path in Plain English",
    "section": "",
    "text": "Creative commons license by Ralph"
  },
  {
    "objectID": "blogs/12-pytest-tmp-path.html#introduction",
    "href": "blogs/12-pytest-tmp-path.html#introduction",
    "title": "Pytest With tmp_path in Plain English",
    "section": "Introduction",
    "text": "Introduction\npytest is a testing package for the python framework. It is broadly used to quality assure code logic. This article discusses why and how we use pytest’s temporary fixtures tmp_path and tmp_path_factory. This blog is the second in a series of blogs called pytest in plain English, favouring accessible language and simple examples to explain the more intricate features of the pytest package.\nFor a wealth of documentation, guides and how-tos, please consult the pytest documentation.\n\n\n\n\n\n\nA Note on the Purpose (Click to expand)\n\n\n\n\n\nThis article intends to discuss clearly. It doesn’t aim to be clever or impressive. Its aim is to extend understanding without overwhelming the reader.\n\n\n\n\nIntended Audience\nProgrammers with a working knowledge of python and some familiarity with pytest and packaging. The type of programmer who has wondered about how to follow best practice in testing python code.\n\n\nWhat You’ll Need:\n\nPreferred python environment manager (eg conda)\npip install pytest==8.1.1\nGit\nGitHub account\nCommand line access\n\n\n\nPreparation\nThis blog is accompanied by code in this repository. The main branch provides a template with the minimum structure and requirements expected to run a pytest suite. The repo branches contain the code used in the examples of the following sections.\nFeel free to fork or clone the repo and checkout to the example branches as needed.\nThe example code that accompanies this article is available in the temp-fixtures branch of the repo."
  },
  {
    "objectID": "blogs/12-pytest-tmp-path.html#what-are-temporary-fixtures",
    "href": "blogs/12-pytest-tmp-path.html#what-are-temporary-fixtures",
    "title": "Pytest With tmp_path in Plain English",
    "section": "What Are Temporary Fixtures?",
    "text": "What Are Temporary Fixtures?\nIn the previous pytest in plain English article, we discussed how to write our own fixtures to serve data to our tests. But pytest comes with its own set of fixtures that are really useful in certain situations. In this article, we will consider those fixtures that are used to create temporary directories and files.\n\nWhy Do We Need Temporary Fixtures?\nIf the code you need to test carries out file operations, then there are a few considerations needed when writing our tests. It is best practice in testing to ensure the system state is unaffected by running the test suite. In the very worst cases I have encountered, running the test suite has resulted in timestamped csvs being written to disk every time pytest was run. As developers potentially run these tests hundreds of times while working on a code base, this thoughtless little side-effect quickly results in a messy file system.\nJust to clarify - I’m not saying it’s a bad idea to use timestamped file names. Or to have functions with these kinds of side effects - these features can be really useful. The problem is when the test suite creates junk on your disk that you weren’t aware of…\nBy using temporary fixtures, we are ensuring the tests are isolated from each other and behave in dependable ways. If you ever encounter a test suite that behaves differently on subsequent runs, then be suspicious of a messy test suite with file operations that have changed the state of the system. In order for us to reason about the state of the code, we need to be able to rely on the answers we get from the tests, known in test engineering speak as determinism.\n\n\nLet’s Compare the Available Temporary Fixtures\nThe 2 fixtures that we should be working with as of 2024 are tmp_path and tmp_path_factory. Both of these newer temporary fixtures return pathlib.Path objects and are included with the pytest package in order to encourage developers to use them. No need to import tempfile or any other dependency to get what you need, it’s all bundled up with your pytest installation.\ntmp_path is a function-scoped fixture. Meaning that if we use tmp_path in 2 unit tests, then we will be served with 2 separate temporary directories to work with. This should meet most developers’ needs. But if you’re doing something more complex with files, there are occasions where you may need a more persistent temporary directory. Perhaps a bunch of your functions need to work sequentially using files on disk and you need to test how all these units work together. This kind of scenario can arise if you are working on really large files where in-memory operations become too costly. This is where tmp_path_factory can be useful, as it is a session-scoped temporary structure. A tmp_path_factory structure will be created at the start of a test suite and will persist until teardown happens once the last test has been executed.\n\n\n\nFixture Name\nScope\nTeardown after each\n\n\n\n\ntmp_path\nfunction\ntest function\n\n\ntmp_path_factory\nsession\npytest session\n\n\n\n\n\nWhat About tmpdir?\nAh, the eagle-eyed among you may have noticed that the pytest package contains other fixtures that are relevant to temporary structures. Namely tmpdir and tmpdir_factory. These fixtures are older equivalents of the fixtures we discussed above. The main difference is that instead of returning pathlib.Path objects, they return py.path.local objects. These fixtures were written before pathlib had been adopted as the standardised approach to handling paths across multiple operating systems. The future of tmpdir and tmpdir_factory have been discussed for deprecation. These fixtures are being sunsetted and it is advised to port old test suites over to the new tmp_path fixture instead. The pytest team has provided a utility to help developers identify these issues in their old test suites.\nIn summary, don’t use tmpdir any more and consider converting old code if you used it in the past…"
  },
  {
    "objectID": "blogs/12-pytest-tmp-path.html#how-to-use-temporary-fixtures",
    "href": "blogs/12-pytest-tmp-path.html#how-to-use-temporary-fixtures",
    "title": "Pytest With tmp_path in Plain English",
    "section": "How to Use Temporary Fixtures",
    "text": "How to Use Temporary Fixtures\n\nWriting Source Code\nAs a reminder, the code for this section is located here.\nIn this deliberately silly example, let’s say we have a poem sitting on our disk in a text file. Thanks to chatGPT for the poem and MSFT Bing Copilot for the image, making this a trivial consideration. Or should I really thank the millions of people who wrote the content that these services trained on?\nSaving the text file in the chunk below to the ./tests/data/ folder is where you would typically save data for your tests.\n\n\n\ntests/data/jack-jill-2024.txt\n\nIn the realm of data, where Jack and Jill dwell,\nThey ventured forth, their tale to tell.\nBut amidst the bytes, a glitch they found,\nA challenge profound, in algorithms bound.\n\nTheir circuits whirred, their processors spun,\nAs they analyzed the glitch, one by one.\nYet despite their prowess, misfortune struck,\nA bug so elusive, like lightning struck.\n\nTheir systems faltered, errors abound,\nAs frustration grew with each rebound.\nBut Jack and Jill, with minds so keen,\nRefused to let the glitch remain unseen.\n\nWith perseverance strong and logic clear,\nThey traced the bug to its hidden sphere.\nAnd with precision fine and code refined,\nThey patched the glitch, their brilliance defined.\n\nIn the end, though misfortune came their way,\nJack and Jill triumphed, without delay.\nFor in the realm of AI, where challenges frown,\nTheir intellect prevailed, wearing victory's crown.\n\nSo let their tale inspire, in bytes and code,\nWhere challenges rise on the digital road.\nFor Jack and Jill, with their AI might,\nShowed that even in darkness, there's always light.\n\nLet’s imagine we need a program that can edit the text and write new versions of the poem to disk. Let’s go ahead and create a function that will read the poem from disk and replace any word that you’d like to change.\n\n\"\"\"Demonstrating tmp_path & tmp_path_factory with a simple txt file.\"\"\"\nfrom pathlib import Path\nfrom typing import Union\n\ndef _update_a_term(\n    txt_pth: Union[Path, str], target_pattern:str, replacement:str) -&gt; str:\n    \"\"\"Replace the target pattern in a body of text.\n\n    Parameters\n    ----------\n    txt_pth : Union[Path, str]\n        Path to a txt file.\n    target_pattern : str\n        The pattern to replace.\n    replacement : str\n        The replacement value.\n\n    Returns\n    -------\n    str\n        String with any occurrences of target_pattern replaced with specified\n        replacement value.\n\n    \"\"\"\n    with open(txt_pth, \"r\") as f:\n        txt = f.read()\n        f.close()\n    return txt.replace(target_pattern, replacement)\n\nNow we can try using the function to rename a character in the rhyme, by running the below code in a python shell.\n\nfrom pyprojroot import here\nrhyme = _update_a_term(\n  txt_pth=here(\"data/blogs/jack-jill-2024.txt\"),\n  target_pattern=\"Jill\",\n  replacement=\"Jock\")\nprint(rhyme[0:175])\n\nIn the realm of data, where Jack and Jock dwell,\nThey ventured forth, their tale to tell.\nBut amidst the bytes, a glitch they found,\nA challenge profound, in algorithms bound.\n\n\n\n\n\n\n\n\nWhy Use Underscores?\n\n\n\n\n\nYou may have noticed that the above function starts with an underscore. This convention means the function is not intended for use by the user. These internal functions would typically have less defensive checks than those you intend to expose to your users. It’s not an enforced thing but is considered good practice. It means “use at your own risk” as internals often have less documentation, may not be directly tested and could be less stable than functions in the api.\n\n\n\nGreat, next we need a little utility function that will take our text and write it to a file of our choosing.\n\ndef _write_string_to_txt(some_txt:str, out_pth:Union[Path, str]) -&gt; None:\n    \"\"\"Write some string to a text file.\n\n    Parameters\n    ----------\n    some_txt : str\n        The text to write to file.\n    out_pth : Union[Path, str]\n        The path to the file.\n    \n    Returns\n    -------\n    None\n\n    \"\"\"\n    with open(out_pth, \"w\") as f:\n        f.writelines(some_txt)\n        f.close()    \n\nFinally, we need a wrapper function that will use the above functions, allowing the user to read in the text file, replace a pattern and then write the new poem to file.\n\ndef update_poem(\n    poem_pth:Union[Path, str],\n    target_pattern:str,\n    replacement:str,\n    out_file:Union[Path, str]) -&gt; None:\n    \"\"\"Takes a txt file, replaces a pattern and writes to a new file.\n\n    Parameters\n    ----------\n    poem_pth : Union[Path, str]\n        Path to a txt file.\n    target_pattern : str\n        A pattern to update.\n    replacement : str\n        The replacement value.\n    out_file : Union[Path, str]\n        A file path to write to.\n\n    \"\"\"\n    txt = _update_a_term(poem_pth, target_pattern, replacement)\n    _write_string_to_txt(txt, out_file)\n\nHow do we know it works? We can use it and observe the output, as I did with _update_a_term() earlier, but this article is about testing. So let’s get to it.\n\n\nTesting the Source Code\nWe need to test update_poem() but it writes files to disk. We don’t want to litter our (and our colleagues’) disks with files every time pytest runs. Therefore we need to ensure the function’s out_file parameter is pointing at a temporary directory. In that way, we can rely on the temporary structure’s behaviour on teardown to remove these files when pytest finishes doing its business.\n\n\"\"\"Tests for update_poetry module.\"\"\"\nimport os\n\nimport pytest\n\nfrom example_pkg import update_poetry\n\ndef test_update_poem_writes_new_pattern_to_file(tmp_path):\n    \"\"\"Check that update_poem changes the poem pattern and writes to file.\"\"\"\n    new_poem_path = os.path.join(tmp_path, \"new_poem.txt\")\n    update_poetry.update_poem(\n        poem_pth=\"tests/data/jack-jill-2024.txt\",\n        target_pattern=\"glitch\",\n        replacement=\"bug\",\n        out_file=new_poem_path\n        )\n\nBefore I go ahead and add a bunch of assertions in, look at how easy it is to use tmp_path, blink and you’ll miss it. You simply reference it in the signature of the test where you wish to use it and then you are able to work with it like you would any other path object.\nSo far in this test function, I specified that I’d like to read the text from a file called jack-jill-2024.txt, replace the word “glitch” with “bug” wherever it occurs and then write this text to a file called new_poem.txt in a temporary directory.\nSome simple tests for this little function:\n\nDoes the file I asked for exist?\nAre the contents of that file as I expect?\n\nLet’s go ahead and add in those assertions.\n\n\"\"\"Tests for update_poetry module.\"\"\"\n\nimport os\n\nimport pytest\n\nfrom example_pkg import update_poetry\n\ndef test_update_poem_writes_new_pattern_to_file(tmp_path):\n    \"\"\"Check that update_poem changes the poem pattern and writes to file.\"\"\"\n    new_poem_path = os.path.join(tmp_path, \"new_poem.txt\")\n    update_poetry.update_poem(\n        poem_pth=\"tests/data/jack-jill-2024.txt\",\n        target_pattern=\"glitch\",\n        replacement=\"bug\",\n        out_file=new_poem_path\n        )\n    # Now for the assertions\n    assert os.path.exists(new_poem_path)\n    assert os.listdir(tmp_path) == [\"new_poem.txt\"]\n    # let's check what pattern was written - now we need to read in the\n    # contents of the new file.\n    with open(new_poem_path, \"r\") as f:\n        what_was_written = f.read()\n        f.close()\n    assert \"glitch\" not in what_was_written\n    assert \"bug\" in what_was_written\n\nRunning pytest results in the below output.\ncollected 1 item\n\ntests/test_update_poetry.py .                                            [100%]\n\n============================== 1 passed in 0.01s ==============================\nSo we prove that the function works how we hoped it would. But what if I want to work with the new_poem.txt file again in another test function? Let’s add another test to test_update_poetry.py and see what we get when we try to use tmp_path once more.\n\n\"\"\"Tests for update_poetry module.\"\"\"\n# import statements ...\n\n# def test_update_poem_writes_new_pattern_to_file(tmp_path): ...\n\ndef test_do_i_get_a_new_tmp_path(tmp_path):\n    \"\"\"Remind ourselves that tmp_path is function-scoped.\"\"\"\n    assert \"new_poem\" not in os.listdir(tmp_path)\n    assert os.listdir(tmp_path) == []\n\nAs is demonstrated when running pytest once more, tmp_path is function-scoped and we have now lost the new poem with the bugs instead of the glitches. Drat! What to do…\ncollected 2 items\n\ntests/test_update_poetry.py ..                                           [100%]\n\n============================== 2 passed in 0.01s ==============================\n\nAs mentioned earlier, pytest provides another fixture with more flexibility, called tmp_path_factory. As this fixture is session-scoped, we can have full control over this fixture’s scoping.\n\n\n\n\n\n\nFixture Scopes\n\n\n\n\n\nFor a refresher on the rules of scope referencing, please see the blog Pytest Fixtures in Plain English.\n\n\n\n\n\"\"\"Tests for update_poetry module.\"\"\"\n# import statements ...\n\n# def test_update_poem_writes_new_pattern_to_file(tmp_path): ...\n\n# def test_do_i_get_a_new_tmp_path(tmp_path): ...\n\n@pytest.fixture(scope=\"module\")\ndef _module_scoped_tmp(tmp_path_factory):\n    yield tmp_path_factory.mktemp(\"put_poetry_here\", numbered=False)\n\nNote that as tmp_path_factory is session-scoped, I’m free to reference it in another fixture with any scope. Here I define a module-scoped fixture, which means teardown of _module_scoped_tmp will occur once the final test in this test module completes. Now repeating the logic executed with tmp_path above, but this time with our new module-scoped temporary directory, we get a different outcome.\n\n\"\"\"Tests for update_poetry module.\"\"\"\n# import statements ...\n\n# def test_update_poem_writes_new_pattern_to_file(tmp_path): ...\n\n# def test_do_i_get_a_new_tmp_path(tmp_path): ...\n\n@pytest.fixture(scope=\"module\")\ndef _module_scoped_tmp(tmp_path_factory):\n    yield tmp_path_factory.mktemp(\"put_poetry_here\", numbered=False)\n\n\ndef test_module_scoped_tmp_exists(_module_scoped_tmp):\n    new_poem_path = os.path.join(_module_scoped_tmp, \"new_poem.txt\")\n    update_poetry.update_poem(\n        poem_pth=\"tests/data/jack-jill-2024.txt\",\n        target_pattern=\"glitch\",\n        replacement=\"bug\",\n        out_file=new_poem_path\n        )\n    assert os.path.exists(new_poem_path)\n    with open(new_poem_path, \"r\") as f:\n        what_was_written = f.read()\n        f.close()\n    assert \"glitch\" not in what_was_written\n    assert \"bug\" in what_was_written\n    assert os.listdir(_module_scoped_tmp) == [\"new_poem.txt\"]\n\n\ndef test_do_i_get_a_new_tmp_path_factory(_module_scoped_tmp):\n    assert not os.listdir(_module_scoped_tmp) == [] # not empty...\n    assert os.listdir(_module_scoped_tmp) == [\"new_poem.txt\"]\n    # module-scoped fixture still contains file made in previous test function\n    with open(os.path.join(_module_scoped_tmp, \"new_poem.txt\")) as f:\n        found_txt = f.read()\n        f.close()\n    assert \"glitch\" not in found_txt\n    assert \"bug\" in found_txt\n\nExecuting pytest one final time demonstrates that the same output file written to disk with test_module_scoped_tmp_exists() is subsequently available for further testing in test_do_i_get_a_new_tmp_path_factory().\ncollected 4 items\n\ntests/test_update_poetry.py ....                                         [100%]\n\n============================== 4 passed in 0.01s ==============================\nNote that the order that these 2 tests run in is now important. These tests are no longer isolated and trying to run the second test on its own with pytest -k \"test_do_i_get_a_new_tmp_path_factory\" would result in a failure. For this reason, it may be advisable to pop the test functions within a common test class, or even use pytest marks to mark them as integration tests (more on this in a future blog)."
  },
  {
    "objectID": "blogs/12-pytest-tmp-path.html#summary",
    "href": "blogs/12-pytest-tmp-path.html#summary",
    "title": "Pytest With tmp_path in Plain English",
    "section": "Summary",
    "text": "Summary\nThe reasons we use temporary fixtures and how to use them has been demonstrated with another silly (but hopefully relatable) little example. I have not gone into the wealth of methods available in these temporary fixtures, but they have many useful utilities. Maybe you’re working with a complex nested directory structure for example, the glob method would surely help with that.\nBelow are the public methods and attributes of tmp_path:\n['absolute', 'anchor', 'as_posix', 'as_uri', 'chmod', 'cwd', 'drive', 'exists',\n'expanduser', 'glob', 'group', 'hardlink_to', 'home', 'is_absolute',\n'is_block_device', 'is_char_device', 'is_dir', 'is_fifo', 'is_file',\n'is_junction', 'is_mount', 'is_relative_to', 'is_reserved', 'is_socket',\n'is_symlink', 'iterdir', 'joinpath', 'lchmod', 'lstat', 'match', 'mkdir',\n'name', 'open', 'owner', 'parent', 'parents', 'parts', 'read_bytes',\n'read_text', 'readlink', 'relative_to', 'rename', 'replace', 'resolve',\n'rglob', 'rmdir', 'root', 'samefile', 'stat', 'stem', 'suffix', 'suffixes',\n'symlink_to', 'touch', 'unlink', 'walk', 'with_name', 'with_segments',\n'with_stem', 'with_suffix', 'write_bytes', 'write_text'] \nIt is useful to read the pathlib.Path docs as both fixtures return this type and many of the methods above are inherited from these types. To read the tmp_path and tmp_path_factory implementation, I recommend reading the tmp docstrings on GitHub.\nIf you spot an error with this article, or have suggested improvement then feel free to raise an issue on GitHub.\nHappy testing!"
  },
  {
    "objectID": "blogs/12-pytest-tmp-path.html#acknowledgements",
    "href": "blogs/12-pytest-tmp-path.html#acknowledgements",
    "title": "Pytest With tmp_path in Plain English",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo past and present colleagues who have helped to discuss pros and cons, establishing practice and firming-up some opinions. Particularly:\n\nCharlie\nDan\nEdward\nIan\nMark\n\n\nfin!"
  },
  {
    "objectID": "blogs/13-pytest-parametrize.html",
    "href": "blogs/13-pytest-parametrize.html",
    "title": "Parametrized Tests With Pytest in Plain English",
    "section": "",
    "text": "Complex sushi conveyor belt with a futuristic theme in a pastel palette."
  },
  {
    "objectID": "blogs/13-pytest-parametrize.html#introduction",
    "href": "blogs/13-pytest-parametrize.html#introduction",
    "title": "Parametrized Tests With Pytest in Plain English",
    "section": "Introduction",
    "text": "Introduction\npytest is a testing package for the python framework. It is broadly used to quality assure code logic. This article discusses what parametrized tests mean and how to implement them with pytest. This blog is the third in a series of blogs called pytest in plain English, favouring accessible language and simple examples to explain the more intricate features of the pytest package.\nFor a wealth of documentation, guides and how-tos, please consult the pytest documentation.\n\n\n\n\n\n\nA Note on the Purpose (Click to expand)\n\n\n\n\n\nThis article intends to discuss clearly. It doesn’t aim to be clever or impressive. Its aim is to extend understanding without overwhelming the reader.\n\n\n\n\nIntended Audience\nProgrammers with a working knowledge of python and some familiarity with pytest and packaging. The type of programmer who has wondered about how to follow best practice in testing python code.\n\n\nWhat You’ll Need:\n\nPreferred python environment manager (eg conda)\npip install pytest==8.1.1\nGit\nGitHub account\nCommand line access\n\n\n\nPreparation\nThis blog is accompanied by code in this repository. The main branch provides a template with the minimum structure and requirements expected to run a pytest suite. The repo branches contain the code used in the examples of the following sections.\nFeel free to fork or clone the repo and checkout to the example branches as needed.\nThe example code that accompanies this article is available in the parametrize branch of the repo."
  },
  {
    "objectID": "blogs/13-pytest-parametrize.html#overview",
    "href": "blogs/13-pytest-parametrize.html#overview",
    "title": "Parametrized Tests With Pytest in Plain English",
    "section": "Overview",
    "text": "Overview\n\nWhat Are Parametrized Tests?\nParametrized tests are simply tests that are applied recursively to multiple input values. For example, rather than testing a function on one input value, a list of different values could be passed as a parametrized fixture.\nA standard approach to testing could look like Figure 1 below, where separate tests are defined for the different values we need to check. This would likely result in a fair amount of repeated boilerplate code.\n\n\n\nFigure 1: Testing multiple values without parametrization\n\n\nInstead, we can reduce the number of tests down to 1 and pass a list of tuples to the test instead. Each tuple should contain a parameter value and the expected result, as illustrated in Figure 2.\n\n\n\nFigure 2: Parametrized testing of multiple values\n\n\nSo let’s imagine we have a simple function called double(), the setup for the parametrized list is illustrated in Figure 3.\n\n\n\nFigure 3: Exemplified paramatrization for test_double()\n\n\n\n\nWhy use Parametrization?\nThis approach allows us to thoroughly check the behaviour of our functions against multiple values, ensuring that edge-cases are safely treated or exceptions are raised as expected.\nIn this way, we serve multiple parameters and expected outcomes to a single test, reducing boilerplate code. Parametrization is not a silver bullet, and we still need to define all of our parameters and results in a parametrized fixture. This approach is not quite as flexible as the property-based testing achievable with a package such as hypothesis. However, the learning curve for hypothesis is a bit greater and may be disproportionate to the job at hand.\nFor the reasons outlined above, there are likely many competent python developers that never use parametrized fixtures. But parametrization does allow us to avoid implementing tests with a for loop or vectorized approaches to the same outcomes. When coupled with programmatic approaches to generating our input parameters, many lines of code can be saved. And things get even more interesting when we pass multiple parametrized fixtures to our tests, which I’ll come to in a bit. For these reasons, I believe that awareness of parametrization should be promoted among python developers as a useful solution in the software development toolkit."
  },
  {
    "objectID": "blogs/13-pytest-parametrize.html#implementing-parametrization",
    "href": "blogs/13-pytest-parametrize.html#implementing-parametrization",
    "title": "Parametrized Tests With Pytest in Plain English",
    "section": "Implementing Parametrization",
    "text": "Implementing Parametrization\nIn this section, we will compare some very simple examples of tests with and without parametrization. Feel free to clone the repository and check out to the example code branch to run the examples.\n\nDefine the Source Code\nHere we define a very basic function that checks whether an integer is prime. If a prime is encountered, then True is returned. If not, then False. The value 1 gets its own treatment (return False). Lastly, we include some basic defensive checks, we return a TypeError if anything other than integer is passed to the function and a ValueError if the integer is less than or equal to 0.\n\ndef is_num_prime(pos_int: int) -&gt; bool:\n    \"\"\"Check if a positive integer is a prime number.\n\n    Parameters\n    ----------\n    pos_int : int\n        A positive integer.\n\n    Returns\n    -------\n    bool\n        True if the number is a prime number.\n\n    Raises\n    ------\n    TypeError\n        Value passed to `pos_int` is not an integer.\n    ValueError\n        Value passed to `pos_int` is less than or equal to 0.\n    \"\"\"\n    if not isinstance(pos_int, int):\n        raise TypeError(\"`pos_int` must be a positive integer.\")\n    if pos_int &lt;= 0:\n        raise ValueError(\"`pos_int` must be a positive integer.\")\n    elif pos_int == 1:\n        return False\n    else:\n        for i in range(2, (pos_int // 2) + 1):\n            # If divisible by any number 2&lt;&gt;(n/2)+1, it is not prime\n            if (pos_int % i) == 0:\n                return False\n        else:\n            return True\n\nRunning this function with a range of values demonstrates its behaviour.\n\nfor i in range(1, 11):\n  print(f\"{i}: {is_num_prime(i)}\")\n\n1: False\n2: True\n3: True\n4: False\n5: True\n6: False\n7: True\n8: False\n9: False\n10: False\n\n\n\n\nLet’s Get Testing\nLet’s begin with the defensive tests. Let’s say I need to check that the function can be relied upon to raise on a number of conditions. The typical approach may be to test the raise conditions within a dedicated test function.\n\n\"\"\"Tests for primes module.\"\"\"\nimport pytest\n\nfrom example_pkg.primes import is_num_prime\n\n\ndef test_is_num_primes_exceptions_manually():\n    \"\"\"Testing the function's defensive checks.\n\n    Here we have to repeat a fair bit of pytest boilerplate.\n    \"\"\"\n    with pytest.raises(TypeError, match=\"must be a positive integer.\"):\n        is_num_prime(1.0)\n    with pytest.raises(ValueError, match=\"must be a positive integer.\"):\n        is_num_prime(-1)\n\nWithin this function, I can run multiple assertions against several hard-coded inputs. I’m only checking against a couple of values here but production-ready code may test against many more cases. To do that, I’d need to have a lot of repeated pytest.raises statements. Perhaps more importantly, watch what happens when I run the test.\n% pytest -k \"test_is_num_primes_exceptions_manually\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 56 items / 55 deselected / 1 selected                                \n\ntests/test_primes.py .                                                   [100%]\n\n======================= 1 passed, 55 deselected in 0.01s ======================\n\nNotice that both assertions will either pass or fail together as one test. This could potentially make it more challenging to troubleshoot a failing pipeline. It could be better to have separate test functions for each value, but that seems like an awful lot of work…\n\n\n…Enter Parametrize\nNow to start using parametrize, we need to use the @pytest.mark.parametrize decorator, which takes 2 arguments, a string and an iterable.\n\n@pytest.mark.parametrize(\n    \"some_values, exception_types\", [(1.0, TypeError), (-1, ValueError)]\n    )\n\nThe string should contain comma separated values for the names that you would like to refer to when iterating through the iterable. They can be any placeholder you would wish to use in your test. These names will map to the index of elements in the iterable.\nSo when I use the fixture with a test, I will expect to inject the following values:\niteration 1… “some_values” = 1.0, “exception_types” = TypeError\niteration 2… “some_values” = -1, “exception_types” = ValueError\nLet’s go ahead and use this parametrized fixture with a test.\n\n@pytest.mark.parametrize(\n    \"some_values, exception_types\", [(1.0, TypeError), (-1, ValueError)]\n    )\ndef test_is_num_primes_exceptions_parametrized(some_values, exception_types):\n    \"\"\"The same defensive checks but this time with parametrized input.\n\n    Less lines in the test but if we increase the number of cases, we need to\n    add more lines to the parametrized fixture instead.\n    \"\"\"\n    with pytest.raises(exception_types, match=\"must be a positive integer.\"):\n        is_num_prime(some_values)\n\nThe outcome for running this test is shown below.\n% pytest -k \"test_is_num_primes_exceptions_parametrized\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 56 items / 54 deselected / 2 selected                                \n\ntests/test_primes.py ..                                                  [100%]\n\n======================= 2 passed, 54 deselected in 0.01s ======================\n\nIt’s a subtle difference, but notice that we now get 2 passing tests rather than 1? We can make this more explicit by passing the -v flag (for verbose) when we invoke pytest.\n% pytest -k \"test_is_num_primes_exceptions_parametrized\" -v \n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 \ncachedir: .pytest_cache\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 56 items / 54 deselected / 2 selected                                \n\ntest_is_num_primes_exceptions_parametrized[1.0-TypeError] PASSED         [ 50%]\ntest_is_num_primes_exceptions_parametrized[-1-ValueError] PASSED         [100%]\n\n======================= 2 passed, 54 deselected in 0.01s ======================\n\nIn this way, we get a helpful printout of the test and parameter combination being executed. This can be very helpful in identifying problem cases.\n\n\nYet More Cases\nNext up, we may wish to check return values for our function with several more cases. To keep things simple, let’s write a test that checks the return values for a range of numbers between 1 and 5.\n\ndef test_is_num_primes_manually():\n    \"\"\"Test several positive integers return expected boolean.\n\n    This is quite a few lines of code. Note that this runs as a single test.\n    \"\"\"\n    assert is_num_prime(1) == False\n    assert is_num_prime(2) == True\n    assert is_num_prime(3) == True\n    assert is_num_prime(4) == False\n    assert is_num_prime(5) == True\n\nOne way that this can be serialised is by using a list of parameters and expected results.\n\ndef test_is_num_primes_with_list():\n    \"\"\"Test the same values using lists.\n\n    Less lines but is run as a single test.\n    \"\"\"\n    answers = [is_num_prime(i) for i in range(1, 6)]\n    assert answers == [False, True, True, False, True]\n\nThis is certainly neater than the previous example. Although both implementations will evaluate as a single test, so a failing instance will not be explicitly indicated in the pytest report.\n% pytest -k \"test_is_num_primes_with_list\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 56 items / 55 deselected / 1 selected                               \n\ntests/test_primes.py .                                                   [100%]\n\n======================= 1 passed, 55 deselected in 0.01s ======================\nTo parametrize the equivalent test, we can take the below approach.\n\n@pytest.mark.parametrize(\n    \"some_integers, answers\",\n    [(1, False), (2, True), (3, True), (4, False), (5, True)]\n    )\ndef test_is_num_primes_parametrized(some_integers, answers):\n    \"\"\"The same tests but this time with parametrized input.\n\n    Fewer lines and 5 separate tests are run by pytest.\n    \"\"\"\n    assert is_num_prime(some_integers) == answers\n\nThis is slightly more lines than test_is_num_primes_with_list but has the advantage of being run as separate tests:\n% pytest -k \"test_is_num_primes_parametrized\" -v\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0\ncachedir: .pytest_cache\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 56 items / 51 deselected / 5 selected                               \n\ntests/test_primes.py::test_is_num_primes_parametrized[1-False] PASSED    [ 20%]\ntests/test_primes.py::test_is_num_primes_parametrized[2-True] PASSED     [ 40%]\ntests/test_primes.py::test_is_num_primes_parametrized[3-True] PASSED     [ 60%]\ntests/test_primes.py::test_is_num_primes_parametrized[4-False] PASSED    [ 80%]\ntests/test_primes.py::test_is_num_primes_parametrized[5-True] PASSED     [100%]\n\n======================= 5 passed, 51 deselected in 0.01s ======================\n\nWhere this approach really comes into its own is when the number of cases you need to test increases, you can explore ways of generating cases rather than hard-coding the values, as in the previous examples.\nIn the example below, we can use the range() function to generate the integers we need to test, and then zipping these cases to their expected return values.\n\n# if my list of cases is growing, I can employ other tactics...\nin_ = range(1, 21)\nout = [\n    False, True, True, False, True, False, True, False, False, False,\n    True, False, True, False, False, False, True, False, True, False,\n    ]\n\n\n@pytest.mark.parametrize(\"some_integers, some_answers\", zip(in_, out))\ndef test_is_num_primes_with_zipped_lists(some_integers, some_answers):\n    \"\"\"The same tests but this time with zipped inputs.\"\"\"\n    assert is_num_prime(some_integers) == some_answers\n\nRunning this test yields the following result:\n\n% pytest -k \"test_is_num_primes_with_zipped_lists\" -v \n============================= test session starts =============================\nplatform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0\ncachedir: .pytest_cache\nconfigfile: pyproject.toml\ntestpaths: ./tests\nplugins: anyio-4.0.0\ncollected 56 items / 36 deselected / 20 selected\n\n/test_primes.py::test_is_num_primes_with_zipped_lists[1-False] PASSED  [  5%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[2-True] PASSED   [ 10%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[3-True] PASSED   [ 15%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[4-False] PASSED  [ 20%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[5-True] PASSED   [ 25%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[6-False] PASSED  [ 30%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[7-True] PASSED   [ 35%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[8-False] PASSED  [ 40%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[9-False] PASSED  [ 45%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[10-False] PASSED [ 50%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[11-True] PASSED  [ 55%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[12-False] PASSED [ 60%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[13-True] PASSED  [ 65%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[14-False] PASSED [ 70%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[15-False] PASSED [ 75%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[16-False] PASSED [ 80%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[17-True] PASSED  [ 85%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[18-False] PASSED [ 90%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[19-True] PASSED  [ 95%]\n/test_primes.py::test_is_num_primes_with_zipped_lists[20-False] PASSED [100%]\n\n====================== 20 passed, 36 deselected in 0.02s ======================"
  },
  {
    "objectID": "blogs/13-pytest-parametrize.html#stacked-parametrization",
    "href": "blogs/13-pytest-parametrize.html#stacked-parametrization",
    "title": "Parametrized Tests With Pytest in Plain English",
    "section": "Stacked Parametrization",
    "text": "Stacked Parametrization\n\nParametrize gets really interesting when you have a situation where you need to test combinations of input parameters against expected outputs. In this scenario, stacked parametrization allows you to set up all combinations with very little fuss.\nFor this section, I will define a new function built on top of our is_num_prime() function. This function will take 2 positive integers and add them together, but only if both of the input integers are prime. Otherwise, we’ll simply return the input numbers. To keep things simple, we’ll always return a tuple in all cases.\n\ndef sum_if_prime(pos_int1: int, pos_int2: int) -&gt; tuple:\n    \"\"\"Sum 2 integers only if they are prime numbers.\n\n    Parameters\n    ----------\n    pos_int1 : int\n        A positive integer.\n    pos_int2 : int\n        A positive integer.\n\n    Returns\n    -------\n    tuple\n        Tuple of one integer if both inputs are prime numbers, else returns a\n        tuple of the inputs.\n    \"\"\"\n    if is_num_prime(pos_int1) and is_num_prime(pos_int2):\n        return (pos_int1 + pos_int2,)\n    else:\n        return (pos_int1, pos_int2)\n\nThen using this function with a range of numbers:\n\nfor i in range(1, 6):\n    print(f\"{i} and {i} result: {sum_if_prime(i, i)}\")\n\n1 and 1 result: (1, 1)\n2 and 2 result: (4,)\n3 and 3 result: (6,)\n4 and 4 result: (4, 4)\n5 and 5 result: (10,)\n\n\nTesting combinations of input parameters for this function will quickly become burdensome:\n\nfrom example_pkg.primes import sum_if_prime\n\n\ndef test_sum_if_prime_with_manual_combinations():\n    \"\"\"Manually check several cases.\"\"\"\n    assert sum_if_prime(1, 1) == (1, 1)\n    assert sum_if_prime(1, 2) == (1, 2)\n    assert sum_if_prime(1, 3) == (1, 3)\n    assert sum_if_prime(1, 4) == (1, 4)\n    assert sum_if_prime(1, 5) == (1, 5)\n    assert sum_if_prime(2, 1) == (2, 1)\n    assert sum_if_prime(2, 2) == (4,) # the first case where both are primes\n    assert sum_if_prime(2, 3) == (5,) \n    assert sum_if_prime(2, 4) == (2, 4)\n    assert sum_if_prime(2, 5) == (7,)\n    # ...\n\n% pytest -k \"test_sum_if_prime_with_manual_combinations\"\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 56 items / 55 deselected / 1 selected\n\ntests/test_primes.py .                                                   [100%]\n\n====================== 1 passed, 55 deselected in 0.01s =======================\n\n\nSingle Assertions\nBecause we take more than one input parameter, we can use stacked parametrization to easily inject all combinations of parameters to a test. Simply put, this means that we pass more than one parametrized fixture to the same test. Behind the scenes, pytest prepares all parameter combinations to inject into our test.\nThis allows us to very easily pass all parameter combinations to a single assertion statement, as in the diagram below.\n\n\n\nStacked parametrization against a single assertion\n\n\nTo use stacked parametrization against our sum_if_prime() function, we can use 2 separate iterables:\n\n@pytest.mark.parametrize(\"first_ints\", range(1,6))\n@pytest.mark.parametrize(\"second_ints\", range(1,6))\ndef test_sum_if_prime_stacked_parametrized_inputs(\n    first_ints, second_ints, expected_answers):\n    \"\"\"Using stacked parameters to set up combinations of all cases.\"\"\"\n    assert isinstance(sum_if_prime(first_ints, second_ints), tuple)\n\n\n% pytest -k \"test_sum_if_prime_stacked_parametrized_inputs\" -v\n============================= test session starts =============================\nplatform darwin -- Python 3.11.6, pytest-7.4.3, pluggy-1.3.0 \ncachedir: .pytest_cache\nconfigfile: pyproject.toml\ntestpaths: ./tests\nplugins: anyio-4.0.0\ncollected 56 items / 31 deselected / 25 selected\n\ntest_sum_if_prime_stacked_parametrized_inputs[1-1] PASSED                [  4%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-2] PASSED                [  8%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-3] PASSED                [ 12%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-4] PASSED                [ 16%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-5] PASSED                [ 20%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-1] PASSED                [ 24%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-2] PASSED                [ 28%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-3] PASSED                [ 32%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-4] PASSED                [ 36%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-5] PASSED                [ 40%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-1] PASSED                [ 44%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-2] PASSED                [ 48%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-3] PASSED                [ 52%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-4] PASSED                [ 56%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-5] PASSED                [ 60%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-1] PASSED                [ 64%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-2] PASSED                [ 68%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-3] PASSED                [ 72%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-4] PASSED                [ 76%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-5] PASSED                [ 80%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-1] PASSED                [ 84%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-2] PASSED                [ 88%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-3] PASSED                [ 92%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-4] PASSED                [ 96%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-5] PASSED                [100%]\n\n====================== 25 passed, 31 deselected in 0.01s ======================\n\n\n The above test; which is 6 lines long; executed 25 tests. This is clearly a very beneficial feature of pytest. However, the eagle-eyed among you may have spotted a problem - this is only going to work if the expected answer is always the same. The test we defined is only checking that a tuple is returned in all cases. How can we ensure that we serve the expected answers to the test too? This is where things get a little fiddly.\n\n\nMultiple Assertions\nTo test our function against combinations of parameters with different expected answers, we must employ a dictionary mapping of the parameter combinations as keys and the expected assertions as values.\n\n\n\nUsing a dictionary to map multiple assertions against stacked parametrized fixtures\n\n\nTo do this, we need to define a new fixture, which will return the required dictionary mapping of parameters to expected values.\n\n# Using stacked parametrization, we can avoid manually typing the cases out,\n# though we do still need to define a dictionary of the expected answers...\n@pytest.fixture\ndef expected_answers() -&gt; dict:\n    \"\"\"A dictionary of expected answers for all combinations of 1 through 5.\n\n    First key corresponds to `pos_int1` and second key is `pos_int2`.\n\n    Returns\n    -------\n    dict\n        Dictionary of cases and their expected tuples.\n    \"\"\"\n    expected= {\n        1: {1: (1,1), 2: (1,2), 3: (1,3), 4: (1,4), 5: (1,5),},\n        2: {1: (2,1), 2: (4,), 3: (5,), 4: (2,4), 5: (7,),},\n        3: {1: (3,1), 2: (5,), 3: (6,), 4: (3,4), 5: (8,),},\n        4: {1: (4,1), 2: (4,2), 3: (4,3), 4: (4,4), 5: (4,5),},\n        5: {1: (5,1), 2: (7,), 3: (8,), 4: (5,4), 5: (10,),},\n    }\n    return expected\n\nPassing our expected_answers fixture to our test will allow us to match all parameter combinations to their expected answer. Let’s update test_sum_if_prime_stacked_parametrized_inputs to use the parameter values to access the expected assertion value from the dictionary.\n\n@pytest.mark.parametrize(\"first_ints\", range(1,6))\n@pytest.mark.parametrize(\"second_ints\", range(1,6))\ndef test_sum_if_prime_stacked_parametrized_inputs(\n    first_ints, second_ints, expected_answers):\n    \"\"\"Using stacked parameters to set up combinations of all cases.\"\"\"\n    assert isinstance(sum_if_prime(first_ints, second_ints), tuple)\n    answer = sum_if_prime(first_ints, second_ints)\n    # using the parametrized values, pull out their keys from the\n    # expected_answers dictionary\n    assert answer == expected_answers[first_ints][second_ints]\n\nFinally, running this test produces the below pytest report.\n\n% pytest -k \"test_sum_if_prime_stacked_parametrized_inputs\" -v\n============================= test session starts =============================\nplatform darwin -- Python 3.12.3, pytest-8.1.1, pluggy-1.5.0 \ncachedir: .pytest_cache\nconfigfile: pyproject.toml\ntestpaths: ./tests\ncollected 56 items / 31 deselected / 25 selected\n\ntest_sum_if_prime_stacked_parametrized_inputs[1-1] PASSED                [  4%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-2] PASSED                [  8%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-3] PASSED                [ 12%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-4] PASSED                [ 16%]\ntest_sum_if_prime_stacked_parametrized_inputs[1-5] PASSED                [ 20%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-1] PASSED                [ 24%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-2] PASSED                [ 28%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-3] PASSED                [ 32%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-4] PASSED                [ 36%]\ntest_sum_if_prime_stacked_parametrized_inputs[2-5] PASSED                [ 40%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-1] PASSED                [ 44%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-2] PASSED                [ 48%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-3] PASSED                [ 52%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-4] PASSED                [ 56%]\ntest_sum_if_prime_stacked_parametrized_inputs[3-5] PASSED                [ 60%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-1] PASSED                [ 64%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-2] PASSED                [ 68%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-3] PASSED                [ 72%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-4] PASSED                [ 76%]\ntest_sum_if_prime_stacked_parametrized_inputs[4-5] PASSED                [ 80%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-1] PASSED                [ 84%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-2] PASSED                [ 88%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-3] PASSED                [ 92%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-4] PASSED                [ 96%]\ntest_sum_if_prime_stacked_parametrized_inputs[5-5] PASSED                [100%]\n\n====================== 25 passed, 31 deselected in 0.01s ======================"
  },
  {
    "objectID": "blogs/13-pytest-parametrize.html#summary",
    "href": "blogs/13-pytest-parametrize.html#summary",
    "title": "Parametrized Tests With Pytest in Plain English",
    "section": "Summary",
    "text": "Summary\nThere you have it - how to use basic and stacked parametrization in your tests. We have:\n\nused parametrize to inject multiple parameter values to a single test.\nused stacked parametrize to test combinations of parameters against a single assertion.\nused a nested dictionary fixture to map stacked parametrize input combinations to different expected assertion values.\n\nIf you spot an error with this article, or have a suggested improvement then feel free to raise an issue on GitHub.\nHappy testing!"
  },
  {
    "objectID": "blogs/13-pytest-parametrize.html#acknowledgements",
    "href": "blogs/13-pytest-parametrize.html#acknowledgements",
    "title": "Parametrized Tests With Pytest in Plain English",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo past and present colleagues who have helped to discuss pros and cons, establishing practice and firming-up some opinions. Particularly:\n\nCharlie\nEthan\nHenry\nSergio\n\nThe diagrams used in this article were produced with the excellent Excalidraw, with thanks to Mat for the recommendation.\n\nfin!"
  },
  {
    "objectID": "blogs/09-cycling-network-r5py.html#introduction",
    "href": "blogs/09-cycling-network-r5py.html#introduction",
    "title": "Bicycle Network Modelling with r5py",
    "section": "Introduction",
    "text": "Introduction\nr5py is a relatively new transport modelling package available on PyPI. It provides convenient wrappers to Conveyal’s r5 Java library, a performant routing engine originating from the ubiquitous Open Trip Planner (OTP). Whereas r5py may not be as feature-rich as OTP, its unique strength is in the production of origin:destination matrices at scale. This is important if the intention is to produce stable statistics based on routing algorithms, where the idiosyncrasies of local transport service availability means that departure times can have a significant impact upon overall journey duration.\nr5py achieves stable statistics by calculating travel times over multiple journeys within a time window, returning summaries such as the median travel time from point A to B.\n\n\n\n\n\n\nA Note on the Purpose\n\n\n\nThis tutorial aims to familiarise the reader with r5py and how it integrates with the python geospatial ecosystem of packages. This article is not to be used to attempt to infer service quality outcomes. Limitations of this analysis and suggested improvements will be discussed throughout.\n\n\n\nIntended Audience\nExperienced python practitioners with a robust working knowledge of the typical python GIS stack, eg geopandas, shapely and folium and coordinate reference systems (CRS). Familiarity with r5py is not assumed.\n\n\nOutcomes\n\nIngest London bike charging station locations.\nVisualise charging stations in an interactive hex map.\nGenerate a naive point plane of destinations.\nCheck that the point plane is large enough to accommodate station locations.\nAdjust point plane locations to ensure routability.\nCalculate origin:destination travel time matrix, by cycling modality and with a maximum journey time of 30 minutes.\nEngineer features to help analyse the cycling network accessibility.\nVisualise the cycling network coverage and the most remote points within that area.\n\n\n\nWhat You’ll Need:\n\nConda or miniconda\npip package manager\nAbility to install Java Development Kit\nAbility to request from Transport for London api\nTutorial compatible with macos. subprocess calls may require adaptation for other operating systems.\n\n\n\nrequirements.txt\n\ncontextily\ngeopandas\nhaversine\nfolium\nmapclassify\nmatplotlib\npydeck\npyproj\nr5py\nrequests\nscikit-learn\n\n\n\nConfiguring Java\nIt is required to configure a Java Virtual Machine for this tutorial. The transport routing depends on this. Please consult the r5py installation documentation [1] for guidance. In order to check that you have a compatible Java environment, run r5py.TransportNetwork(osm_pth) after exercise 1. For reference, I have used OpenJDK to manage my Java instance:\nopenjdk 11.0.19 2023-04-18 LTS\nOpenJDK Runtime Environment Corretto-11.0.19.7.1 (build 11.0.19+7-LTS)\nOpenJDK 64-Bit Server VM Corretto-11.0.19.7.1 (build 11.0.19+7-LTS, mixed mode)"
  },
  {
    "objectID": "blogs/09-cycling-network-r5py.html#london-cycle-station-service-coverage",
    "href": "blogs/09-cycling-network-r5py.html#london-cycle-station-service-coverage",
    "title": "Bicycle Network Modelling with r5py",
    "section": "London Cycle Station Service Coverage",
    "text": "London Cycle Station Service Coverage\nStart by loading the required packages.\n\nfrom datetime import datetime, timedelta\nimport os\nimport subprocess\nimport tempfile \nfrom typing import Union\n\nimport contextily as ctx\nimport folium\nimport geopandas as gpd\nfrom haversine import haversine, Unit\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pydeck as pdk\nimport pyproj\nimport r5py\nimport requests\nfrom sklearn import preprocessing\nfrom shapely.geometry import LineString, Point, Polygon\n\n\nStreet Network Data\nFirstly, we must acquire information about the transport network. There are a few sources of this, but we shall use the BBBikes website to ingest London-specific OpenStreetMap extracts. The required data should be in protocol buffer (.pbf) format.\n\nExercise 1\nFind the appropriate url that points to the london.osm.pbf file. Ingest the data and store at an appropriate location.\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\nEither using python requests or subprocess with the curl command, request the url of the pbf file and output the response to a data folder.\n\n\n\n\n\nSolution\n\n\nShow the code\n# As the osm files are large, I will use a tmp directory, though feel free to\n# store the data wherever you like.\ntmp = tempfile.TemporaryDirectory()\nosm_pth = os.path.join(tmp.name, \"london.osm.pbf\")\nsubprocess.run(\n    [\n        \"curl\",\n        \"https://download.bbbike.org/osm/bbbike/London/London.osm.pbf\",\n        \"-o\",\n        osm_pth,\n    ]\n)\n\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0 45  103M   45 47.4M    0     0  43.0M      0  0:00:02  0:00:01  0:00:01 43.0M100  103M  100  103M    0     0  49.8M      0  0:00:02  0:00:02 --:--:-- 49.8M\n\n\nCompletedProcess(args=['curl', 'https://download.bbbike.org/osm/bbbike/London/London.osm.pbf', '-o', '/var/folders/qc/rrswmfbx1_v0sxklq1kr28jw0000gp/T/tmprnd4etkn/london.osm.pbf'], returncode=0)\n\n\n\n\n\nBike Charging Station Locations\n\nExercise 2\nTo get data about the bike charging stations in London, we will query Transport for London’s BikePoint API.\n\nExplore the site and find the correct endpoint to query.\nThe tutorial requires the following fields: station ID, the human-readable name, latitude and longitude for each available station.\nStore the data in a geopandas geodataframe with the appropriate coordinate reference system.\nInspect the head of the geodataframe.\n\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\n\nUsing the requests package, send a get request to the endpoint.\nStore the required fields in a list: “id”, “commonName”, “lat”, “lon”.\nCheck that the response returned HTTP status 200. If True, get the content in JSON format.\nCreate an empty list to store the station data.\nIterate through the content dictionaries. If a key is present within the required fields, store the key and value within a temporary dictionary.\nAppend the dictionary of required fields and their values to the list of stations.\nConvert the list of dictionaries to a pandas dataframe. Then convert this to a geopandas geodataframe, using the coordinate reference system “EPSG:4326”. As we have lat and lon in separate columns, use geopandas points_from_xy(), ensuring you pass values in the order of longitude, latitude.\nPrint out the head of the stations gdf.\n\n\n\n\n\n\nSolution\n\n\nShow the code\nENDPOINT = \"https://api.tfl.gov.uk/BikePoint/\"\nresp = requests.get(ENDPOINT)\nif resp.ok:\n    content = resp.json()\nelse:\n    raise requests.exceptions.HTTPError(\n        f\"{resp.status_code}: {resp.reason}\"\n    )\n\nneeded_keys = [\"id\", \"commonName\", \"lat\", \"lon\"]\nall_stations = list()\nfor i in content:\n    node_dict = dict()\n    for k, v in i.items():\n        if k in needed_keys:\n            node_dict[k] = v\n    all_stations.append(node_dict)\n\nstations = pd.DataFrame(all_stations)\nstation_gdf = gpd.GeoDataFrame(\n    stations,\n    geometry=gpd.points_from_xy(stations[\"lon\"], stations[\"lat\"]),\n    crs=4326,\n)\n\nstation_gdf.head()\n\n\n\n\n\n\n\n\n\nid\ncommonName\nlat\nlon\ngeometry\n\n\n\n\n0\nBikePoints_1\nRiver Street , Clerkenwell\n51.529163\n-0.109970\nPOINT (-0.10997 51.52916)\n\n\n1\nBikePoints_2\nPhillimore Gardens, Kensington\n51.499606\n-0.197574\nPOINT (-0.19757 51.49961)\n\n\n2\nBikePoints_3\nChristopher Street, Liverpool Street\n51.521283\n-0.084605\nPOINT (-0.08460 51.52128)\n\n\n3\nBikePoints_4\nSt. Chad's Street, King's Cross\n51.530059\n-0.120973\nPOINT (-0.12097 51.53006)\n\n\n4\nBikePoints_5\nSedding Street, Sloane Square\n51.493130\n-0.156876\nPOINT (-0.15688 51.49313)\n\n\n\n\n\n\n\nThat’s all the external data needed for this tutorial. Let’s now examine the station locations.\n\n\n\nStation Density\nAs the stations are densely located in and around central London, a standard matplotlib point map would suffer from overplotting. A better way is to present some aggregated value on a map, such as density.\n\nExercise 3\nPlot the density of cycle station locations on a map. The solution will use pydeck, but any visualisation library that can handle geospatial data would be fine.\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\n\nCreate a pydeck hexagon layer based on the station_gdf. The hexagon layer should be configured as below:\n\n\nextruded\nposition from lon and lat columns\nelevation scale is 100\nelevation range from 0 through 100\ncoverage is 1\nradius of hexagons is 250 metres\n\n\nCreate a pydeck view state object to control the initial position of the camera. Configure this as you see fit.\n(Optional) Add a custom tooltip, clarifying that the hexagon elevation is equal to the count of stations within that area. You may wish to consult the deck.gl documentation to help implement this.\nCreate a deck with the hexagon layer, custom view state, tooltip and a map style of your choosing.\n\n\n\n\n\n\nSolution\n\n\nShow the code\n# pydeck visuals - concentration of charging stations by r250m hex\nlayer = pdk.Layer(\n    \"HexagonLayer\",\n    station_gdf,\n    pickable=True,\n    extruded=True,\n    get_position=[\"lon\", \"lat\"],\n    auto_highlight=True,\n    elevation_scale=100,\n    elevation_range=[0, 100],\n    coverage=1,\n    radius=250,  # in metres, default is 1km\n    colorRange=[\n        [255, 255, 178, 130],\n        [254, 217, 118, 130],\n        [254, 178, 76, 130],\n        [253, 141, 60, 130],\n        [240, 59, 32, 130],\n        [189, 0, 38, 130],\n    ], # optionally added rgba values to allow transparency\n)\nview_state = pdk.ViewState(\n    # longitude=-0.140,# value for iframe\n    longitude=-0.070,# value for code chunk\n    latitude=51.535, \n    # zoom=10, # value for iframe\n    zoom=10.5, # value for code chunk\n    min_zoom=5,\n    max_zoom=15,\n    pitch=40.5,\n    bearing=-27.36,\n)\ntooltip = {\"html\": \"&lt;b&gt;n Stations:&lt;/b&gt; {elevationValue}\"}\nr = pdk.Deck(\n    layers=[layer],\n    initial_view_state=view_state,\n    tooltip=tooltip, # prettier than default tooltip\n    map_style=pdk.map_styles.LIGHT,\n)\nr\n\n\n\n        \n    \n\n\n\n\n\nGenerate Destinations\nWe can use the bike stations as journey origins. To compute travel times, we need to generate destination locations. This tutorial uses a simple approach to generating equally spaced points within a user-defined bounding box.\n\n\n\n\n\n\nLimitation\n\n\n\nGenerating a point plane is a fast way to get a travel time matrix. However, this is naive to locations that the riders would prefer to start or finish their journeys. A more robust approach would be to use locations of retail or residential features. The European Commission’s Global Human Settlement Layer [2] data would provide centroids to every populated grid cell down to a 10m2 resolution.\n\n\n\nExercise 4\nWrite a function called create_point_grid() that will take the following parameters:\n\nbbox_list expecting a bounding box list in [xmin, ymin, xmax, ymax] format with epsg:4326 longitude & latitude values.\nstepsize expecting a positive integer, specifying the spacing of the grid points in metres.\n\ncreate_point_grid() should return a geopandas geodataframe of equally spaced point locations - the point grid. The grid point locations should be in epsg:4326 projection. The geodataframe requires a geometry column and an id column equal to the index of the dataframe (required for r5py origin:destination matrix calculation).\nOnce you are happy with the function, use it to produce an example geodataframe and explore() a folium map of the point grid.\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\nNote that epsg:4326 is a geodetic projection, unsuitable for measuring distance between points in the point plane. Ensure that the crs is re-projected to an appropriate planar crs for distance calculation.\n\nStore the South-West and North-East coordinates as shapely.geometry.Point objects.\nUse pyproj.Transformer.from_crs() to create 2 transformers, one from geodetic to planar, and the other back from planar to geodetic.\nUse the transformers to convert the SW and NE points from geodetic to planar.\nUse nested loops to iterate over the area between the corner points. Store the point location as a shapely.geometry.Point object. Append the point to a list of grid points.\nIncrement the x and y values by the provided stepsize and continue to append points in this fashion until xmin has reached the xmax value and ymin has met the ymax value.\nEnsure the stored coordinates are converted back to epsg:4326.\nCreate a pandas dataframe with the geometry column using the appended point locations and an id column that uses the range() function to generate a unique integer value for each row.\nUse the defined function with a sample bounding box and explore the resulting geodataframe with an interactive folium map.\n\n\n\n\n\n\nSolution\n\n\nShow the code\ndef create_point_grid(bbox_list: list, stepsize: int) -&gt; gpd.GeoDataFrame:\n    \"\"\"Create a metric point plane for a given bounding box.\n\n    Return a geodataframe of evenly spaced points for a specified bounding box.\n    Distance between points is controlled by stepsize in metres.  As\n    an intermediate step requires transformation to epsg:27700, the calculation\n    of points is suitable for GB only.\n\n    Parameters\n    ----------\n    bbox_list : list\n        A list in xmin, ymin, xmax, ymax order. Expected to be in epsg:4326.\n        Use https://boundingbox.klokantech.com/ or similar to export a bbox.\n    stepsize : int\n        Spacing of grid points in metres. Must be larger than zero.\n\n    Returns\n    -------\n    gpd.GeoDataFrame\n        GeoDataFrame in epsg:4326 of the point locations.\n\n    Raises\n    ------\n    TypeError\n        bbox_list is not type list.\n        Coordinates in bbox_list are not type float.\n        step_size is not type int.\n    ValueError\n        bbox_list is not length 4.\n        xmin is greater than or equal to xmax.\n        ymin is greater than or equal to ymax.\n        step_size is not a positive integer.\n\n    \"\"\"\n    # defensive checks\n    if not isinstance(bbox_list, list):\n        raise TypeError(f\"bbox_list expects a list. Found {type(bbox_list)}\")\n    if not len(bbox_list) == 4:\n        raise ValueError(f\"bbox_list expects 4 values. Found {len(bbox_list)}\")\n    for coord in bbox_list:\n        if not isinstance(coord, float):\n            raise TypeError(\n                f\"Coords must be float. Found {coord}: {type(coord)}\"\n            )\n    # check points are ordered correctly\n    xmin, ymin, xmax, ymax = bbox_list\n    if xmin &gt;= xmax:\n        raise ValueError(\n            \"bbox_list value at pos 0 should be smaller than value at pos 2.\"\n        )\n    if ymin &gt;= ymax:\n        raise ValueError(\n            \"bbox_list value at pos 1 should be smaller than value at pos 3.\"\n        )\n    if not isinstance(stepsize, int):\n        raise TypeError(f\"stepsize expects int. Found {type(stepsize)}\")\n    if stepsize &lt;= 0:\n        raise ValueError(\"stepsize must be a positive integer.\")\n\n    # Set up crs transformers. Need a planar crs for work in metres - use BNG\n    planar_transformer = pyproj.Transformer.from_crs(4326, 27700)\n    geodetic_transformer = pyproj.Transformer.from_crs(27700, 4326)\n    # bbox corners\n    sw = Point((xmin, ymin))\n    ne = Point((xmax, ymax))\n    # Project corners to planar\n    planar_sw = planar_transformer.transform(sw.x, sw.y)\n    planar_ne = planar_transformer.transform(ne.x, ne.y)\n    # Iterate over metric plane\n    points = []\n    x = planar_sw[0]\n    while x &lt; planar_ne[0]:\n        y = planar_sw[1]\n        while y &lt; planar_ne[1]:\n            p = Point(geodetic_transformer.transform(x, y))\n            points.append(p)\n            y += stepsize\n        x += stepsize\n    df = pd.DataFrame({\"geometry\": points, \"id\": range(0, len(points))})\n    gdf = gpd.GeoDataFrame(df, crs=4326)\n    return gdf\n\ncreate_point_grid(\n  bbox_list=[-0.5917,51.2086,0.367,51.7575], stepsize=5000).explore(min_zoom=9)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\n\nStudy Area Size\nBefore we go ahead with the transport modelling, it is important to check that the point plane is large enough to contain a 30 minute journey from any of the stations. 30 minutes is the current charging interval for the pay as you ride options [3]. Note that making the point plane larger or the step size smaller means more travel times to calculate, so there is a compromise to be met. Using too small a grid will introduce edge effects [4] and therefore limit the validity of the study.\n\nExercise 5\nCheck that the point plane study area is large enough to accommodate an estimation of reachable area from the station locations.\n\n\nPart 1\n\nCreate a point_plane object with create_point_grid() that has a bounding box of your choosing. Use a stepsize of 1000 metres.\nGet the boundary polygon of this point plane. This is the study area.\nBuffer the bike station locations. This buffered area should represent the reachable area from within a 30 minute ride of any station and a presumed average urban cycle speed of 18 kilometres per hour (an opinionated speed based on a sample of one overweight, middle-aged man’s Strava data). Store the geometry as a Polygon object.\nCheck that the study area completely contains the buffered stations.\n\n\n\nPart 2\nCreate a diagnostic plot displaying the station locations, buffered station polygon and study area polygon together on one map.\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\nPart 1\nFor this exercise, you may find the Klokantech bounding box tool useful. Ensure that the output is formatted as csv.\n\nCreate a point plane of your choosing. Use the total_bounds attribute to extract values for minx, miny, maxx, maxy.\nUse shapely.geometry.Polygon to convert the 4 values above into a rectangular bounding box.\nRe-project the stations geodataframe to a planar crs. Buffer this geodataframe by an appropriate value in metres, convert back to epsg:4326 and store the unary union.\nCheck that the study area polygon completely contains the buffered station polygon by using an appropriately named GeoDataFrame method.\n\nPart 2\n\nPlot the stations gdf using marker values “o”, an alpha of 0.5, markersize of 10 and red colour. Store in a variable called ax.\nPlot the study area boundary polygon, ensuring the ax value from the previous step is used. Use an alpha of 0.2.\nAdd a plot of the buffered stations to the same axes, ensuring a colour “red” and an alpha of 0.2.\nUse contextily to add a basemap to the axes, selecting an appropriate crs value and tile provider.\nUse matplotlib.pyplot to show the plot.\n\n\n\n\n\n\nSolution\nPart 1\n\n\nShow the code\npoint_plane = create_point_grid(\n    [-0.4, 51.35, 0.15, 51.65], stepsize=1000\n)\n# Get a boundary polygon for the study area\nminx, miny, maxx, maxy = point_plane.total_bounds\nbbox_polygon = gpd.GeoSeries(\n    [Polygon([(minx, miny), (minx, maxy), (maxx, maxy), (maxx, miny)])]\n)\n# buffer the stations by presumed urban cycle speed of 18 kph\nstation_buffer = gpd.GeoSeries(\n    Polygon(\n      station_gdf.to_crs(27700).buffer(9000).to_crs(4326).geometry.unary_union\n      )\n)\ncond = bbox_polygon.contains(station_buffer)[0]\nprint(\n  f\"Point grid contains buffered stations? {cond}\")\n\n\nPoint grid contains buffered stations? True\n\n\nPart 2\n\n\nShow the code\nax = station_gdf.plot(marker=\"o\", color=\"red\", alpha=0.5, markersize=10)\n# plot the bounding box of the point plane boundary in blue\nbbox_polygon.plot(ax=ax, alpha=0.2, edgecolor=\"black\")\n# plot the buffered potential travel region around the stations\n# in light red\nstation_buffer.plot(ax=ax, alpha=0.2, color=\"red\")\nctx.add_basemap(\n    ax, crs=station_gdf.crs.to_string(), source=ctx.providers.CartoDB.Positron\n)\nplt.show()\n\n\n\n\n\n\n\n\n\nWith a study area adequately encompassing the proposed reachable area, proceed to the transport routing.\n\n\n\nRoutability\nAs we have created a point plane naive to the transport network, it is important to check that the points are reachable by bike. Any point falling within an inaccessible portion of the transport network will report a null travel time. r5py comes with a utility function that helps to ‘snap’ unreachable locations to the nearest feature of the travel network.\n\nExercise 6\n\n\nPart 1\nUsing the r5py quickstart documentation, instantiate a transport_network object, passing osm_pth as its single argument.\n\n\nPart 2\n\nNow using the r5py advanced use section, create a new column in the point_plane gdf called snapped_geometry.\nUse the correct method of the transport_network to adjust the existing geometry column.\nUse a maximum search radius of 500 metres and specify the bicycle modality. Inspect the resulting geodataframe.\n\n\n\nPart 3\nNow that we have a point plane with a routable geography, we can check to ensure that the maximum search radius was observed.\n\nCalculate the haversine distance in metres between the original geometry and the snapped_geometry coordinates.\nAssign the result to point_plane[\"snap_dist_m\"].\nInspect the distribution of the snap_dist_m column. Confirm that there are no values above the maximum search radius value.\n\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\nPart 1\n\nr5py is imported as r5py. You can inspect the available classes by using the dir() function.\n\nPart 2\n\nUse dir() on the transport_network object instantiated in part 1 to find the appropriate method for snapping the coordinates to the nearest network feature.\nSpecify the radius argument with an appropriate value.\nFor the street_mode argument, select the appropriate r5py transport mode. To find this value, use dir(r5py.TransportMode).\n\nPart 3\n\nThe haversine function is imported. Unfortunately, it expects coordinates to be in a latitude, longitude order.\nApply a lambda function across every row in the point_plane GeoDataFrame. You will need to specify axis=1 to achieve this.\nWithin the lambda function, calculate the haversine distance in metres between the original coordinates and the snapped_geometry coordinates. Assign the output to the correctly named column.\nInspect the distribution of the haversine distances in whichever way you feel. Can you confirm that no coordinate was adjusted beyond the maximum search radius used when you instantiated the snapped_geometry column?\n\n\n\n\n\n\nSolution\n\n\nPart 1\n\n\nShow the code\ntransport_network = r5py.TransportNetwork(osm_pth)\n\n\nThis may seem like a small step, but if this passed, then you have correctly configured your Java Virtual Machine.\n\n\nPart 2\n\n\nShow the code\npoint_plane[\"snapped_geometry\"] = transport_network.snap_to_network(\n    point_plane[\"geometry\"],\n    radius=500,\n    street_mode=r5py.TransportMode.BICYCLE,\n)\npoint_plane.head()\n\n\n\n\n\n\n\n\n\ngeometry\nid\nsnapped_geometry\n\n\n\n\n0\nPOINT (-0.40000 51.35000)\n0\nPOINT (-0.40010 51.34960)\n\n\n1\nPOINT (-0.39463 51.34995)\n1\nPOINT (-0.39420 51.34960)\n\n\n2\nPOINT (-0.38926 51.34990)\n2\nPOINT (-0.38927 51.35027)\n\n\n3\nPOINT (-0.38390 51.34985)\n3\nPOINT (-0.38468 51.35024)\n\n\n4\nPOINT (-0.37853 51.34980)\n4\nPOINT (-0.37851 51.34984)\n\n\n\n\n\n\n\n\n\nPart 3\n\n\nShow the code\n# reverse the lonlat to latlon\npoint_plane[\"snap_dist_m\"] = point_plane.apply(\n    lambda row:haversine(\n        (row[\"geometry\"].y, row[\"geometry\"].x),\n        (row[\"snapped_geometry\"].y, row[\"snapped_geometry\"].x),\n        unit=Unit.METERS), axis=1)\n\npoint_plane[\"snap_dist_m\"].plot.hist(\n    bins=100,\n    title=\"Distribution of coordinate snap distance in point plane (m)\"\n    )\n\n\n\n\n\n\n\n\n\nHere we can confirm that the distribution of the haversine distances is strongly right-skewed. There appear to be no values greater than 450 metres.\n\npoint_plane[\"snap_dist_m\"].describe()\n\ncount    5871.000000\nmean       42.857620\nstd        56.671823\nmin         0.013986\n25%        11.194528\n50%        24.091469\n75%        48.486417\nmax       491.635701\nName: snap_dist_m, dtype: float64\n\n\nIn describing the column we can observe the actual maximum haversine distance of 492 metres. Note the differences in the mean and median are attributable to the strong skew in the distance distribution.\nThe spatial adjustment caused by the snapping can be visualised. This is useful for sanity-checking and edge-case investigation.\n\n\nExercise 7\n\n\nPart 1\n\nCreate a deep copy of the point_plane geodataframe and assign to a new object called largest_snaps.\nRetrieve the rows with the largest 100 snap_dist_m values. Visualising the points is expensive, so we will only display a subset.\nApply a lambda function over largest_snaps, creating a LineString between each geometry and snapped_geometry value. This will be used to draw a line between each point on a map.\nAssign the output to largest_snaps[\"lines\"].\nInspect the head of the resultant geodataframe.\n\n\n\nPart 2\n\nPlot largest_snaps on a folium map. Add a marker layer with red icons showing the locations of the original point plane geometry.\nAdd a second marker layer to the same folium map, adding the snapped geometry with a green marker.\nAdd the final layer to the map - the lines connecting the geometries to their snapped equivalents.\nShow the map.\n\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\nPart 1\n\nSort ascending the largest_snaps geodataframe by snap_dist_m. Take the top 100 records only.\nLineString takes 2 arguments, a start and end point coordinate.\nApply the LineString logic over each row in the geodataframe, ensuring the axis argument is set to 1.\nFor each row, pass the geometry column value to LineString as the first argument, and the snapped_geometry value as the second.\nAssign the returned value to an appropriately named column.\n\nPart 2\nThis exercise will exploit the kwargs available through the GeoDataFrame.explore() method. Alternatively, the map can be built from scratch using the folium library.\n\nCall explore on largest_snaps, specifying a “marker” marker_type. Use the marker_kwds parameter to pass a dictionary specifying which font-awesome icon to use for the geometry points. Assign the map to imap.\nSet the geometry to the snapped_geometry column and repeat the above process, this time specifying green markers for the points. Ensure the m parameter is set to imap in order to add this to the same map object.\nLastly, set the geometry to the lines column and explore, again setting m=imap to add the line geometries to the interactive map. Specify an appropriate zoom level.\nShow the map and explore the adjusted geometries.\n\n\n\n\n\n\nSolution\n\n\nPart 1\n\n\nShow the code\nlargest_snaps = point_plane.copy(deep=True)\n# retrieve the top 100 rows where coordinates adjusted by the greatest dist.\nlargest_snaps = largest_snaps.sort_values(\n    by=\"snap_dist_m\", ascending=False).head(100)\n# create the LineString geometry\nlargest_snaps[\"lines\"] = largest_snaps.apply(\n    lambda row: LineString([row[\"geometry\"], row[\"snapped_geometry\"]]),\n    axis=1\n)\nlargest_snaps.head()\n\n\n\n\n\n\n\n\n\ngeometry\nid\nsnapped_geometry\nsnap_dist_m\nlines\n\n\n\n\n825\nPOINT (-0.39423 51.39259)\n825\nPOINT (-0.39746 51.39652)\n491.635701\nLINESTRING (-0.39423 51.39259, -0.39746 51.39652)\n\n\n5388\nPOINT (-0.22671 51.62509)\n5388\nPOINT (-0.22553 51.62089)\n473.637347\nLINESTRING (-0.22671 51.62509, -0.22553 51.62089)\n\n\n5557\nPOINT (0.12522 51.62996)\n5557\nPOINT (0.11988 51.62753)\n457.484858\nLINESTRING (0.12522 51.62996, 0.11988 51.62753)\n\n\n5839\nPOINT (-0.01873 51.64566)\n5839\nPOINT (-0.02477 51.64732)\n455.327799\nLINESTRING (-0.01873 51.64566, -0.02477 51.64732)\n\n\n5632\nPOINT (-0.02407 51.63508)\n5632\nPOINT (-0.03049 51.63476)\n444.667055\nLINESTRING (-0.02407 51.63508, -0.03049 51.63476)\n\n\n\n\n\n\n\n\n\nPart 2\n\n\nShow the code\n# layer 1\nz_start = 9\nimap = largest_snaps.explore(\n    marker_type=\"marker\",\n    marker_kwds={\n        \"icon\": folium.map.Icon(color=\"red\", icon=\"ban\", prefix=\"fa\"),\n    },\n    map_kwds={\n        \"center\": {\"lat\": 51.550, \"lng\": -0.070}\n    },\n    zoom_start=z_start,\n)\n# layer 2\nimap = largest_snaps.set_geometry(\"snapped_geometry\").explore(\n    m=imap,\n    marker_type=\"marker\",\n    marker_kwds={\n        \"icon\": folium.map.Icon(color=\"green\", icon=\"bicycle\", prefix=\"fa\"),\n    }\n)\n# layer 3\nimap = largest_snaps.set_geometry(\"lines\").explore(\n    m=imap,\n    zoom_start=z_start\n)\nimap\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "blogs/09-cycling-network-r5py.html#travel-times",
    "href": "blogs/09-cycling-network-r5py.html#travel-times",
    "title": "Bicycle Network Modelling with r5py",
    "section": "Travel Times",
    "text": "Travel Times\nNow that we have everything we need to carry out the transport routing, there is one final adjustment to the point plane - ensure that the snapped geometries are set as the geometry column. The snapped distance and original geometry column can be removed.\n\npoint_plane.drop(columns=[\"geometry\", \"snap_dist_m\"], axis=1, inplace=True)\npoint_plane.rename(columns={\"snapped_geometry\": \"geometry\"}, inplace=True)\npoint_plane.set_geometry(\"geometry\", inplace=True)\npoint_plane.head()\n\n\n\n\n\n\n\n\nid\ngeometry\n\n\n\n\n0\n0\nPOINT (-0.40010 51.34960)\n\n\n1\n1\nPOINT (-0.39420 51.34960)\n\n\n2\n2\nPOINT (-0.38927 51.35027)\n\n\n3\n3\nPOINT (-0.38468 51.35024)\n\n\n4\n4\nPOINT (-0.37851 51.34984)\n\n\n\n\n\n\n\n\nCompute the Travel Time Matrix\nNow we use r5py to compute the travel times from the station locations to the adjusted point plane.\nSome notes on the parameters:\n\ntransport_modes takes a list of modes. For simplicity, only BICYCLE is used, though combining with WALK would allow routing through portions of the travel network tagged as pedestrian-only.\ndeparture_time takes a datetime that signifies the first trip start time and date. This should ideally match the date that you ingested the osm file, as the osm files will best represent the real-world state of the transport network.\ndeparture_time_window creates a time window to carry out routing operations. The first journey occurs at 8am, as specified by departure. Then r5py processes a journey at every minute until the departure_time_window is met. By default, r5py returns the median travel time across these journeys. This feature provides stable statistics, particularly when working with bus or train timetable data.\nThe points can be snapped during the computation job, by specifying snap_to_network=True. As we have already specified how to do this, we can set this to False.\nmax_time takes a timedelta object. Here we specify that the journeys should take no longer than 30 minutes, as this is the current hire charge period for the bikes.\nThe compute_travel_times method returns a pandas DataFrame of median travel times for every origin, destination combination.\n\nThis step can be expensive, depending on the size of your point plane. Don’t be alarmed by NaN in the travel_time column. These are points in the point plane that were not reachable from any bike station.\n\ndept_time = datetime.now().replace(hour=8, minute=0, second=0, microsecond=0)\n\ntravel_time_matrix = r5py.TravelTimeMatrixComputer(\n    transport_network,\n    origins=station_gdf,\n    destinations=point_plane,\n    transport_modes=[r5py.TransportMode.BICYCLE],\n    departure=dept_time,\n    departure_time_window=timedelta(minutes=10),\n    snap_to_network=False,\n    max_time=timedelta(minutes=30),\n).compute_travel_times()\n\ntravel_time_matrix.dropna().head()\n\n\n\n\n\n\n\n\nfrom_id\nto_id\ntravel_time\n\n\n\n\n2938\nBikePoints_1\n2938\n29.0\n\n\n2939\nBikePoints_1\n2939\n28.0\n\n\n3038\nBikePoints_1\n3038\n29.0\n\n\n3039\nBikePoints_1\n3039\n29.0\n\n\n3040\nBikePoints_1\n3040\n30.0\n\n\n\n\n\n\n\n\n\nFeature Engineering\nIn order to produce some informative visuals, the travel time matrix will need some summarisation and feature engineering.\n\nExercise 8\nProduce a table called med_tts with the following spec:\nid                       int64\ngeometry              geometry\nmedian_tt              float64\nn_stations_serving       int16\nn_stations_norm        float64\ninverted_med_tt        float64\nlisted_geom             object\n\n\nPart 1\n\nCalculate the median travel time for every point in the point plane across the stations, call the column median_tt.\nCalculate the number of bike stations that can reach each point in the point plane. Ensure that this column is formatted as “int16” and is called n_stations_serving.\nJoin the medians and number of stations to point_plane on to_id.\n\n\n\nPart 2\n\nUse a minmax scaler to scale the number of stations serving each point in the point plane. Assign this to med_tts[\"n_stations_norm\"].\nCalculate inverteded values for the median travel time. Use the same scaling as the previous step and assign to med_tts[\"inverted_med_tt\"].\nCreate a column with a list of the coordinate for each row, in [long, lat] order. This is the geometry format expected by pydeck. Assign this to med_tts[\"listed_geom\"].\n\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\nPart 1\n\nTo create the median travel times across bike stations, group by the to_id column and calculate the median.\nTo get the number of stations reaching each point, group by the to_id column and count the number of from_id values.\nJoin the above grouped dataframes to the point plane dataframe, using the to_id column as the search key. Ensure the columns are named as specified in the exercise.\nCast n_stations_serving to int16. First, ensure that NaNs get encoded as 0. To do this, create a boolean mask where that column is na and assign the column values that meet that boolean index to 0. Then casting to int will be possible.\n\nPart 2\n\nInstantiate a min_max_scaler using an appropriate class from sklearn.\nReshape the values of n_stations_serving into a 2D numpy array, containing enough rows for each value.\nUsing the min_max_scaler, transform the numpy array.\nFlatten the output of min_max_scaler and assign to a column called n_stations_norm.\nCreate a new column inverted_med_tt, which subtracts all median_tt values from the maximum value in that column.\nScale inverted_med_tt by repeating steps 2 through 4 for this column.\nUse a list comprehension to extract each of the geometry coordinate values as a long,lat list. Assign to listed_geom.\n\n\n\n\n\n\nSolution\n\n\nShow the code\ndef get_median_tts_for_all_stations(\n    tt: pd.DataFrame, pp: gpd.GeoDataFrame\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Join travel times point geometries & calculate medians.\n\n    Parameters\n    ----------\n    tt : pd.DataFrame\n        Matrix of travel times where `from_id` are stations and `to_id` are\n        points in the point plane.\n    pp : gpd.GeoDataFrame\n        Locations in the point plane.\n\n    Returns\n    -------\n    gpd.GeoDataFrame\n        Point plane locations with median travel times from stations and number\n        of stations serving each point.\n\n    \"\"\"\n    #----- Part 1 -----\n    # get median travel time from all stations:\n    med_tts = tt.groupby(\"to_id\")[\"travel_time\"].median()\n    # get number of stations serving each point in the grid\n    tt_dropna = tt.dropna()\n    n_stations = tt_dropna.groupby(\"to_id\")[\"from_id\"].count()\n    df = pp.join(med_tts).join(n_stations)\n    df = df.rename(\n        columns={\"travel_time\": \"median_tt\", \"from_id\": \"n_stations_serving\"}\n    )\n    # need integer for n_stations_serving but there are NaNs\n    bool_ind = df[\"n_stations_serving\"].isna()\n    df.loc[bool_ind, \"n_stations_serving\"] = 0.0\n    df[\"n_stations_serving\"] = df[\"n_stations_serving\"].astype(\"int16\")\n    #----- Part 2 -----\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x = df[\"n_stations_serving\"].values.reshape(-1, 1)\n    x_scaled = min_max_scaler.fit_transform(x)\n    df[\"n_stations_norm\"] = pd.Series(x_scaled.flatten())\n    max_tt = max(df[\"median_tt\"].dropna())\n    df[\"inverted_med_tt\"] = (max_tt - df[\"median_tt\"])\n    x = df[\"inverted_med_tt\"].values.reshape(-1, 1)\n    x_scaled = min_max_scaler.fit_transform(x)\n    df[\"inverted_med_tt\"] = pd.Series(x_scaled.flatten())\n    out_gdf = gpd.GeoDataFrame(df, crs=4326)\n    out_gdf[\"listed_geom\"] = [[c.x, c.y] for c in out_gdf[\"geometry\"]]\n\n    return out_gdf\n\n\nmed_tts = get_median_tts_for_all_stations(travel_time_matrix, point_plane)\nmed_tts.dropna().head()\n\n\n\n\n\n\n\n\n\nid\ngeometry\nmedian_tt\nn_stations_serving\nn_stations_norm\ninverted_med_tt\nlisted_geom\n\n\n\n\n1386\n1386\nPOINT (-0.14795 51.41766)\n30.0\n1\n0.002660\n0.117647\n[-0.1479481, 51.4176588]\n\n\n1388\n1388\nPOINT (-0.13660 51.41752)\n29.0\n1\n0.002660\n0.176471\n[-0.1366036, 51.4175184]\n\n\n1469\n1469\nPOINT (-0.25464 51.42343)\n31.0\n1\n0.002660\n0.058824\n[-0.2546385, 51.4234283]\n\n\n1470\n1470\nPOINT (-0.25322 51.42198)\n32.0\n2\n0.005319\n0.000000\n[-0.2532204, 51.4219807]\n\n\n1472\n1472\nPOINT (-0.23869 51.42585)\n27.5\n2\n0.005319\n0.264706\n[-0.2386902, 51.4258517]\n\n\n\n\n\n\n\nAs this final GeoDataFrame is all that is required for the remaining tutorial, go ahead and tidy up the environment.\n\n# Tidy up\ntmp.cleanup() # only needed if tmp directory used\ndel [station_gdf, travel_time_matrix, point_plane, transport_network, imap,\nlargest_snaps, z_start]\n\n\n\n\nVisualise Travel Time\n\nExercise 9\nUsing the pydeck scatterplot layer docs, write a function that will take the med_tts GeoDataFrame and plot an interactive map. Use the features available in med_tts to customise the point radius and colour. Use the function to render an interactive map.\n\n\nShow the code\ndef make_scatter_deck(\n    gdf: gpd.GeoDataFrame,\n    radius=\"(n_stations_norm * 20) + 20\",\n    start_lon: float=-0.005,\n    start_lat: float=51.518,\n    start_zoom: Union[int, float]=10,\n) -&gt; pdk.Deck:\n    \"\"\"Render a scatterPlotLayer of travel time & number of stations serving.\n\n    Intended for use with output of ./src/tt-london-bikes.py -&gt;\n    ./data/interim/median_travel_times.pkl.\n\n    Parameters\n    ----------\n    gdf : gpd.GeoDataFrame\n        Table of grid locations and travel time from station locations.\n    radius : str, optional\n        A valid pydeck get_radius expression, by default\n        \"(n_stations_norm * 25) + 20\"\n    start_lon: float, optional\n        The starting view longitude, by default -0.110.\n    start_lat: float, optional\n        The starting view latitude, by default 51.518.\n    start_zoom: Union[int, float], optional\n        The starting view zoom, by default 10.\n\n    Returns\n    -------\n    pdk.Deck\n        A rendered interactive map.\n\n    \"\"\"\n    # some basic defensive checks\n    if not isinstance(gdf, gpd.GeoDataFrame):\n        raise TypeError(f\"gdf expected gpd.GeoDataFrame, found {type(gdf)}\")\n    expected_cols = [\n        \"n_stations_serving\",\n        \"listed_geom\",\n        \"inverted_med_tt\",\n        \"median_tt\",\n    ]\n    coldiff = sorted(list(set(expected_cols).difference(gdf.columns)))\n    if coldiff:\n        raise AttributeError(f\"Required column names are absent: {coldiff}\")\n    gdf = gdf.rename(columns={\"n_stations_serving\": \"n_stats\"})\n    # create deck layers\n    layer = pdk.Layer(\n        \"ScatterplotLayer\",\n        gdf,\n        pickable=True,\n        opacity=0.2,\n        stroked=True,\n        filled=True,\n        radius_scale=6,\n        radius_min_pixels=1,\n        radius_max_pixels=100,\n        line_width_min_pixels=1,\n        get_position=\"listed_geom\",\n        get_radius=radius,\n        get_fill_color=\"[255,(median_tt * 255), (inverted_med_tt * 255)]\",\n        get_line_color=\"[255,(median_tt * 255), (inverted_med_tt * 255)]\",\n    )\n    # Set the viewport location\n    view_state = pdk.ViewState(\n        longitude=start_lon,\n        latitude=start_lat,\n        zoom=start_zoom,\n        min_zoom=5,\n        max_zoom=15,\n        pitch=40.5,\n        bearing=-27.36,\n    )\n    tooltip = {\n        \"text\": \"Stations serving: {n_stats}\\nMdn travel time: {median_tt}\"\n    }\n    # Render\n    r = pdk.Deck(\n        layers=[layer], initial_view_state=view_state, tooltip=tooltip\n    )\n    return r\n\n\nr = make_scatter_deck(med_tts)\nr\n\n\n\n        \n    \n\n\nTake some time to study the map. Pan in and out by scrolling. The angle of the map can be adjusted by shift + clicking and dragging the mouse left to right. Find the point with the greatest number of stations serving. Look for any curious patterns in the median travel time. Take a look at the Greenwich peninsula, where the River Thames appears to limit accessibility from the North.\n\n\nExercise 10\nLastly, we can identify those points within the thirty minute reachable area from the bike station network that are the most remote. Let’s visualise the 20 most remote locations. These would represent candidate locations for increasing the coverage of the bike network within the thirty minute reachable zone. Once more, please note that the point grid is naive to locations where people live or would like to travel to and from.\n\n\n\n\n\n\nClick to expand hint\n\n\n\n\n\n\nSort descending the med_tt dataframe on median_tt and n_stations_serving.\nTake the top 20 records.\nPass this dataframe to the function you wrote in exercise 9.\n\n\n\n\n\n\nShow the code\nn_isolated = (\n    med_tts.dropna()\n    .sort_values([\"median_tt\", \"n_stations_serving\"], ascending=[False, False])\n    .head(20)\n)\nr = make_scatter_deck(n_isolated, radius=50, start_zoom=9.5)\nr"
  },
  {
    "objectID": "blogs/09-cycling-network-r5py.html#tips",
    "href": "blogs/09-cycling-network-r5py.html#tips",
    "title": "Bicycle Network Modelling with r5py",
    "section": "Tips",
    "text": "Tips\n\nMost of the packages used in this tutorial expect the sequence of coordinates to be long, lat. If you select an alternative method for mapping visuals, remember to check that this is consistent. If you are getting empty interactive map visuals, pan out and check if an incorrect coordinate specification has resulted in your points being rendered off the East coast of Africa.\nThe exception to the above rule is haversine, which expects lat, long."
  },
  {
    "objectID": "blogs/09-cycling-network-r5py.html#conclusion",
    "href": "blogs/09-cycling-network-r5py.html#conclusion",
    "title": "Bicycle Network Modelling with r5py",
    "section": "Conclusion",
    "text": "Conclusion\nIf you made it this far, well done! This tutorial has got you up and running with the r5py package. You have used several libraries in the python GIS stack to execute an analysis of bike station locations in London:\n\nStation locations were ingested with TfL’s api.\nOpenStreetMap data was ingested from the BBBikes download service.\nA point plane of your size was generated.\nThe coverage of the point plane was inspected.\nThe point plane features were adjusted to the underlying transport network.\nMedian travel times from bike stations to the point plane were calculated.\nTravel times were summarised and features engineered for presentation in informative pydeck maps.\n\nNext steps for this work would be to explore how potential station locations could be informed by places where people would wish to commute, such as retail, businesses, tourist attractions and residential areas. OpenStreetMap files are a rich source of location data, which can be extracted with libraries such as pyosmium.\nService optimisation is an interesting area of operational research. This analysis does not consider local demand on the stations and their capacity to meet that demand. This sort of problem is known as the capacitated facility location problem and can provide operational efficiencies while improving service quality for the customer.\n\nfin!"
  }
]